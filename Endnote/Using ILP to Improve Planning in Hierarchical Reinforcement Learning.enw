%0 Conference Proceedings
%T Using ILP to Improve Planning in Hierarchical Reinforcement Learning
%A Reid, Mark
%A Ryan, Malcolm
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_11
%X Hierarchical reinforcement learning has been proposed as a solution to the problem of scaling up reinforcement learning. The RL-TOPs Hierarchical Reinforcement Learning System is an implementation of this proposal which structures an agent’s sensors and actions into various levels of representation and control. Disparity between levels of representation means actions can be misused by the planning algorithm in the system. This paper reports on how ILP was used to bridge these representation gaps and shows empirically how this improved the system’s performance. Also discussed are some of the problems encountered when using an ILP system in what is inherently a noisy and incremental domain.
%P 174-190

