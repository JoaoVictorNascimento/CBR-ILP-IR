%0 Conference Proceedings
%T Audio Information Retrieval (AIR) Tools
%D 2000
%A Cook, Perry R.
%A Tzanetakis, George
%X Most of the work in music Information Retrieval (MIR) and analysis has been performed using symbolic representation like MIDI. The recent advances in computing power and network connectivity have made large amounts of raw digital audio data available in the form of unstructured monolithic sound files. In this work the focus is on tools that work directly on real world audio data without attempting to transcribe the music. To distinguish from symbolic−based music IR for the remainder of the paper we use the term audio IR (AIR) to refer to techniques that work directly on raw audio signals. Obviously these signals can contain music as well as other types of audio like speech. We describe a series of tools based on current and newly developed techniques for AIR integrated under MARSYAS, our framework for audio analysis. For related work refer to (Foote, 1999). The tools developed are based on Signal Processing, Pattern Recognition and Visualization techniques. Finally, due to the immature state of the available techniques and to the inherent complexity of the task it is important to take advantage of the human user in the system. We have developed two user interfaces to integrate and improve our techniques: an augmented sound editor and TimbreGrams a novel graphical representation for soundfiles. The previously unpublished contributions of this paper are the genre classification method, the segmentation− based retrieval and summarization, and the definition of the TimbreGram. Feature−based audio analysis The developed analysis tools are based on the calculation of short−time feature vectors. The signal is processed in small chunks so that its statistical characteristics are relativily stable. For each chunk some form of spectral analysis is performed and based on that analysis a vector of feature values is calculated. In our system features based on FFT (Fast Fourier Transform) analysis, MPEG filterbank analysis, LPC (Linear Predictive Coding) and MFCC (Mel−Frequency cepstrum coefficients) are supported. In addition derivatives and running statistics are used to express temporal changes. The flexible architecture of MARSYAS allows the easy integration and experimentation of new features. Based on the calculated features different types of audio analysis processes can be performed.
