%A French, JC
%A Powell, AL
%A Callan, J
%A Viles, CL
%A Emmitt, T
%A Prey, KJ
%A Mou, Y
%E Hearst, M
%E Gey, F
%E Tong, R
%T Comparing the performance of database selection algorithms
%G English
%0 Conference Proceedings
%X We compare the performance of two database selection algorithms reported in the literature. Their performance is compared using a common testbed designed specifically for database selection techniques. The testbed is a decomposition of the TREC/TIPSTER data into 236 subcollections. The databases from our testbed were ranked using both the gGlOSS and CORI techniques and compared to a baseline derived from TREC relevance judgements. We examined the degree to which CORI and gGlOSS approximate this baseline. Our results confirm our earlier observation that the gGlOSS Ideal(l) ranks do not estimate relevance-based ranks well. We also find that CORI is a uniformly better estimator of relevance-based ranks than gGlOSS for the test environment used in this study. Part of the advantage of the CORI algorithm can be explained by a strong correlation between gGlOSS and a sire-based baseline (SBR). We also find that CORI produces consistently accurate rankings on testbeds ranging from 100-921 sites. However for a given level of recall, search effort appears to scale linearly with the number of databases.
%I ASSOC COMPUTING MACHINERY
%C 1515 BROADWAY, NEW YORK, NY 10036-9998 USA
%D 1999
%R 10.1145/312624.312684


%A Fujii, A
%A Itou, K
%A Ishikawa, T
%E Hajic, J
%E Matsumoto, Y
%T A method for open-vocabulary speech-driven text retrieval
%G English
%0 Conference Proceedings
%X While recent retrieval techniques do not limit the number of index terms, out-of-vocabulary (OOV) words are crucial in speech recognition. Aiming at retrieving information with spoken queries, we fill the gap between speech recognition and text retrieval in terms of the vocabulary size. Given a spoken query, we generate a transcription and detect OOV words through speech recognition. We then correspond detected OOV words to terms indexed in a target collection to complete the transcription, and search the collection for documents relevant to the completed transcription. We show the effectiveness of our method by way of experiments.
%I ASSOCIATION COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2002


%A Stoica, I
%A Morris, R
%A Karger, D
%A Kaashoek, MF
%A Balakrishnan, H
%T Chord: A scalable peer-to-peer lookup service for Internet applications
%G English
%0 Journal Article
%X A fundamental problem that confronts peer-to-peer applications is to efficiently locate the node that stores a particular data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data item pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis, simulations, and experiments show that Chord is scalable, with communication cost and the state maintained by each node scaling logarithmically with the number of Chord nodes.
%I ASSOC COMPUTING MACHINERY
%C 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
%D 2001
%V 31
%R 10.1145/964723.383071


%A Nie, JY
%A Cai, J
%T Filtering noisy parallel corpora of Web pages
%G English
%0 Conference Proceedings
%X In our previous study, we successfully built an automatic mining system for parallel texts from the Web - PTMiner that is able to determine a large number of parallel Web pages for different language pairs. However, there are a number of non-parallel text pairs in this corpus. This paper proposes a filtering approach to clean up the corpus. Our experiments show that once the corpus is cleaned, both the translation accuracy of the resulting translation models and the effectiveness of cross-language information retrieval (CLIR) using these models are improved significantly.
%I IEEE
%C 345 E 47TH ST, NEW YORK, NY 10017 USA
%D 2002


%A Chen, J
%A Nie, JY
%T Automatic construction of parallel English-Chinese corpus for cross-language information retrieval
%G English
%0 Conference Proceedings
%X A major obstacle to the construction of a probabilistic translation model is the lack of large parallel corpora. In this paper we first describe a parallel text mining system that finds parallel texts automatically on the Web. The generated Chinese-English parallel corpus is used to train a probabilistic translation model which translates queries for Chinese-English cross-language information retrieval (CLIR). We will discuss some problems in translation model training and show the preliminary CLIR results.
%I ASSOCIATION COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2000


%A Aslam, JA
%A Decatur, SE
%T Specification and simulation of statistical query algorithms for efficiency and noise tolerance
%G English
%0 Journal Article
%X A recent innovation in computational learning theory is the statistical query (SQ) model. The advantage of specifying learning algorithms in this model is that SO algorithms can be simulated in the probably approximately correct (PAC) model, both in the absence and in the presence of noise. However, simulations of SO algorithms in the PAC model have non-optimal time and sample complexities. In this paper, we introduce a new method for specifying statistical query algorithms based on a type of relative error and provide simulations in the noise-free and noise-tolerant PAC models which yield more efficient algorithms. Requests for estimates of statistics in this new model take the following form: "Return an estimate of the statistic within a 1 +/- mu factor, or return perpendicular to, promising that the statistic is less than theta." In addition to showing that this is a very natural language for specifying learning algorithms, we also shaw that this new specification is polynomially equivalent to standard SQ, and thus, known learnability and hardness results for statistical query learning are preserved. We then give highly efficient PAC simulations of relative error SQ algorithms. We show that the learning algorithms obtained by simulating efficient relative error SQ algorithms both in the absence of noise and in the presence of malicious noise have roughly optimal sample complexity. We also show that the simulation of efficient relative error SQ algorithms in the presence of classification noise yields learning algorithms at least as efficient as those obtained through standard methods, and in some cases improved, roughly optimal results are achieved. The sample complexities for all of these simulations are based on the d(v) metric, which is a type of relative error metric useful for quantities which are small or even zero. We show that uniform convergence with respect to the d(v) metric yields "uniform convergence" with respect to (mu, theta) accuracy. Finally, while we show that many specific learning algorithms can be written as highly efficient relative error SO algorithms, we also show, in fact, that all SO algorithms can be written efficiently by proving general upper bounds on the complexity of (mu, theta) queries as a function of the accuracy parameter epsilon. As a consequence of this result, we give general upper bounds on the complexity of learning algorithms achieved through the use of relative error SO algorithms and the simulations described above. (C) 1998 Academic Press.
%I ACADEMIC PRESS INC
%C 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
%D 1998
%V 56
%R 10.1006/jcss.1997.1558


%A Fujii, A
%A Ishikawa, T
%T Utilizing the World Wide Web as an encyclopedia: Extracting term descriptions from semi-structured texts
%G English
%0 Conference Proceedings
%X In this paper, we propose a method to extract descriptions of technical terms from Web pages in order to utilize the World Wide Web as an encyclopedia. We use linguistic patterns and HTML text structures to extract text fragments containing term descriptions. We also use a language model to discard extraneous descriptions, and a clustering method to summarize resultant descriptions. We show the effectiveness of our method by way of experiments.
%I ASSOC COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2000


%A Wermter, S
%A Arevian, G
%E Smith, MH
%E Gruver, WA
%E Hall, LO
%T Modular preference Moore machines in news mining agents
%G English
%0 Conference Proceedings
%X This paper focuses on Hybrid Symbolic Neural Architectures that support the task of classifying textual information in learning agents. We give an outline of these symbolic and neural preference Moore machines. Furthermore, we demonstrate how they can be used in the context of information mining and news classification. Using the Reuters newswire text data, we demonstrate how hybrid symbolic and neural machines can provide an effective foundation for learning news agents. 
%X This paper focuses on Hybrid Symbolic Neural Architectures that support the task of classifying textual information in learning agents. We give an outline of these symbolic and neural preference Moore machines, Furthermore, we demonstrate how they can be used in the context of information mining and news classification. Using the Reuters newswire text data, we demonstrate how hybrid symbolic and neural machines can provide an effective foundation for learning news agents.
%I IEEE
%C 345 E 47TH ST, NEW YORK, NY 10017 USA
%D 2001


%A Aslam, JA
%A Decatur, SE
%T On the sample complexity of noise-tolerant learning
%G English
%0 Journal Article
%X In this paper, we further characterize the complexity of noise-tolerant learning in the PAC model, Specifically, we show a general lower bound of Omega(log(1/delta)/epsilon(1 - 2 eta)(2)) on the number of examples required for PAC learning in the presence of classification noise, Combined with a result of Simon, we effectively show that the sample complexity of PAC learning in the presence of classification noise is Omega(VC(F)/epsilon(1-2 eta)(2) + log(1/delta)/epsilon(1 - 2 eta)(2)). Furthermore, we demonstrate the optimality of the general lower bound by providing a noise-tolerant learning algorithm for the class of symmetric Boolean functions which uses a sample size within a constant factor of this bound. Finally, we note that our general lower bound compares favorably with various general upper bounds for PAC learning in the presence of classification noise.
%I ELSEVIER SCIENCE BV
%C PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
%D 1996
%V 57
%R 10.1016/0020-0190(96)00006-3


%A Laham, D
%E Shafto, MG
%E Langley, P
%T Latent semantic analysis approaches to categorization
%G English
%0 Conference Proceedings
%X Many computational models of semantic memory rely on vector representations of concepts based on explicit encoding of arbitrary feature sets. Latent Semantic Analysis (LSA) creates high dimensional (n = 300+) vectors for concepts in semantic memory through statistical analysis of a large representative corpus of text rather than subjective feature sets linked to object names (for details see Landauer & Dumais, 1997; Landauer, Foltz, & Laham, in press). Concepts can be compared in the semantic space and their similarity indexed by the cosine of the angle between vectors.
%I LAWRENCE ERLBAUM ASSOC PUBL
%C 10 INDUSTRIAL AVE, MAHWAH, NJ 07430 USA
%D 1997


%A BEIMEL, A
%A CHOR, B
%T UNIVERSALLY IDEAL SECRET-SHARING SCHEMES
%G English
%0 Journal Article
%X Given a set of parties {1,...,n), an access structure is a monotone collection of subsets of the parties. For a certain domain of secrets, a secret-sharing scheme for an access structure is a method for a dealer to distribute shares to the parties. These shares enable subsets in the access structure to reconstruct the secret, while subsets not in the access structure get no information about the secret. A secret-sharing scheme is ideal if the domains of the shares are the same as the domain of the secrets. An access structure is universally ideal if there exists an ideal secret-sharing scheme for it over every finite domain of secrets. An obvious necessary condition for an access structure to be universally ideal is to be ideal over the binary and ternary domains of secrets. In this work, we prove that this condition is also sufficient. We also show that being ideal over just one of the two domains does not suffice for universally ideal access structures. Finally, we give an exact characterization for each of these two conditions.
%I IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
%C 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
%D 1994
%V 40
%R 10.1109/18.335890


%A Beimel, A
%A Gal, A
%A Paterson, M
%T Lower bounds for monotone span programs
%G English
%0 Conference Proceedings
%X Span programs provide a linear algebraic model of computation. Lower bounds for span programs imply lower bounds for formula size, symmetric branching programs, and contact schemes. Monotone span programs correspond also to linear secret-sharing schemes. We present a new technique for proving lower bounds for monotone span programs. We prove a lower bound of (m 2.5) for the 6-clique function. Our results improve on the previously known bounds for explicit functions.
%I I E E E, COMPUTER SOC PRESS
%C 10662 LOS VAQUEROS CIRCLE, LOS ALAMITOS, CA 90720
%D 1995
%R 10.1109/SFCS.1995.492669


%A Tzanetakis, G
%A Cook, P
%T Musical genre classification of audio signals
%G English
%0 Journal Article
%X Musical genres are categorical labels created by humans to characterize pieces of music. A musical genre is characterized by the common characteristics shared by its members. These characteristics typically are related to the instrumentation, rhythmic structure, and harmonic content of the music. Genre hierarchies are commonly used to structure the large collections of music available on the Web. Currently musical genre annotation is performed manually. Automatic musical genre classification can assist or replace the human user in this process and would be a valuable addition to music information retrieval systems. In addition, automatic musical genre classification provides a framework for developing and evaluating features for any type of content-based analysis of musical signals. In this paper, the automatic classification of audio signals into an hierarchy of musical genres is explored. More specifically, three feature sets for representing timbral texture, rhythmic content and pitch content are proposed. The performance and relative importance of the proposed features is investigated by training statistical pattern recognition classifiers using real-world audio collections. Both whole file and real-time frame-based classification schemes are described. Using the proposed feature sets, classification of 61% for ten musical genres is achieved. This result is comparable to results reported for human musical genre classification.
%I IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
%C 345 E 47TH ST, NEW YORK, NY 10017-2394 USA
%D 2002
%V 10
%R 10.1109/TSA.2002.800560


%A Beimel, A
%A Gal, A
%T On arithmetic branching programs
%G English
%0 Journal Article
%X The model of arithmetic branching programs is an algebraic model of computation generalizing the model of modular branching programs. We show that, up to a polynomial factor in size, arithmetic branching programs are equivalent to complements of dependency programs, a model introduced by Pudlak and Sgall. Using this equivalence we prove that dependency programs are closed under conjunction over every field, answering an open problem of theirs. Furthermore, we show that span programs, an algebraic model of computation introduced by Karchmer and Wigderson, are at least as strong as arithmetic programs; every arithmetic program can be simulated by a span program of size not more than twice the size of the arithmetic program. Using the above results we give a new proof that N L/poly subset of or equal to + L/poly, first proved by Wigderson [25]. Our simulation of N L/poly is more efficient, and it holds for logspace counting classes over every field. (C) 1999 Academic Press.
%I ACADEMIC PRESS INC ELSEVIER SCIENCE
%C 525 B ST, STE 1900, SAN DIEGO, CA 92101-4495 USA
%D 1999
%V 59
%R 10.1006/jcss.1999.1648


%A RILOFF, E
%A LEHNERT, W
%T INFORMATION EXTRACTION AS A BASIS FOR HIGH-PRECISION TEXT CLASSIFICATION
%G English
%0 Journal Article
%X We describe an approach to text classification that represents a compromise between traditional word-based techniques and in-depth natural language processing.  Our approach uses a natural language processing task called ''information extraction'' as a basis for high-precision text classification.  We present three algorithms that use varying amounts of extracted information to classify texts.  The relevancy signatures algorithm uses linguistic phrases; the augmented relevancy signatures algorithm uses phrases and local context; and the case-based text classification algorithm uses larger pieces of context.  Relevant phrases and contexts are acquired automatically using a training corpus.  We evaluate the algorithms on the basis of two test sets from the MUC-4 corpus.  All three algorithms achieved high precision on both test sets, with the augmented relevancy signatures algorithm and the case-based algorithm reaching 100% precision with over 60% recall on one set.  Additionally, we compare the algorithms on a larger collection of 1700 texts and describe an automated method for empirically deriving appropriate threshold values.  The results suggest that information extraction techniques can support high-precision text classification and, in general, that using more extracted information improves performance.  As a practical matter, we also explain how the text classification system can be easily ported across domains.
%I ASSOC COMPUTING MACHINERY
%C 1515 BROADWAY, NEW YORK, NY 10036
%D 1994
%V 12
%R 10.1145/183422.183428


%A HERLOCKER, JL
%A KONSTAN, JA
%T Tcl commands as media in a distributed multimedia toolkit
%G English
%0 Conference Proceedings
%X This paper discusses the design and implementation of a command stream based on Tcl. A command stream is a series of arbitrary commands that can be tightly synchronized with other media in a distributed multimedia presentation. In TclStream, we represent an arbitrary command as a collection of fragments of Tcl code. The command stream medium supports the standard manipulation functions of multimedia environments: reverse, fast-forward, random access, and variable speed. The ability to specify arbitrary actions, combined with fine playback control, make TclStream an extremely flexible and powerful presentation medium. 
%I USENIX ASSOC
%C SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710
%D 1995


%A Feamster, N
%A Balazinska, M
%A Harfst, G
%A Balakrishnan, H
%A Karger, D
%T Infranet: Circumventing web censorship and surveillance
%G English
%0 Conference Proceedings
%X An increasing number of countries and companies routinely block or monitor access to parts of the Internet. To counteract these measures, we propose Infranet, a system that enables clients to surreptitiously retrieve sensitive content via cooperating Web servers distributed across the global Internet. These Infranet servers provide clients access to censored sites while continuing to host normal uncensored content. Infranet uses a tunnel protocol that provides a covert communication channel between its clients and servers, modulated over standard HTTP transactions that resemble innocuous Web browsing. In the upstream direction, Infranet clients send covert messages to Infranet servers by associating meaning to the sequence of HTTP requests being made. In the downstream direction, Infranet servers return content by hiding censored data in uncensored images using steganographic techniques. We describe the design, a prototype implementation, security properties, and performance of Infranet. Our security analysis shows that Infranet can successfully circumvent several sophisticated censoring techniques.
%I USENIX ASSOC
%C SUITE 215, 2560 NINTH ST, BERKELEY, CA 94710 USA
%D 2002


%A Beimel, A
%A Kushilevitz, E
%T Learning boxes in high dimension
%G English
%0 Journal Article
%X We present exact learning algorithms that learn several classes of (discrete) boxes in [O,..., l - 1](n). In particular we learn: (1) The class of unions of O (log n) boxes in time poly(n, log l) (solving an open problem of [16] and [12]; in [3] this class is shown to be learnable in time poly(n, l)). (2) The class of unions of disjoint boxes in time poly(n, t, log l), where t is the number of boxes. (Previously this was known only in the case where all boxes are disjoint in one of the dimensions; in [3] this class is shown to be learnable in time poly(n,t, l).) In particular our algorithm learns the class of decision trees over n variables, that take values in (O,..., l - 1), with comparison nodes in time poly(n, t, log l), where t is the number of leaves (this was an open problem in [9] which was shown in [4] to be learnable in time poly(n, t, l)). (3) The class of unions of O(1)-degenerate boxes (that is, boxes that depend only on O(1) variables) in time poly(n, t, log l) (generalizing the learnability of O(1)-DNF and of boxes in O(1) dimensions). The algorithm for this class uses only equivalence queries and it can also be used to learn the class of unions of O(1) boxes (from equivalence queries only).
%I SPRINGER
%C 233 SPRING ST, NEW YORK, NY 10013 USA
%D 1998
%V 22
%R 10.1007/PL00013835


%A Riloff, E
%A Wiebe, J
%E Collins, M
%E Steedman, M
%T Learning extraction patterns for subjective expressions
%G English
%0 Conference Proceedings
%X This paper presents a bootstrapping process that learns linguistically rich extraction patterns for subjective (opinionated) expressions. High-precision classifiers label unannotated data to automatically create a large training set, which is then given to an extraction pattern learning algorithm. The learned patterns are then used to identify more subjective sentences. The bootstrapping process learns many subjective patterns and increases recall while maintaining high precision.
%I ASSOCIATION COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2003


%A DEERWESTER, S
%A DUMAIS, ST
%A FURNAS, GW
%A LANDAUER, TK
%A HARSHMAN, R
%T INDEXING BY LATENT SEMANTIC ANALYSIS
%G English
%0 Journal Article
%X A new method for automatic indexing and retrieval is described. The approach is to take advantage of implicit higher-order structure in the association of terms with documents (âsemantic structureâ) in order to improve the detection of relevant documents on the basis of terms found in queries. The particular technique used is singular-value decomposition, in which a large term by document matrix is decomposed into a set of ca. 100 orthogonal factors from which the original matrix can be approximated by linear combination. Documents are represented by ca. 100 item vectors of factor weights. Queries are represented as pseudo-document vectors formed from weighted combinations of terms, and documents with supra-threshold cosine values are returned. initial tests find this completely automatic method for retrieval to be promising.
%I JOHN WILEY & SONS INC
%C 111 RIVER ST, HOBOKEN, NJ 07030 USA
%D 1990
%V 41
%R 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9


%A Fujii, A
%A Ishikawa, T
%T Organizing encyclopedic knowledge based on the web and its application to question answering
%G English
%0 Conference Proceedings
%X We propose a method to generate large-scale encyclopedic knowledge, which is valuable for much NLP research, based on the Web. We first search the Web for pages containing a term in question. Then we use linguistic patterns and HTML structures to extract text fragments describing the term. Finally, we organize extracted term descriptions based on word senses and domains. In addition, we apply an automatically generated encyclopedia to a question answering system targeting the Japanese Information-Technology Engineers Examination.
%I ASSOCIATION COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2001


%A Itou, K
%A Fujii, A
%A Ishikawa, T
%T Language modeling for multi-domain speech-driven text retrieval
%G English
%0 Conference Proceedings
%X We report experimental results associated with speech-driven text retrieval, which facilitates retrieving information in multiple domains with spoken queries. Since users speak contents related to a target collection, we produce language models used for speech recognition based on the target collection, so as to improve both the recognition and retrieval accuracy. Experiments using existing test collections combined with dictated queries showed the effectiveness of our method.
%I IEEE
%C 345 E 47TH ST, NEW YORK, NY 10017 USA
%D 2001


%A Beimel, A
%A Chor, B
%T Communication in key distribution schemes
%G English
%0 Journal Article
%X A (g, b) key distribution scheme allows conferences of g users to generate secret keys, such that disjoint coalitions. of b users cannot gain any information on the generated key (in the information-theoretic sense). In this work, we study the relationships between communication and space efficiency of key distribution schemes. We prove that communication does not help in the context of unrestricted schemes. On the other hand, we show that for restricted schemes, which are secure only when used by a limited number of conferences, communication can substantially improve the space efficiency. We also present lower bounds on the space efficiency of restricted schemes.
%I IEEE-INST ELECTRICAL ELECTRONICS ENGINEERS INC
%C 445 HOES LANE, PISCATAWAY, NJ 08855-4141 USA
%D 1996
%V 42
%R 10.1109/18.481774


%A Hearst, MA
%A Karadi, C
%E Belkin, NJ
%E Narasimhalu, AD
%E Willett, P
%T Cat-a-cone: An interactive interface for specifying searches and viewing retrieval results using a large category hierarchy
%G English
%0 Conference Proceedings
%X This paper introduces a novel user interface that integrates search and browsing of very large category hierarchies with their associated text collections. A key component is the separate but simultaneous display of the representations of the categories and the retrieved documents. Another key component is the display of multiple selected categories simultaneously, complete with their hierarchical context. The prototype implementation uses animation and a three-dimensional graphical workspace to accommodate the category hierarchy and to store intermediate search results. Query specification in this 3D environment is accomplished via a novel method for painting Boolean queries over a combination of category labels and free text, Examples are shown on a collection of medical text.
%I ASSOC COMPUTING MACHINERY
%C 1515 BROADWAY, NEW YORK, NY 10036-9998
%D 1997
%R 10.1145/258525.258582


%A Beimel, A
%A Weinreb, E
%E Titsworth, F
%T Separating the power of monotone span programs over different fields
%G English
%0 Conference Proceedings
%X Monotone span programs are a linear-algebraic model of computation. They are equivalent to linear secret sharing schemes and have various applications in cryptography and complexity. A fundamental question is how the choice of the field in which the algebraic operations are performed effects the power of the span program. In this paper we prove that the power of monotone span programs over finite fields of different characteristics is incomparable; we show a super-polynomial separation between any two fields with different characteristics, answering an open problem of Pudlak and Sgall 1998. Using this result we prove a super-polynomial lower bound for monotone span programs for a function in uniform - NC2 (and therefore in P), answering an open problem of Babai, Wigderson, and Gal 1999. (All previous lower bounds for monotone span programs were for functions not known to be in P.) Finally, we show that quasi-linear schemes, a generalization of linear secret sharing schemes introduced in Beimel and Ishai 2001, are stronger than linear secret sharing schemes. In particular, this proves, without any assumptions, that non-linear secret sharing schemes are more efficient than linear secret sharing schemes.
%I IEEE COMPUTER SOC
%C 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
%D 2003
%R 10.1109/SFCS.2003.1238216


%A Tzanetakis, G
%A Cook, P
%T Sound analysis using MPEG compressed audio
%G English
%0 Conference Proceedings
%X There is a huge amount of audio data available that is compressed using the MPEG audio compression standard. Sound analysis is based on the computation of short time feature vectors that describe the instantaneous spectral content of the sound. An interesting possibility is the calculation of features directly from compressed data. Since the bulk of the feature calculation is performed during the encoding stage this process has a significant performance advantage if the available data is compressed. Combining decoding and analysis in one stage is also very important for audio streaming applications. In this paper, we describe the calculation of features directly from MPEG audio compressed data. Two of the basic processes of analyzing sound are: segmentation and classification. To illustrate the effectiveness of the calculated features we have implemented two case studies: a general audio segmentation algorithm and a Music/Speech classifier. Experimental data is provided to show that the results obtained are comparable with sound analysis algorithms working directly with audio samples.
%I IEEE
%C 345 E 47TH ST, NEW YORK, NY 10017 USA
%D 2000


%A French, JC
%A Knight, JC
%A Powell, AL
%T Applying hypertext structures to software documentation
%G English
%0 Journal Article
%X Software documentation represents a critical resource to the successful functioning of many enterprises. However, because it is static, documentation often fails to meet the needs of the many diverse users who are required to consult it on a regular basis in the course of their daily work. Software documentation is a rich resource that has not been fully exploited. Treatment of software documentation presents a number of interesting problems that require a blend of information retrieval and hypertext techniques for their successful solution. The evolving nature of a software project and the diverse demands on its documentation present an especially challenging environment. This is made even more challenging by the variety of information resources, ranging from formal specification languages to source code, that must be integrated into a coherent whole for the purpose of querying. In this paper we discuss work in progress at the University of Virginia. We consider the issues involved with automating the management of software documentation to better increase its utility. We describe a prototype system, SLEUTH, currently under investigation as a vehicle for software documentation management. The prototype maintains software documentation as a hypertext with typed links for the purpose of browsing by users with varying needs. These links are generated mechanically by the system and kept accurate under update. Appropriate authoring tools provide the system with the information it needs for this maintenance function. Ad hoc querying is provided over the documentation and hypertext documents are synthesized in response to these queries. (C) 1997 Elsevier Science Ltd.
%I PERGAMON-ELSEVIER SCIENCE LTD
%C THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD, ENGLAND OX5 1GB
%D 1997
%V 33
%R 10.1016/S0306-4573(96)00064-7


%A French, JC
%A Powell, AL
%A Schulman, E
%T Using clustering strategies for creating authority files
%G English
%0 Journal Article
%X As more online databases are integrated into digital libraries, the issue of quality control of the data becomes increasingly important, especially as it relates to the effective retrieval of information. Authority work, the need to discover and reconcile variant forms of strings in bibliographic entries, will become more critical in the future. Spelling variants, misspellings, and transliteration differences will all increase the difficulty of retrieving information. We investigate a number of approximate string matching techniques that have traditionally been used to help with this problem. We then introduce the notion of approximate word matching and show how it can be used to improve detection and categorization of variant forms. We demonstrate the utility of these approaches using data from the Astrophysics Data System and show how we can reduce the human effort involved in the creation of authority files.
%I WILEY
%C 111 RIVER ST, HOBOKEN, NJ 07030 USA
%D 2000
%V 51
%R 10.1002/(SICI)1097-4571(2000)51:8<774::AID-ASI90>3.0.CO;2-P


%A Beimel, A
%A Chor, B
%E Coppersmith, D
%T Secret sharing with public reconstruction
%G English
%0 Journal Article
%X All known constructions of information theoretic t-out-of-n secret sharing schemes require secure, private communication channels among the parties for the reconstruction of the secret. In this work we investigate the cost of performing the reconstruction over public communication channels. A naive implementation of this task distributes O(n) one times pads to each party. This results in shares whose size is O(n) times the secret size. We present three implementations of such schemes that are substantially more efficient: A scheme enabling multiple reconstructions of the secret by different subsets of parties, with factor O(n/t) increase in the shares' size. A one-time scheme, enabling a single reconstruction of the secret, with O(log(n/t)) increase in the shares) size. A one-time scheme, enabling a single reconstruction by a set of size exactly t, with factor O(1) increase in the shares' size. We prove that the first implementation is optimal (up to constant factors) by showing a tight Omega(n/t) lower bound for the increase in the shares' size.
%I SPRINGER-VERLAG BERLIN
%C HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
%D 1995
%V 963


%A Fusiello, A
%A Panuccio, A
%A Murino, V
%A Fontana, F
%A Rocchesso, D
%T A multimodal electronic travel aid device
%G English
%0 Conference Proceedings
%X This paper describes an Electronic Travel Aid device, that may enable blind individuals to "see the world with their ears". A wearable prototype will be assembled using low-cost hardware: earphones, sunglasses fitted with two micro cameras, and a palmtop computer The system, which currently runs on a desktop computer is able to detect the light spot produced by a laser pointer compute its angular position and depth, and generate a corresponding sound providing the auditory cues for the perception of the position and distance of the pointed surface patch. It permits different sonification modes that can be chosen by drawing, with the laser pointer a predefined stroke which will be recognized by a Hidden Markov Model. In this way the blind person can use a common pointer as a replacement of the cane and will interact with the device by using a flexible and natural sketch based interface.
%I IEEE COMPUTER SOC
%C 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
%D 2002
%R 10.1109/ICMI.2002.1166966


%A Zhang, Z
%A Srihari, RK
%A Rao, A
%T Applications of image understanding in semantics-oriented multimedia information retrieval
%G English
%0 Conference Proceedings
%X This paper focuses on research in development of semantics-oriented multimedia information retrieval techniques. Semantics-oriented information retrieval addresses the effectiveness of the retrieval. With the goal of significantly improving retrieval precision and query capability, image understanding technologies are applied to develop effective retrieval techniques. Specifically, three techniques are developed by combining IU technologies (i.e., face detection) with other existing or developed techniques (i.e., text indexing, conventional similarity matching, and face identification) for image retrieval. These techniques are evaluated to demonstrate the significance of the semantics-oriented multimedia information retrieval.
%I IEEE COMPUTER SOC
%C 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
%D 2000
%R 10.1109/MMSE.2000.897197


%A Beimel, A
%A Kushilevitz, E
%T Learning unions of high-dimensional boxes over the reals
%G English
%0 Journal Article
%X Beimel and Kushilevitz (1997) presented an algorithm that exactly learns (using membership queries and equivalence queries) several classes of unions of boxes in high dimension over finite discrete domains. The running time of the algorithm is polynomial in the logarithm of the size of the domain and other parameters of the target function (in particular, the dimension). We go one step further and present a PAC + MQ algorithm whose running time is independent of the size of the domain. Thus, we can learn such classes of boxes over infinite domains. Specifically, we learn unions of t disjoint n-dimensional boxes over the reals in time polynomial in n and t, and unions of O(log n) (possibly intersecting) n-dimensional boxes over the reals in time polynomial in n. (C) 2000 Published by Elsevier Science B.V. All rights reserved.
%I ELSEVIER SCIENCE BV
%C PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
%D 2000
%V 73
%R 10.1016/S0020-0190(00)00024-7


%A Aslam, J
%A Li, Q
%A Rus, D
%T Three power-aware routing algorithms for sensor networks
%G English
%0 Journal Article
%X This paper discusses online power-aware routing in large wireless ad hoc networks (especially sensor networks) for applications in which the message sequence is not known. We seek to optimize the lifetime of the network. We show that online power-aware routing does not have a constant competitive ratio to the off-line optimal algorithm. We develop an approximation algorithm called max-min zP(min) that has a good empirical competitive ratio. To ensure scalability, we introduce a second online algorithm for power-aware routing. This hierarchical algorithm is called zone-based routing. Our experiments show that its performance is quite good. Finally, we describe a distributed version of this algorithm that does not depend on any centralization. Copyright (C) 2003 John Wiley Sons, Ltd.
%I WILEY-HINDAWI
%C ADAM HOUSE, 3RD FL, 1 FITZROY SQ, LONDON, WIT 5HE, ENGLAND
%D 2003
%V 3
%R 10.1002/wcm.111


%A Phillips, W
%A Riloff, E
%E Hajic, J
%E Matsumoto, Y
%T Exploiting strong syntactic heuristics and co-training to learn semantic lexicons
%G English
%0 Conference Proceedings
%X We present a bootstrapping method that uses strong syntactic heuristics to learn semantic lexicons. The three sources of information are appositives, compound nouns, and ISA clauses. We apply heuristics to these syntactic structures, embed them in a bootstrapping architecture, and combine them with co-training. Results on WSJ articles and a pharmaceutical corpus show that this method obtains high precision and finds a large number of terms.
%I ASSOCIATION COMPUTATIONAL LINGUISTICS
%C PO BOX 6090, SOMERSET, NJ 08875 USA
%D 2002


%A Beimel, A
%A Bergadano, F
%A Bshouty, NH
%A Kushilevitz, E
%A Varricchio, S
%T Learning functions represented as multiplicity automata
%G English
%0 Journal Article
%X We study the learnability of multiplicity automata in Angluin's exact learning model, and we investigate its applications. Our starting point is a known theorem from automata theory relating the number of states in a minimal multiplicity automaton for a function to the rank of its Hankel matrix. With this theorem in hand, we present a new simple algorithm for learning multiplicity automata with improved time acid query complexity, and we prove the learnability of various concept classes. These include (among others): The class of disjoint DNF, and more generally satisfy-O(1) DNF. The class of polynomials over finite fields. The class of bounded-degree polynomials over infinite fields. The class of XOR of terms. Certain classes of boxes in high dimensions. In addition, we obtain the best query complexity for several classes known to be learnable by other methods such as decision trees and polynomials over GF(2). While multiplicity automata are shown to be useful to prove the learnability of some subclasses of DNF formulae and various other classes, we study the limitations of this method. We prove that this method cannot be used to resolve the learnability of some other open problems such as the learnability of general DNF formulas or even k-term DNF for k = omega(log n) or satisfy-s DNF formulas for s = omega(1). These results are proven by exhibiting functions in the above classes that require multiplicity automata with super-polynomial number of states.
%I ASSOC COMPUTING MACHINERY
%C 2 PENN PLAZA, STE 701, NEW YORK, NY 10121-0701 USA
%D 2000
%V 47
%R 10.1145/337244.337257


%A Aslam, J
%A Pelekhov, K
%A Rus, D
%T A practical clustering algorithm for static and dynamic information organization
%G English
%0 Conference Proceedings
%X We present and analyze the off-line star algorithm for clustering static information systems and the on-line star algorithm for clustering dynamic information systems. These algorithms organize a document collection into a number of clusters that is naturally induced by the collection via a computationally efficient cover by dense subgraphs. Mie further show a lower bound on the accuracy of the clusters produced by these algorithms as well as demonstrate that these algorithms are efficient (running times roughly linear in the size of the problem). Finally, we provide data from a number of experiments.
%I SIAM
%C 3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA
%D 1999


%A Ganti, V
%A Ramakrishnan, R
%A Gehrke, J
%A Powell, A
%A French, J
%E Kitsuregawa, M
%E Maciaszek, L
%E Papazoglou, M
%E Pu, C
%T Clustering large datasets in arbitrary metric spaces
%G English
%0 Conference Proceedings
%X Clustering partitions a collection of objects into groups called clusters, such that similar objects fall into the same group. Similarity between objects is defined by a distance function satisfying the triangle inequality; this distance function along with the collection of objects describes a distance space. In a distance space, the only operation possible on data objects is the computation of distance between them. All scalable algorithms in the literature assume a special type of distance space, namely a k-dimensional vector space, which allows vector operations on objects. We present two scalable algorithms designed for clustering very large datasets in distance spaces. Our first algorithm BUBBLE is, to our knowledge, the first scalable clustering algorithm for data in a distance space. Our second algorithm BUBBLE-FM improves upon BUBBLE by reducing the number of calls to the distance function, which may be computationally very expensive. Both algorithms make only a single scan over the database while producing high clustering quality In a detailed experimental evaluation, we study both algorithms in terms of scalability and quality of clustering. We also show results of applying the algorithms to a real-life dataset.
%I IEEE COMPUTER SOC
%C 10662 LOS VAQUEROS CIRCLE, PO BOX 3014, LOS ALAMITOS, CA 90720-1264 USA
%D 1999
%R 10.1109/ICDE.1999.754966


%A ASLAM, JA
%A DECATUR, SE
%T GENERAL BOUNDS ON STATISTICAL QUERY LEARNING AND PAC LEARNING WITH NOISE VIA HYPOTHESIS BOOSTING
%G English
%0 Conference Proceedings
%I I E E E, COMPUTER SOC PRESS
%C 10662 LOS VAQUEROS CIRCLE, LOS ALAMITOS, CA 90720
%D 1993


%A Fujii, A
%A Ishikawa, T
%E White, JS
%T Applying machine translation to two-stage cross-language information retrieval
%G English
%0 Journal Article
%X Cross-language information retrieval (CLIR), where queries and documents are in different languages, needs a translation of queries and/or documents, so as to standardize both of them into a common representation. For this purpose, the use of machine translation is an effective approach. However, computational cost is prohibitive in translating large-scale document collections. To resolve this problem, we propose a two-stage CLIR method. First, we translate a given query into the document language, and retrieve a limited number of foreign documents. Second, we machine translate only those documents into the user language, and re-rank them based on the translation result. We also show the effectiveness of our method by way of experiments using Japanese queries and English technical documents.
%I SPRINGER-VERLAG BERLIN
%C HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
%D 2000
%V 1934


%A Nie, JY
%A Brisebois, M
%A Lepage, F
%T Information retrieval as counterfactual
%G English
%0 Journal Article
%X Relevance, one of the fundamental notions in information retrieval (IR), has long been studied from a cognitive point of view. It is known that relevance depends not only on the topic of the document and the information need expressed in a query, but also on other 'situational' factors in the retrieval situation, such as the user's previous knowledge, background, intentions and so on. Formal models, on the other hand, usually consider relevance from a system point of view, i.e. they isolate relevance in a restricted context in which only the topic matters. One of the reasons for this very partial modeling is due to the inappropriateness of standard formal tools for describing relevance in a general context. This paper is an attempt to identify a more appropriate logical framework for the modeling. Counterfactual conditional logic is examined with respect to the IR requirements, indicating the logic's high potential value for this task. A particular conditional logic is then defined which, in comparison with previous developments on conditional logic, is better suited to IR. The new model gives an insight into the phenomena related to the 'situational' factors of relevance judgment which, until now, have not been considered.
%I CAMBRIDGE UNIV PRESS
%C 40 WEST 20TH STREET, NEW YORK, NY 10011-4211
%D 1995
%V 38
%R 10.1093/comjnl/38.8.643


%A RILOFF, E
%T AUTOMATICALLY CONSTRUCTING A DICTIONARY FOR INFORMATION EXTRACTION TASKS
%G English
%0 Conference Proceedings
%X Knowledge-based natural language processing systems have achieved good success with certain tasks but they are often criticized because they depend on a domain-specific dictionary that requires a great deal of manual knowledge engineering. This knowledge engineering bottleneck makes knowledge-based NLP systems impractical for real-world applications because they cannot be easily scaled up or ported to new domains. In response to this problem, we developed a system called AutoSlog that automatically builds a domain-specific dictionary of concepts for extracting information from text. Using AutoSlog, we constructed a dictionary for the domain of terrorist event descriptions in only 5 person-hours. We then compared the AutoSlog dictionary with a hand-crafted dictionary that was built by two highly skilled graduate students and required approximately 1500 person-hours of effort. We evaluated the two dictionaries using two blind test sets of 100 texts each. Overall, the AutoSlog dictionary achieved 98% of the performance of the hand-crafted dictionary. On the first test set, the AutoSlog dictionary obtained 96.3% of the performance of the hand-crafted dictionary. On the second test set, the overall scores were virtually indistinguishable with the AutoSlog dictionary achieving 99.7% of the performance of the handcrafted dictionary.
%I M I T PRESS
%C 55 HAYWARD ST, CAMBRIDGE, MA 02142
%D 1993


%A Tzanetakis, G
%A Ermolinskyi, A
%A Cook, P
%T Pitch histograms in audio and symbolic music information retrieval
%G English
%0 Journal Article
%X In order to represent musical content, pitch and timing information is utilized in the majority of existing work in Symbolic Music Information Retrieval (MIR). Symbolic representations such as MIDI allow the easy calculation of such information and its manipulation. In contrast, most of the existing work in Audio MIR uses timbral and beat information, which can be calculated using automatic computer audition techniques. In this paper, Pitch Histograms are defined and proposed as a way to represent the pitch content of music signals both in symbolic and audio form. This representation is evaluated in the context of automatic musical genre classification. A multiple-pitch detection algorithm for polyphonic signals is used to calculate Pitch Histograms for audio signals. In order to evaluate the extent and significance of errors resulting from the automatic multiple-pitch detection, automatic musical genre classification results from symbolic and audio data are compared. The comparison indicates that Pitch Histograms provide valuable information for musical genre classification. The results obtained for both symbolic and audio cases indicate that although pitch errors degrade classification performance for the audio case, Pitch Histograms can be effectively used for classification in both cases.
%I SWETS ZEITLINGER PUBLISHERS
%C P O BOX 825, 2160 SZ LISSE, NETHERLANDS
%D 2003
%V 32
%R 10.1076/jnmr.32.2.143.16743


%A Riloff, E
%A Jones, R
%T Learning dictionaries for information extraction by multi-level bootstrapping
%G English
%0 Conference Proceedings
%X Information extraction systems usually require two dictionaries: a semantic lexicon and a dictionary of extraction patterns for the domain. We present a multilevel bootstrapping algorithm that generates both the semantic lexicon and extraction patterns simultaneously. As input, our technique requires only unannotated training texts and a handful of seed words for a category. We use a mutual bootstrapping technique to alternately select the best extraction pattern for the category and bootstrap its extractions into the semantic lexicon, which is the basis for selecting the next extraction pattern. To make this approach more robust, we add a second level of bootstrapping (metabootstrapping) that retains only the most reliable lexicon entries produced by mutual bootstrapping and then restarts the process. We evaluated this multilevel bootstrapping technique on a collection of corporate web pages and a corpus of terrorism news articles. The algorithm produced high-quality dictionaries for several semantic categories.
%X Information extraction systems usually require two dictionaries: a semantic lexicon and a dictionary of extraction patterns for the domain. We present a multilevel bootstrapping algorithm that generates both the semantic lexicon and extraction patterns simultaneously. As input, am technique requires only unannotated training texts and a handful of seed words for a category. We use a mutual bootstrapping technique to alternately select the best extraction pattern for the category and bootstrap its extractions into the semantic lexicon, which is the basis far selecting the next extraction pattern. To make this approach more robust, we add a second level of bootstrapping (metabootstrapping) that retains only the most reliable lexicon entries produced by mutual bootstrapping and then restarts the process. We evaluated this multilevel bootstrapping technique on a collection of corporate web pages and a corpus of terrorism news articles. The algorithm produced high-quality dictionaries for several semantic categories.
%I AMER ASSOC ARTIFICIAL INTELLIGENCE
%C 445 BURGESS DR, MENLO PK, CA 94025 USA
%D 1999


%A Beimel, A
%A Stahl, Y
%E Cimato, S
%E Galdi, C
%E Persiano, G
%T Robust information-theoretic private information retrieval
%G English
%0 Journal Article
%X A Private Information Retrieval (PIR) protocol allows a user to retrieve a data item of its choice from a database, such that the servers storing the database do not gain information on the identity of the item being retrieved. PIR protocols were studied in depth since the subject was introduced in Chor, Goldreich, Kushilevitz, and Sudan 1995. The standard definition of PIR protocols raises a simple question - what happens if some of the servers crash during the operation? How can we devise a protocol which still works in the presence of crashing servers? Current systems do not guarantee availability of servers at all times for many reasons, e.g., crash of server or communication problems. Our purpose is to design robust PIR protocols, i.e., protocols which still work correctly even if only k out of E servers are available during the protocols' operation (the user does not know in advance which servers are available). We present various robust PIR protocols giving different tradeoffs between the different parameters. These protocols are incomparable, i.e., for different values of n and k we will get better results using different protocols. We first present a generic transformation from regular PIR protocols to robust PIR protocols, this transformation is important since any improvement in the communication complexity of regular PIR protocol will immediately implicate improvement in the robust PIR protocol communication. We also present two specific robust PIR protocols. Finally, we present robust PIR protocols which can tolerate Byzantine servers, i.e., robust PIR protocols which still work in the presence of malicious servers or servers with corrupted or obsolete databases.
%I SPRINGER-VERLAG BERLIN
%C HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
%D 2003
%V 2576


%A Beimel, A
%A Ishai, Y
%T On the power of nonlinear secret-sharing
%G English
%0 Journal Article
%X A secret-sharing scheme enables a dealer to distribute a secret among n parties such that only some predefined authorized sets of parties will be able to reconstruct the secret from their shares. The ( monotone) collection of authorized sets is called an access structure, and is freely identified with its characteristic monotone function f : {0, 1} n. {0, 1}. A family of secret-sharing schemes is called efficient if the total length of the n shares is polynomial in n. Most previously known secret-sharing schemes belonged to a class of linear schemes, whose complexity coincides with the monotone span program size of their access structure. Prior to this work there was no evidence that nonlinear schemes can be significantly more efficient than linear schemes, and in particular there were no candidates for schemes efficiently realizing access structures which do not lie in NC. The main contribution of this work is the construction of two efficient nonlinear schemes: ( 1) A scheme with perfect privacy whose access structure is conjectured not to lie in NC, and ( 2) a scheme with statistical privacy whose access structure is conjectured not to lie in P/poly. Another contribution is the study of a class of nonlinear schemes, termed quasi-linear schemes, obtained by composing linear schemes over different fields. While these schemes are (superpolynomially) more powerful than linear schemes, we show that they cannot efficiently realize access structures outside NC.
%I SIAM PUBLICATIONS
%C 3600 UNIV CITY SCIENCE CENTER, PHILADELPHIA, PA 19104-2688 USA
%D 2005
%V 19
%R 10.1137/S0895480102412868


%A Riloff, E
%T Automatically generating extraction patterns from untagged text
%G English
%0 Conference Proceedings
%X Many corpus-based natural language processing systems rely on text corpora that have been manually annotated with syntactic or semantic tags. In particular, all previous dictionary construction systems for information extraction have used an annotated training corpus or some form of annotated input. We have developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text. AutoSlog-TS is based on the AutoSlog system, which generated extraction patterns using annotated text and a set of heuristic rules. By adapting AutoSlog and combining it with statistical techniques, we eliminated its dependency on tagged text. In experiments with the MUC-4 terrorism domain, AutoSlogTS created a dictionary of extraction patterns that performed comparably to a dictionary created by AutoSlog, using only preclassified texts as input.
%I AMER ASSOC ARTIFICIAL INTELLIGENCE
%C 445 BURGESS DR, MENLO PK, CA 94025 USA
%D 1996


%A Zhang, ZF
%A Srihari, RK
%T Subspace morphing theory for appearance based object identification
%G English
%0 Journal Article
%X Object identification techniques have wide applications ranging from industry, business, military, law enforcement, to people's daily life. This research is motivated to develop a new theory for appearance based object identification with its applications in different areas. Although many successful techniques have been proposed in certain specific applications, object identification, in general, still remains as a difficult and challenging problem. In appearance based approaches, almost all the proposed methods are based on a fundamental assumption, i.e., all the images (both in the model base and to be queried) are in the same dimensions, so that the feature vectors are all in the same feature space; if images are provided with different dimensions, a normalization in scale to a pre-determined image space must be conducted. In this research, a theory for appearance based object identification called subspace morphing is developed, which allows scale-invariant identification of images of objects, and therefore, does not require normalization. Theoretical analysis and experimental evaluation show that in the situation where images are provided in different dimensions, which is common in many applications, subspace morphing theory is superior to the existing, normalization-based techniques in performance. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.
%I PERGAMON-ELSEVIER SCIENCE LTD
%C THE BOULEVARD, LANGFORD LANE, KIDLINGTON, OXFORD OX5 1GB, ENGLAND
%D 2002
%V 35


%A Beimel, A
%A Ishai, Y
%E Orejas, F
%E Spirakis, PG
%E VanLeeuwen, J
%T Information-theoretic private information retrieval: A unified construction - (Extended abstract)
%G English
%0 Journal Article
%X A Private Information Retrieval (PIR) protocol enables a user to retrieve a data item from a database while hiding the identity of the item being retrieved. In a t-private, k-server PIR protocol the database is replicated among k servers, and the user's privacy is protected from any collusion of up to t servers. The main cost-measure of such protocols is the communication complexity of retrieving a single bit of data. This work addresses the information-theoretic setting for PIR, in which the user's privacy should be unconditionally protected from collusions of servers. We present a unified general construction, whose abstract components can be instantiated to yield both old and new families of PIR protocols. A main ingredient in the new protocols is a generalization of a solution by Babai, Kimmel, and Lokam to a communication complexity problem in the so-called simultaneous messages model. Our construction strictly improves upon previous constructions and resolves some previous anomalies. In particular, we obtain: (1) t-private k-server PIR protocols with O(n(1/[(2k-1)/t])) communication bits, where n is the database size. For t > 1, this is a substantial asymptotic improvement over the previous state of the art; (2) a constant-factor improvement in the communication complexity of 1-private PIR, providing the first improvement to the 2-server case since PIR protocols were introduced; (3) efficient PIR protocols with logarithmic query length. The latter protocols have applications to the construction of efficient families of locally decodable codes over large alphabets and to PIR protocols with reduced work by the servers.
%I SPRINGER-VERLAG BERLIN
%C HEIDELBERGER PLATZ 3, D-14197 BERLIN, GERMANY
%D 2001
%V 2076


%0 Conference Proceedings
%T Feature construction with inductive logic programming: A study of quantitative predictions of biological activity by structural attributes
%A Srinivasan, Ashwin
%A King, Ross.D.
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_50
%X Recently, computer programs developed within the field of Inductive Logic Programming (ILP) have received some attention for their ability to construct restricted first-order logic solutions using problemspecific background knowledge. Prominent applications of such programs have been concerned with determining âstructure-activityâ relationships in the areas of molecular biology and chemistry. Typically the task here is to predict the âactivityâ of a compound, like toxicity, from its chemical structure. Research in the area shows that: (a) ILP programs have been restricted to qualitative predictions of activity (âhighâ, âlowâ etc.); (b) When appropriate attributes are available, ILP programs have not been able to better the performance of standard quantitative analysis techniques like linear regression. However ILP programs perform creditably when such attributes are unavailable; and (c) When both are applicable, ILP programs are usually slower than their propositional counterparts. This paper examines the use of ILP programs, not for obtaining theories complete for the sample, but as a method of âdiscoveringâ new attributes. These could then be used by methods like linear regression, thus allowing for quantitative predictions and the ability to use structural information as background knowledge. Using structure-activity tasks as a test-bed the utility of ILP programs in constructing new features was evaluated by examining the prediction of chemical activity using linear regression, with and without the aid of ILP learnt logical attributes. In three out of the five datasets examined the addition of ILP attributes produced statistically better results (P 10.01). In addition six important structural features that have escaped the attention of the expert chemists were discovered.
%P 89-104


%0 Conference Proceedings
%T Efficient proof encoding
%A Pompe, UroÅ¡
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_62
%X This paper proposes a method of storing the proofs of the learning examples in an efficient manner. FOIL-like top down learners usually store the computed answers of a partially induced clause as a set of ground substitutions. The need for the re-computation of the root part of the SLDNF-tree is reduced that way, but the approach is spaceinefficient when the literals in the clause are nondeterminate. We introduce a weak syntactic language bias that does not practically restrict the hypothesis space. Further more, we present a proof encoding scheme, using a mesh-like data structure, that exploits the properties of this bias to store the computed answers efficiently. We show that such encoding grows at most linearly with respect to the clause length. The result is not influenced by the presence of nondeterminism in the background knowledge.
%P 299-314


%0 Conference Proceedings
%T A stochastic simple similarity
%A Sebag, MichÃ¨le
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027313
%X This paper continues a previous work using stochastic heuristics to extract and exploit knowledge with no size restrictions, with polynomial complexity.
%P 95-105


%0 Conference Proceedings
%T Case-based reasoning for information system design
%A Krampe, Dirk
%A Lusti, Markus
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_479
%X We present a process model that applies case-based reasoning techniques to information system design. Describing the process model we focus on similarity and case adaption aspects. We are currently implementing the process model in a research prototype called CBModeler.
%P 63-73


%0 Conference Proceedings
%T Scalable information organization
%D 2000
%A Aslam, Javed A.
%A Reiss, Fred R.
%A Rus, Daniela
%X We present three scalable extensions of the star algorithm for information organization that use sampling. The star algorithm organizes a document collection into clusters that are naturally induced by the topic structure of collection, via a computationally efficient cover by dense subgraphs. We also provide supporting data from extensive experiments. 

%0 Conference Proceedings
%T PROFIL: A decision support tool for metallic sections design using a CBR approach
%A Wybo, Jean Luc
%A Geffraye, FrÃ©deric
%A Russeil, Aline
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_4
%X This paper presents the PROFIL system, a Decision Support Tool for the Design of metallic sections production. The PROFIL system uses a Case-Based Reasoning approach for the selection of pertinent former designs.
%P 33-42


%0 Conference Proceedings
%T Handling Quantifiers in ILP
%A Goncalves, M. -Elisabeth
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_64
%X An important research area in the field of Inductive Logic Programming (ILP) is concerned with predicate learning. Recently, many predicate learners have been developed whose task consists in learning a definition of a concept from positive and negative examples. In most of them, the definition of the concept is represented by a set of definite (or normal) clauses. The variables that appear in the head of a clause (the head-variables) are universally quantified, and the variables that appear only in the body of the clause (the body-variables) are existentially quantified. Some predicate learners described in the ILP literature are able to deal with such existential (body-)variables, using some language bias like ij-determinacy (see [11]). However, as far as the authors know, no ILP system is able to deal with clauses in whose body both existential and universal body-variables appear. Moreover, there exists no generalisation and no specialisation operator that handle such body-variables.
%P 337-357


%0 Conference Proceedings
%T The Use of a Uniform Declarative Model in 3D Visualisation for Case-Based Reasoning
%A Falkman, GÃ¶ran
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_9
%X We present an information visualisation tool, The Cube, as a solution to the problem of visualising cases derived from large amounts of clinical data. The Cube is based on the idea of dynamic 3D parallel diagrams, an idea similar to the notion of 3D parallel coordinate plots. The Cube was developed to provide interactive visualisation of the case base in terms of relationships between and within cases, in order to enhance the clinicianâs ability to intelligibly analyse existing patient material and to allow for pattern recognition and statistical analysis.
%P 103-117


%0 Conference Proceedings
%T Analysis of the Evolution of PeerÂ­toÂ­Peer Systems
%D 2002  
%A Liben-Nowell, David
%A Balakrishnan, Hariharan
%A Karger, David R.
%X In this paper, we give a theoretical analysis of peer-to-peer (P2P) networks operating in the face of concurrent joins and unexpected departures. We focus on Chord, a recently developed P2P system that implements a distributed hash table abstraction, and study the process by which Chord maintains its distributed state as nodes join and leave the system. We argue that traditional performance measures based on run-time are uninformative for a continually running P2P network, and that the rate at which nodes in the network need to participate to maintain system state is a more useful metric. We give a general lower bound on this rate for a network to remain connected, and prove that an appropriately modified version of Chord's maintenance rate is within a logarithmic factor of the optimum rate.

%0 Conference Proceedings
%T Poetry Generation in COLIBRI
%A DÃ­az-Agudo, BelÃ©n
%A GervÃ¡s, Pablo
%A GonzÃ¡lez-Calero, Pedro A.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_7
%X CBROnto is an ontology that incorporates common Case-Based Reasoning (CBR) terminology and serves as a domain-independent framework to design CBR applications. It is the core of COLIBRI, an environment to assist during the design of knowledge intensive CBR systems that combine cases with various knowledge types and reasoning methods. CBROnto captures knowledge about CBR tasks and methods, and aims to unify case specific and general domain knowledge representational needs. CBROnto specifies a modelling framework to describe reusable CBR Problem Solving Methods based on the CBR tasks they solve. This paper describes CBROntoâs main ideas and exemplifies them with an application to generate Spanish poetry versions of texts provided by the user.
%P 73-87


%0 Conference Proceedings
%T Diverse Product Recommendations Using an Expressive Language for Case Retrieval
%A Bridge, Derek
%A Ferguson, Alex
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_5
%X We describe Order-Based Retrieval, which is an approach to case retrieval based on the application of partial orders to the case base. We argue that it is well-suited to product recommender applications because, as well as retrieving products that best match customer-specified âidealâ attribute-values, it also: allows the customer to specify soft constraints; gives a natural semantics and implementation to tweaks; and delivers an inherently diverse result set.
%P 43-57


%0 Conference Proceedings
%T Experiments in Predicting Biodegradability
%A DÅ¾eroski, SaÅ¡o
%A Blockeel, Hendrik
%A Kompare, Boris
%A Kramer, Stefan
%A Pfahringer, Bernhard
%A Van Laer, Wim
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_9
%X We present a novel application of inductive logic programming (ILP) in the area of quantitative structure-activity relationships (QSARs). The activity we want to predict is the biodegradability of chemical compounds in water. In particular, the target variable is the half-life in water for aerobic aqueous biodegradation. Structural descriptions of chemicals in terms of atoms and bonds are derived from the chemicalsâ SMILES encodings. Definition of substructures are used as background knowledge. Predicting biodegradability is essentially a regression problem, but we also consider a discretized version of the target variable. We thus employ a number of relational classification and regression methods on the relational representation and compare these to propositional methods applied to different propositionalisations of the problem. Some expert comments on the induced theories are also given.
%P 80-91


%0 Conference Proceedings
%T Understanding creativity: A case-based approach
%A Kolodner, Janet L.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_73
%X Dissatisfaction with existing standard case-based reasoning (CBR) systems has prompted us to investigate how we can make these systems more creative and, more broadly, what would it mean for them to be more creative. This paper discusses three research goals: understanding creative processes better, investigating the role of cases and CBR in creative problem solving, and understanding the framework that supports this more interesting kind of case-based reasoning. In addition, it discusses methodological issues in the study of creativity and, in particular, the use of CBR as a research paradigm for exploring creativity.
%P 1-20


%0 Conference Proceedings
%T Surfing the Digital Wave
%A Smyth, Barry
%A Cotter, Paul
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_41
%X In the future digital TV will offer an unprecedented level of programme choice. We are told that this will lead to dramatic increases in viewer satisfaction as all viewing tastes are catered for all of the time. However, the reality may be somewhat different. We have not yet developed the tools to deal with this increased level of choice (for example, conventional TV guides will be virtually useless), and viewers will face a significant and frustrating information overload problem. This paper describes a solution in the form of the PTV system. PTV employs user profiling and information filtering techniques to generate web-based TV viewing guides that are personalised for the viewing preferences of individual users. The paper explains how PTV constructs graded user profiles to drive a hybrid recommendation technique, combining case-based and collaborative information filtering methods. The results of an extensive empirical study to evaluate the quality of PTVâs casebased and collaborative filtering strategies are also described.
%P 561-571


%0 Conference Proceedings
%T Operator decision aiding by adaptation of supervision strategies
%A Fuchs, BÃ©atrice
%A Mille, Alain
%A Chiron, BenoÃ®t
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_3
%X This paper presents a CBR application in the domain of industrial supervision. The domain knowledge is acquired at design stage through different models and some critical prototypical situations. At operating stage, new situations and their associated supervision strategy complete the supervision system and are reused by adaptation in later situations in similar contexts. The system can be viewed as an artificial operator who collects experiences from the operators in order to propose relevant variants in similar situations. First, we present current approaches in process supervision. Then, knowledge and cases representation that support case-based reasoning and the different stages of the reasoning process are presented. We focus on case adaptation, and show different degrees of case reuse, depending on available knowledge.
%P 23-32


%0 Conference Proceedings
%T When Experience is Wrong: Examining CBR for Changing Tasks and Environmentsâ
%A Leake, David B.
%A Wilson, David C.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_16
%X Case-based problem-solving systems reason and learn from experiences, building up case libraries of problems and solutions to guide future reasoning. The expected benefits of this learning process depend on two types of regularity: (1) problem-solution regularity, the relationship between problem-to-problem and solution-to-solution similarity measures that assures that solutions to similar prior problems are a useful starting point for solving similar current problems, and (2) problem-distribution regularity, the relationship between old and new problems that assures that the case library will contain cases similar to the new problems it encounters. Unfortunately, these types of regularity are not assured. Even in contexts for which initial regularity is sufficient, problems may arise if a systemâs users, tasks, or external environment change over time. This paper defines criteria for assessing the two types of regularity, discusses how the definitions may be used to assess the need for case-base maintenance, and suggests maintenance approaches for responding to those needs. In particular, it discusses the role of analysis of performance over time in responding to environmental changes.
%P 218-232


%0 Conference Proceedings
%T Some Properties of Inverse Resolution in Normal Logic Programs
%A Sakama, Chiaki
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_26
%X This paper studies the properties of inverse resolution in normal logic programs. The V-operators are known as operations for inductive generalization in definite logic programs. In the presence of negation as failure in a program, however, the V-operators do not work as generalization operations in general and often make a consistent program inconsistent. Moreover, they may destroy the syntactic structure of logic programs such as acyclicity and local stratification. On the procedural side, unrestricted application of the V-operators may lose answers computed in the original program and make queries flounder. We provide sufficient conditions for the V-operators to avoid these problems.
%P 279-290


%0 Conference Proceedings
%T Bootstrapping Case Base Development with Annotated Case Summariesâ
%A BrÃ¼ninghaus, Stefanie
%A Ashley, Kevin D.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_5
%X Since assigning indicies to textual cases is very time-consuming and can impede the development of CBR systems, methods to automate the task are desirable. In this paper,we present amachine learning approach that helps to bootstrap the development of a larger case base from a small collection of marked-up case summaries. It uses the marked-up sentences as training examples to induce a classifier that labels incoming cases whether an indexing concept applies. We illustrate how domain knowledge and linguistic information can be integrated with amachine learning algorithm to improve performance.The paper presents experimental resultswhich indicate the usefulness of learning from sentences and adding a thesaurus.We also consider the chancesand limitations of leveraging the learned classifiers for full-text documents.
%P 59-73


%0 Conference Proceedings
%T Similarity metrics: A formal unification of cardinal and non-cardinal similarity measures
%A Osborne, Hugh
%A Bridge, Derek
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_495
%X In [9] we introduced a formal framework for constructing ordinal similarity measures, and suggested how this might also be applied to cardinal measures. In this paper we will place this approach in a more general framework, called similarity metrics. In this framework, ordinal similarity metrics (where comparison returns a boolean value) can be combined with cardinal metrics (returning a numeric value) and, indeed, with metrics returning values of other types, to produce new metrics.
%P 235-244


%0 Conference Proceedings
%T A New Approach to Solution Adaptation and Its Application for Design Purposes
%A Hejazi, Mahmoudreza
%A Badie, Kambiz
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_40
%X In this paper, a new approach is proposed for transformational adaptation based on detecting a solutionâs incompatibility regarding the new problem situation and trying to overcome the incompatibility in an iterative manner. By incompatibility, we mean a state for which the required objectives are not satisfied due to any change in the status of the constraints. Based upon this approach, we have proposed a framework for redesigning an existing system under new constraints. To show the capability of this framework, a software prototype was developed that it is capable of redesigning an existing digital circuit under presence of new constraints, e.g. type of gates, power dissipation, fan in/out, gate prices and so on.
%P 549-559


%0 Conference Proceedings
%T INRECA: A seamlessly integrated system based on inductive inference and case-based reasoning
%A Auriol, E.
%A Wess, S.
%A Manago, M.
%A Althoff, K. D.
%A TraphÃ¶ner, R.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_33
%X This paper focuses on integrating inductive inference and case-based reasoning. We study integration along two dimensions: Integration of case-based methods with methods based on general domain knowledge, and integration of problem solving and incremental learning from experience. In the Inreca system, we perform case-based reasoning as well as tdidt (Top-Down Induction of Decision Trees) classification by using the same data structure called the Inreca tree. We extract decision knowledge using a tdidt algorithm to improve both the similarity assessment by determining optimal weights, and the speed of the overall system by inductive learning. The integrated system we implemented evolves smoothly along application development time from a pure case-based reasoning approach, where each particular case is a piece of knowledge, to a more inductive approach where some subsets of the cases are generalised into abstract knowledge. Our proposed approach is driven by the needs of a concrete pre-commercial system and real diagnostic applications. We evaluate the system on a database of insurance risk for cars and an application involving forestry management in Ireland.
%P 371-380


%0 Conference Proceedings
%T N â« 2: multi-speaker display systems for virtual reality and spatial audio projection
%D 1998
%A Cook, Perry R.
%A Essl, Georg
%A Tzanetakis, Georgos
%A Trueman, Dan
%X This paper describes multi-speaker display systems for immersive auditory environments, collaborative projects, realistic acoustic modeling, and live musical performance. Two projects are described. The sound sub-system of the Princeton Display Wall project, and the NBody musical instrument body radiation response project. The Display Wall is an 18' Ã 8' rear-projection screen, illuminated by 8 high-resolution video projectors. Each projector is driven by a 4-way symmetric-multi-processor PC. The audio sub-system of this project involves 26 loudspeakers and server PCs to drive the speakers in real time from soundfile playback, audio effects applied to incoming audio streams, and parametric sound synthesis. The NBody project involves collecting and using directional impulse responses from a variety of stringed musical instruments. Various signal processing techniques were used to investigate, factor, store, and implement the collected impulse responses. A software workbench was created which allows virtual microphones to be placed around a virtual instrument, and then allows signals to be processed through the resulting derived transfer functions. Multi-speaker display devices and software programs were constructed which allow real-time application of of the filter functions to arbitrary sound sources. This paper also discusses the relation of spherical display systems to conventional systems in terms of spatial audio and sound-field reconstruction, with the conclusion that most conventional techniques can be used for spherical display systems as well.

%0 Conference Proceedings
%T Supporting Electronic Design Reuse by Integrating Quality-Criteria into CBR-Based IP Selection
%A Schaaf, Martin
%A Maximini, Rainer
%A Bergmann, Ralph
%A Tautz, Carsten
%A TraphÃ¶ner, Ralph
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_46
%X The growing complexity of todayâs electronic designs requires reusing existing design components, called Intellectual Properties (IPs). Experience management approaches can be used to support design reuse, particularly the process of selecting reusable IPs. For the IP selection, quality criteria concerning the IP code and the documentation must be considered in addition to functional requirements of the IP. We analyse IP quality criteria in detail and show different concepts for their integration into the retrieval process.
%P 628-641


%0 Conference Proceedings
%T Refining Complete Hypotheses in ILP
%A Bratko, Ivan
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_6
%X Most ILP systems employ the covering algorithm whereby hypotheses are constructed iteratively clause by clause. Typically the covering algorithm is greedy in the sense that each iteration adds the best clause according to some local evaluation criterion. Some typical problems of the covering algorithm are: unnecessarily long hypotheses, difficulties in handling recursion, difficulties in learning multiple predicates. This paper investigates a non-covering approach to ILP, implemented as a Prolog program called HYPER, whose goals were: use intensional background knowledge, handle recursion well, and enable multi-predicate learning. Experimental results in this paper may appear surprising in the view of the very high combinatorial complexity of the search space associated with the non-covering approach.
%P 44-55


%0 Conference Proceedings
%T Creative design: Reasoning and understanding
%A Simina, Marin
%A Kolodner, Janet
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_527
%X This paper investigates memory issues that influence longterm creative problem solving and design activity, taking a case-based reasoning perspective. Our exploration is based on a well-documented example: the invention of the telephone by Alexander Graham Bell. We abstract Bell's reasoning and understanding mechanisms that appear time and again in long-term creative design. We identify that the understanding mechanism is responsible for analogical anticipation of design constraints and analogical evaluation, beside case-based design. But an already understood design can satisfy opportunistically suspended design problems, still active in background. The new mechanisms are integrated in a computational model, ALEC1, that accounts for some creative behavior in case-based design.
%P 587-598


%0 Conference Proceedings
%T Linguistic Annotation for the Semantic Web
%D 2003
%A Buitelaar, Paul
%A Declerck, Thierry
%X Establishing the semantic web on a large scale implies the widespread annotation of web documents with ontology-based knowledge markup. For this purpose, tools have been developed that allow for semi-automatic annotation of web documents with ontology-based metadata. However, given that a large number of web documents consist either fully or at least partially of free text, language technology tools will be needed to support this authoring process by providing an automatic analysis of the semantic structure of textual documents. In this way, free text documents will become available as semi-structured documents, from which meaningful units can be extracted automatically (information extraction) and organized through clustering or classification (text mining). Obviously, this is of importance for both knowledge markup and ontology development, i.e. the dynamic adaptation of ontologies to evolving applications and domains. In this paper we present the following linguistic analysis steps that underlie both of these: morphological analysis, part-of-speech tagging, chunking, dependency structure analysis, semantic tagging. Examples for each are given in the context of two projects that use linguistic and semantic annotation for the purpose of cross-lingual information retrieval and content-based multimedia access.

%0 Conference Proceedings
%T Case-based reasoning for network management
%A Stadler, Michael
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_104
%X Even though today case-based reasoning is applied in a wide range of different areas, there are only few systems which make use of case-based techniques for network management. In this paper, we outline the domain of network management and highlight consequences for the application of problem solvers operating in this domain. After this, we present a case-based prototype performing a task of closed-loop network management upon a simulated computer network together with first results.
%P 414-423


%0 Conference Proceedings
%T Hierarchical PowerÂ­-aware Routing in Sensor Networks
%D 2001
%A Li, Qun
%A Aslam, Javed
%A Rus, Daniela
%X This paper discusses online power-aware routing in large sensor networks. We seek to optimize the lifetime of the network. We develop an approximation algorithm called max-min zPmin that has a good empirical competitive ratio. To ensure scalability, we introduce a hierarchical algorithm, which is called zone-based routing.
%0 Conference Proceedings
%T Relevance Score Normalization for Metasearch
%D 2001
%A Montague, Mark H.
%A Aslam, Javed A.
%X Given the ranked lists of documents returned by multiple search engines in response to a given query, the problem of  metasearch is to combine these lists in a way which optimizes the performance of the combination. This problem can be naturally decomposed into three subproblems: (1) normalizing the relevance scores given by the input systems, (2) estimating relevance scores for unretrieved documents, and (3) combining the newly-acquired scores for each document into one, improved score.Research on the problem of metasearch has historically concentrated on algorithms for combining (normalized) scores. In this paper, we show that the techniques used for normalizing relevance scores and estimating the relevance scores of unretrieved documents can have a significant effect on the overall performance of metasearch. We propose two new normalization/estimation techniques and demonstrate empirically that the performance of well known metasearch algorithms can be significantly improved through their use.

%0 Conference Proceedings
%T Î»-Subsumption and its application to learning from positive-only examples
%A Markov, Zdravko
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_66
%X The general aim of the present paper is to show the advantages of the model-theoretic approach to Inductive Logic Programming. The paper introduces a new generality ordering between Horn clauses, called Î»-subsumption. It is stronger than B-subsumption and weaker than generalized subsumption. Most importantly Î»-subsumption allows to compare clauses in a local sense, i.e. with respect to a partial interpretation. This allows to define a non-trivial upper bound in the Î»-subsumption lattice without the use of negative examples. An algorithm for concept learning from positive-only examples, based on these ideas, is described and its performance is empirically evaluated in the paper.
%P 377-396


%0 Journal Article
%T MULTIFEATURE AUDIO SEGMENTATION FOR BROWSING AND ANNOTATION
%D 1999 
%A PrincetonUniversity, ComputerScienceDepartment
%A PrincetonUniversity, ComputerScienceandMusicDeptartment
%J Proceedings of the 1999 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics. WASPAA'99 (Cat. No.99TH8452)
%X Indexing and content-based retrieval are necessary to handle the large amounts of audio and multimedia data that is becoming available on the Web and elsewhere. Since manual indexing using existing audio editors is extremely time consuming a number of automatic content analysis systems have been proposed. Most of these systems rely on speech recognition techniques to create text indices. On the other hand, very few systems have been proposed for automatic indexing of music and general audio. Typically these systems rely on classification and similarity-retrieval techniques and work in restricted audio domains. A somewhat different, more general approach for fast indexing of arbitrary audio data is the use of segmentation based on multiple temporal features combined with automatic or semi-automatic annotation. In this paper, a general methodology for audio segmentation is proposed. A number of experiments were performed to evaluate the proposed methodology and compare different segmentation schemes. Finally, a prototype audio browsing and annotation tool based on segmentation combined with existing classification techniques was implemented. 



%0 Conference Proceedings
%T Reducing Lexical Semantic Complexity with Systematic Polysemous Classes and Underspecification
%D 2000
%A Buitelaar, Paul
%X This paper presents an algorithm for finding systematic polysemous classes in WordNet and similar semantic databases, based on a definition in (Apresjan 1973). The introduction of systematic polysemous classes can reduce the amount of lexical semantic processing, because the number of disambiguation decisions can be restricted more clearly to those cases that involve real ambiguity (homonymy). In many applications, for instance in document categorization, information retrieval, and information extraction, it may be sufficient to know if a given word belongs to a certain class (underspecified sense) rather than to know which of its (related) senses exactly to pick. The approach for finding systematic polysemous classes is based on that of (Buitelaar 1998a, Buitelaar 1998b), while addressing some previous shortcomings.

%0 Conference Proceedings
%T An Unsupervised Bayesian Distance Measure
%A Kontkanen, Petri
%A Lahtinen, Jussi
%A MyllymÃ¤ki, Petri
%A Tirri, Henry
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_14
%X We introduce a distance measure based on the idea that two vectors are considered similar if they lead to similar predictive probability distributions. The suggested approach avoids the scaling problem inherent to many alternative techniques as the method automatically transforms the original attribute space to a probability space where all the numbers lie between 0 and 1. The method is also flexible in the sense that it allows different attribute types (discrete or continuous) in the same consistent framework. To study the validity of the suggested measure, we ran a series of experiments with publicly available data sets. The empirical results demonstrate that the unsupervised distance measure is sensible in the sense that it can be used for discovering the hidden clustering structure of the data.
%P 148-160


%0 Conference Proceedings
%T Using Mobile Agents for Analyzing Intrusion in Computer Networks
%D 2001
%A Aslam, Jay
%A Cremonini, Marco
%A Kotz, David
%A Rus, Daniela
%X Today hackers disguise their attacks by launching them form a set of compromised hosts distributed across the Internet. It is very difficult to defend against these attacks or to track down their origin. Commercially available intrusion detection systems can signal the occurrence of limited known types of attacks. New types of attacks are launched regularly but these tools are not effective in detecting them. Human experts are still the key tool for identifying, tracking, and disabling new attacks. Often this involves experts from many organizations working together to share their observations, hypothesis, and attack signatures. Unfortunately, today these experts have few tools that help them to automate this process. In this project we recognize that human experts will remain a critical part in the process of identifying, tracking and disabling computer attacks. We also recognize that an important part of the discovery, analysis, and defense against new distributed attacks is the cooperation that occurs between experts across different organizations. Many installations do not have the expertise necessary to develop full attack analyses. 

%0 Conference Proceedings
%T Integrating rule induction and case-based reasoning to enhance problem solving
%A An, Aijun
%A Cercone, Nick
%A Chan, Christine
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_519
%X We present a new method that integrates rule induction and case-based reasoning. The method is new in two aspects. First, it applies a novel feature weighting function for assessing similarities between cases. By using this weighting function, optimal case retrieval is achieved in that the most relevant cases can be retrieved from the case base. Second, the method handles both classification and numeric prediction tasks under a mixed paradigm of rule-based and case-based reasoning. Before problem solving, rule induction is performed to induce a set of decision rules from a set of training data. The rules are then employed to determine some parameters in the new weighting function. The induced rules are also used to detect possible noise in the training set so that noisy cases are not used in case-based reasoning. For classification tasks, rules are applied to make decisions; if there is a conflict between matched rules, case-based reasoning is performed. The method was implemented in ELEM2-CBR, a learning and problem solving system. We demonstrate the performance of ELEM2-CBR by comparing it with other methods on a number of designed and real-world problems.
%P 499-508


%0 Journal Article
%T Applying a Hybrid Query Translation Method to Japanese/English Cross-Language Patent Retrieval
%D 2002
%A Fukui, Masatoshi
%A Higuchi, Shigeto
%A Nakatani, Youichi
%A Tanaka, Masao
%A Fujii, Atsushi
%A Ishikawa, Tetsuya
%X This paper applies an existing query translation method to cross-language patent retrieval. In our method, multiple dictionaries are used to derive all possible translations for an input query, and collocational statistics are used to resolve translation ambiguity. We used Japanese/English parallel patent abstracts to perform comparative experiments, where our method outperformed a simple dictionary-based query translation method, and achieved 76% of monolingual retrieval in terms of average precision


%0 Conference Proceedings
%T Part-of-speech tagging using Progol
%A Cussens, James
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_38
%X A system for âtaggingâ words with their part-of-speech (POS) tags is constructed. The system has two components: a lexicon containing the set of possible POS tags for a given word, and rules which use a word's context to eliminate possible tags for a word. The Inductive Logic Programming (ILP) system Progol is used to induce these rules in the form of definite clauses. The final theory contained 885 clauses. For background knowledge, Progol uses a simple grammar, where the tags are terminals and predicates such as nounp (noun phrase) are non-terminals. Progol was altered to allow the caching of information about clauses generated during the induction process which greatly increased efficiency. The system achieved a per-word accuracy of 96.4% on known words drawn from sentences without quotation marks. This is on a par with other tagging systems induced from the same data [5, 2, 4] which all have accuracies in the range 96â97%. The per-sentence accuracy was 4 49.5%.
%P 93-108


%0 Conference Proceedings
%T Local Predictions for Case-Based Plan Recognition
%A Kerkez, Boris
%A Cox, Michael T.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_15
%X This paper presents a novel case-based plan recognition system that interprets observations of plan behavior using a case library of past observations. The system is novel in that it represents a plan as a sequence of action-state pairs rather than a sequence of actions preceded by some initial state and followed by some final goal state. The system utilizes a unique abstraction scheme to represent indices into the case base. The paper examines and evaluates three different methods for prediction. The first method is prediction without adaptation; the second is predication with adaptation, and the third is prediction with heuristics. We show that the first method is better than a baseline random prediction, that the second method is an improvement over the first, and that the second and the third methods combined are the best overall strategy.
%P 189-203


%0 Conference Proceedings
%T An Empirical Approach to Conceptual Case Frame Acquisition
%D 1998
%A Riloff, Ellen
%A Schmelzenbach, Mark
%X Conceptual natural language processing systems usually rely on case frame instantiation to recognize events and role objects in text. But generating a good set of case frames for a domain is timeconsuming, tedious, and prone to errors of omission. We have developed a corpus-based algorithm for acquiring conceptual case frames empirically from unannotated text. Our algorithm builds on previous research on corpus-based methods for acquiring extraction patterns and semantic lexicons. Given extraction patterns and a semantic lexicon for a domain, our algorithm learns semantic preferences for each extraction pattern and merges the syntactically compatible patterns to produce multi-slot case frames with selectional restrictions. The case frames generate more cohesive output and produce fewer false hits than the original extraction patterns. Our system requires only preclassified training texts and a few hours of manual review to filter the dictionaries, demonstrating that conceptual case frames can be acquired from unannotated text without special training resources.

%0 Conference Proceedings
%T Top-down induction of logic programs from incomplete samples
%A Inuzuka, Nobuhiro
%A Kamo, Masakage
%A Ishii, Naohiro
%A Seki, Hirohisa
%A Itoh, Hidenori
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_60
%X We propose an ILP system FOIL-I, which induces logic programs by a top-down method from incomplete samples. An incomplete sample is constituted by some of positive examples and negative examples on a finite domain. FOIL-I has an evaluation function to estimate candidate definitions, the function which is composition of an information-based function and an encoding complexity measure. FOILI uses a best-first search using the evaluation function to make use of suspicious but necessary candidates. Other particular points include a treatment for recursive definitions and removal of redundant clauses. Randomly selected incomplete samples are tested with FOIL-I, QuinIan's FOIL and Muggleton's Progol. Compared with others FOIL-I can induce target relations in many cases from small incomplete samples.
%P 265-282


%0 Conference Proceedings
%T Extraction-Based Text Categorization: Generating Domain-Specific Role Relationships Automatically
%D 1999
%A Riloff, Ellen
%A Lorenzen, Jeffrey Jay
%X In previous work, we developed several algorithms that use information extraction techniques to achieve high-precision text categorization. The relevancy signatures algorithm classifies texts using extraction patterns, and the augmented relevancy signatures algorithm classifies texts using extraction patterns and semantic features associated with role fillers (Riloff and Lehnert, 1994). These algorithms relied on hand-coded training data, including annotated texts and a semantic dictionary. In this chapter, we describe two advances that significantly improve the practicality of our approach. First, we explain how the extraction patterns can be generated automatically using only preclassified texts as input. Second, we present the word-augmented relevancy signatures algorithm that uses lexical items to represent domain-specific role relationships instead of semantic features. Using these techniques, we can automatically build text categorization systems that benefit from domain-specific natural language processing. 

%0 Conference Proceedings
%T Category-Based Filtering and User Stereotype Cases to Reduce the Latency Problem in Recommender Systems
%A Sollenborn, Mikael
%A Funk, Peter
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_29
%X Collaborative filtering is an often successful method for personalized item selection in Recommender systems. However, in domains where items are frequently added, collaborative filtering encounters the latency problem. Characterized by the systemâs inability to select recently added items, the latency problem appears because new items in a collaborative filtering system must be reviewed before they can be recommended. Content-based filtering may help to counteract this problem, but runs the risk of only recommending items almost identical to the ones the user has appreciated before. In this paper, a combination of category-based filtering and user stereotype cases is proposed as a novel approach to reduce the latency problem. Category-based filtering puts emphasis on categories as meta-data to enable quicker personalization. User stereotype cases, identified by clustering similar users, are utilized to decrease response times and improve the accuracy of recommendations when user information is incomplete.
%P 395-405


%0 Conference Proceedings
%T The application of case-based reasoning to the tasks of health care planning
%A Bradburn, Carol
%A Zeleznikow, John
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_100
%X This paper describes an application of case-based reasoning in the field of health care planning. The process is modelled in the FLORENCE expert system, an experimental prototype which models the reasoning of an expert clinician in advising on the three basic planning tasks of diagnosis, prognosis and prescription within a nursing domain. We have developed an empirical approach. Both rule-based and case-based reasoning are used where appropriate. It has been found that case-based reasoning is especially appropriate to situations where decisions must be made about the progress of cases over time.
%P 365-378


%0 Conference Proceedings
%T Case-based information retrieval
%A SmaÃ¯l, Malika
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_103
%X This paper discusses a Case-Based Reasoning (CBR) approach as a good way of incrementally improving an information retrieval strategy. The proposed approach, Cabri-n, achieves a synergy between CBR and information retrieval that aims to exploit users feedback for improving the retrieval short-term performances (during a single retrieval session) and the long-term performances (over the system's life time). The long-term improvement is achieved by managing a memory of sessions which exploits successes as well as failures of information retrieval. A typology defined over the set of potential information needs serves as a meta-index for the long-term memory, so allows a context-sensitive retrieval and adaptation of former sessions. Besides, we discuss some common issues of CBR and information retrieval making their combination a promising paradigm.
%P 404-413


%0 Conference Proceedings
%T A Dynamic Approach to Reducing Dialog in On-Line Decision Guides
%A Doyle, Michelle
%A Cunningham, PÃ¡draig
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_6
%X Online decision guides typically ask too many questions of the user, as they make no attempt to focus the questions. We describe some approaches to minimising the questions asked of a user in an online query situation. Questions are asked in an order that reflects their ability to narrow down the set of cases. Thus time to reach an answer is decreased. This has the dual benefit of taking some of the monotony out of online queries, and also of decreasing the amount of network request-response cycles. Most importantly, question order is decided at run time, and therefore adapts to the user. This approach is in the spirit of lazy learning with induction delayed to run-time, allowing adaptation to the emerging details of the situation. We evaluate a few different approaches to the question selection task, and compare the best approach (one based on ideas from retrieval in CBR) to a commercial online decision guide.
%P 49-60


%0 Conference Proceedings
%T Unearthing Virtual History: Using Diverse Interfaces to Reveal Hidden Virtual Worlds
%A Benford, Steve
%A Bowers, John
%A Chandler, Paul
%A Ciolfi, Luigina
%A Flintham, Martin
%A Fraser, Mike
%A Greenhalgh, Chris
%A Hall, Tony
%A HellstrÃ¶m, Sten Olof
%A Izadi, Shahram
%A Rodden, Tom
%A SchnÃ¤delbach, Holger
%A Taylor, Ian
%Y Abowd, Gregory D.
%Y Brumitt, Barry
%Y Shafer, Steven
%S Ubicomp 2001: Ubiquitous Computing
%D 2001
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-45427-4
%F 10.1007/3-540-45427-6_18
%X We describe an application in which museum visitors hunt for virtual history outdoors, capture it, and bring it back indoors for detailed inspection. This application provides visitors with ubiquitous access to a parallel virtual world as they move through an extended physical space. Diverse devices, including mobile wireless interfaces for locating hotspots of virtual activity outdoors, provide radically different experiences of the virtual depending upon location, task, and available equipment. Initial reflections suggest that the physical design of such devices needs careful attention so as to encourage an appropriate style of use. We also consider the extension of our experience to support enacted scenes. Finally, we discuss potential benefits of using diverse devices to make a shared underlying virtual world ubiquitously available throughout physical space.
%P 225-231


%0 Conference Proceedings
%T Integrating Information Resources: A Case Study of Engineering Design Supportâ
%A Leake, David B.
%A Birnbaum, Larry
%A Hammond, Kristian
%A Marlow, Cameron
%A Yang, Hao
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_35
%X The development of successful case-based design aids depends both on the CBR processes themselves and on crucial questions of integrating the CBR system into the larger task context: how to make the CBR component provide information at the right time and in the right form, how to access relevant information from additional information sources to supplement the case library, how to capture information for use downstream and how to unobtrusively acquire new cases. This paper presents a set of design principles and techniques that integrate methods from CBR and information retrieval to address these questions. The paper illustrates their application through a case study of the Stamping Advisor, a tool to support feasibility analysis for stamped metal automotive parts.
%P 482-496


%0 Conference Proceedings
%T Personalised Route Planning: A Case-Based Approach
%A McGinty, Lorraine
%A Smyth, Barry
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_37
%X Automatically generating high-quality routes using real map data is difficult for a number of reasons. Real maps rarely contain the sort of information that is useful for constructing high quality routes. In addition, the notion of âroute qualityâ is difficult to define and is likely to change from person to person. In this sense the automatic construction of high-quality routes that match the preferences of individuals is an example of a weak-theory problem, and therefore well suited to a case-based approach. In this paper we describe and evaluate a case-based route planning system that is capable of efficiently generating routes that reflect the implicit preferences of individual users.
%P 431-443


%0 Conference Proceedings
%T Induction of logic programs with more than one recursive clause by analyzing saturations
%A Furusawa, Mitsue
%A Inuzuka, Nobuhiro
%A Seki, Hirohisa
%A Itoh, Hidenori
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_45
%X This paper describes a bottom-up ILP algorithm called MRI, which induces recursive programs with one or more recursive clauses from a few of examples. It analyzes saturations using path structures, which express streams of terms processed by predicates and was originally introduced by Identam-Almquist. We introduce extension and difference of path structures. Recursive clauses can be expressed as a difference among path structures. The paper also shows experimental results.
%P 165-172


%0 Conference Proceedings
%T Probabilistic indexing for case-based prediction
%A Faltings, Boi
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_529
%X The main assumption underlying case-based reasoning is that a problem with similar features as an earlier one is likely to have the same solution. However, this assumption has never been formally justified, and one can easily find practical situations where it is not true. We use probablity theory to show that even if this fundamental assumption can be wrong for particular instances, it is guaranteed to be correct on the average, and this no matter what the probability distributions involved are. We define the concept of a match weight as a well-justified measure of similarity. We show how it is often possible to effectively compute a lower bound on match weight. We report on the performance of such bounds when used as a similarity measure in a simple example.
%P 611-622


%0 Conference Proceedings
%T An underlying memory model to support case retrieval
%A Brown, Mike G.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_82
%X The goal of the work described in this paper is to provide a general and underlying model of memory to support the process of Case-Based Reasoning (CBR). The approach taken is to build a range of biasing constraint into the structure of memory itself and to use a suitably designed activation passing process to exploit this information as a guide for the retrieval of appropriate source cases. This provides the potential for highly flexible case retrieval without the need for exhaustive search of memory. This claim is supported by initial experimentation using a prototype implementation of the memory model.
%P 132-143


%0 Conference Proceedings
%T Large-scale fault diagnosis for on-board train systems
%A Netten, B. D.
%A Vingerhoeds, R. A.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_7
%X A new approach is developed for fault diagnosis during different stages of development and operation of large train systems, incorporating case-based reasoning, conditional probabilities and indexing networks. Due to the size and complexity, the explicit, complete and accurate modelling of the on-board train systems is regarded impossible. The knowledge is implicitly available in fault-cases with possible symptoms, test results and actions. Off-line, different diagnostic systems are automatically maintained and (re)generated. Knowledge and experience of manufacturers and railway companies are fed back into all systems, but only after validation by authorised personnel. On-line, the system responses are consistent and fast enough, despite the size and uncertainty in the fault-cases. Available case-based reasoning tools have serious limitations in permissible size of the problem, handling probability factors, meeting required response times and satisfying the real-time requirements. The novelty of the proposed approach is that fault-networks, rather than fault-trees, are built automatically as the indexing structure of the case-base for on-line use.
%P 67-76


%0 Conference Proceedings
%T Reliable communication over partially authenticated networks
%A Beimell, Amos
%A Franklin, Matthew
%Y Mavronicolas, Marios
%Y Tsigas, Philippas
%S Distributed Algorithms
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69600-1
%F 10.1007/BFb0030688
%X Reliable communication between parties in a network is a basic requirement for executing any protocol. In this work, we consider the effect on reliable communication when some pairs of parties have common authentication keys. The pairs sharing keys define a natural âauthentication graphâ, which may be quite different from the âcommunication graphâ of the network. We characterize when reliable communication is possible in terms of these two graphs, focusing on the very strong setting of a Byzantine adversary with unlimited computational resources.
%P 245-259


%0 Conference Proceedings
%T Refining conversational case libraries
%A Aha, David W.
%A Breslow, Leonard A.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_498
%X Conversational case-based reasoning (CBR) shells (e.g., Inference's CBR Express) are commercially successful tools for supporting the development of help desk and related applications. In contrast to rule-based expert systems, they capture knowledge as cases rather than more problematic rules, and they can be incrementally extended. However, rather than eliminate the knowledge engineering bottleneck, they refocus it on case engineering, the task of carefully authoring cases according to library design guidelines to ensure good performance. Designing complex libraries according to these guidelines is difficult; software is needed to assist users with case authoring. We describe an approach for revising case libraries according to design guidelines, its implementation in Clire, and empirical results showing that, under some conditions, this approach can improve conversational CBR performance.
%P 267-278


%0 Conference Proceedings
%T Structural similarity as guidance in case-based design
%A BÃ¶rner, Katy
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_87
%X This paper presents a novel approach to determine structural similarity as guidance for adaptation in case-based reasoning (Cbr). We advance structural similarity assessment which provides not only a single numeric value but the most specific structure two cases have in common, inclusive of the modification rules needed to obtain this structure from the two cases. Our approach treats retrieval, matching, and adaptation as a group of dependent processes. This guarantees the retrieval and matching of not only similar but adaptable cases. Both together enlarge the overall problem solving performance of Cbr and the explainability of case selection and adaptation considerably. Although our approach is more theoretical in nature and not restricted to a specific domain, we will give an example taken from the domain of industrial building design. Additionally, we will sketch two prototypical implementations of the approach.
%P 197-208


%0 Conference Proceedings
%T A Multiple-Domain Evaluation of Stratified Case-Based Reasoning
%A Branting, L.Karl
%A Tao, Yi
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_4
%X Stratified case-based reasoning (SCBR) is a technique in which case abstractions are used to assist case retrieval, matching, and adaptation. Previous work has shown that SCBR can significantly decrease the computational expense required for retrieval, matching, and adaptation under a variety of different problem conditions. This paper extends this work to two new domains: a problem in combinatorial optimization, sorting by prefix reversal; and logistics planning. An empirical evaluation in the prefix-reversal problem showed that SCBR reduced search cost, but severely degraded solution quality. By contrast, in logistics planning, use of SCBR as an indexing mechanism led to faster solution times and permitted more problems to be solved than either hierarchical problem solving (by ALPINE) or ground level CBR (by SPA) alone. The primary factor responsible for the difference in SCBRâs performance in these two domains appeared to be that the optimal-case utility was low in the prefix-reversal task but high in logistics planning.
%P 44-58


%0 Conference Proceedings
%T Case-Based Reasoning for Breast Cancer Treatment Decision Helping
%A Lieber, Jean
%A Bresson, BenoÃ®t
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_16
%X This paper presents two applications for the breast cancer treatment decision helping. The first one is called Casimir/RBR and can be likened to a rule-based reasoning system. In some situations, the application of the rules of this system does not provide a satisfying treatment. Then, the application Casimir/CBR-which is not fully implementedcan be used. Casimir/CBR uses principles of case-based reasoning in order to suggest solutions by adapting the rules of Casimir/RBR. In this framework, the rules are considered as cases: they are adapted rather than used literally.
%P 173-185


%0 Conference Proceedings
%T A case based method for solving relatively stable dynamic constraint satisfaction problems
%A Huang, Y.
%A Miles, R.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_44
%X This paper discusses some key issues in using case based methods to solve large constraint satisfaction problems. The problem addressed here is characterised by the large cardinality of the constraint tables. The aim is to reduce the amount of consistency checking carried out by database queries. We have addressed issues concerning the similarity measurement, adaptation/repair control in terms of conflict ordering strategies, the quality of the case base and issues concerning backtracking strategies. The results presented in this paper indicate an approach for improving case based methods in solving large constraint satisfaction problems.
%P 481-490


%0 Conference Proceedings
%T PRODILOGY/ANALOGY: Analogical reasoning in general problem solving
%A Veloso, Manuela M.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_75
%X This paper describes the integration of analogical reasoning into general problem solving as a method of learning at the strategy level to solve problems more effectively. The method based on derivational analogy has been fully implemented in prodigy/analogy and proven empirically to be amenable to scaling up both in terms of domain and problem complexity. prodigy/analogy addresses a set of challenging problems, namely: how to accumulate episodic problem solving experience, cases, how to define and decide when two problem solving situations are similar, how to organize a large library of planning cases so that it may be efficiently retrieved, and finally how to successfully transfer chains of problem solving decisions from past experience to new problem solving situations when only a partial match exists among corresponding problems. The paper discusses the generation and replay of the problem solving cases and we illustrate the algorithms with examples. We present briefly the library organization and the retrieval strategy. We relate this work with other alternative strategy learning methods, and also with plan reuse. prodigy/analogy casts the strategy-level learning process for the first time as the automation of the complete cycle of constructing, storing, retrieving, and flexibly reusing problem solving experience. We demonstrate the effectiveness of the analogical replay strategy by providing empirical results on the performance of prodigy/analogy, accumulating and reusing a large case library in a complex problem solving domain. The integrated learning system reduces the problem solving search effort incrementally as more episodic experience is compiled into the library of accumulated learned knowledge.
%P 33-50


%0 Conference Proceedings
%T Comparison-Based Recommendation
%A Ginty, Lorraine Mc
%A Smyth, Barry
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_42
%X Recommender systems combine user profiling and filtering techniques to provide more pro-active and personal information retrieval systems, and have been gaining in popularity as a way of overcoming the ubiquitous information overload problem. Many recommender systems operate as interactive systems that seek feedback from the end-user as part of the recommendation process to revise the userâs query. In this paper we examine different forms of feedback that have been used in the past and focus on a low-cost preference-based feedback model, which to date has been very much under utilised. In particular we describe and evaluate a novel comparison-based recommendation framework which is designed to utilise preference-based feedback. Specifically, we present results that highlight the benefits of a number of new query revision strategies and evidence to suggest that the popular more-like-this strategy may be flawed.
%P 575-589


%0 Conference Proceedings
%T Morphosyntactic Tagging of Slovene Using Progol
%A Cussens, James
%A DÅ¾eroski, SaÅ¡o
%A Erjavec, TomaÅ¾
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_8
%X We consider the task of tagging Slovene words with morphosyntactic descriptions (MSDs). MSDs contain not only part-of-speech information but also attributes such as gender and case. In the case of Slovene there are 2,083 possible MSDs. P-Progol was used to learn morphosyntactic disambiguation rules from annotated data (consisting of 161,314 examples) produced by the MULTEXT-East project. P-Progol produced 1,148 rules taking 36 hours. Using simple grammatical background knowledge, e.g. looking for case disagreement, P-Progol induced 4,094 clauses in eight parallel runs. These rules have proved effective at detecting and explaining incorrect MSD annotations in an independent test set, but have not so far produced a tagger comparable to other existing taggers in terms of accuracy.
%P 68-79


%0 Conference Proceedings
%T Combining CBR with Interactive Knowledge Acquisition, Manipulation and Reuseâ
%A Leake, David B.
%A Wilson, David C.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_15
%X Because of the complexity of aerospace design, intelligent systems to support and amplify the abilities of aerospace designers have the potential for profound impact on the speed and reliability of design generation. This article describes a framework for supporting the interactive capture of design cases and their application to new problems, illustrating the approach with a discussion of its use in a support system for aircraft design. The project integrates case-based reasoning with interactive tools for capturing expert design knowledge through âconcept mapping.â Concept mapping tools provide crucial functions for interactively generating and examining design cases and navigating their hierarchical structure, while CBR techniques provide capabilities to facilitate retrieval and to aid interactive adaptation of designs. The project aims simultaneously to develop a useful design aid and more generally to develop practical interactive approaches to fundamental issues of case acquisition and representation, context-sensitive retrieval, and case adaptation.
%P 203-217


%0 Conference Proceedings
%T Learning Logic programs with random classification noise
%A HorvÃ¡th, TamÃ¡s
%A Sloan, Robert H.
%A TurÃ¡n, GyÃ¶rgy
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_63
%X We consider the learnability of classes of logic programs in the presence of noise, assuming that the label of each example is reversed with a fixed probability. We review the polynomial PAC learnability of nonrecursive, determinate, constant-depth Horn clauses in the presence of such noise. This result is extended to an analogous class of recursive logic programs that consist of a recursive clause, a base case clause, and ground background knowledge. Also, we show that arbitrary nonrecursive Horn clauses with forest background knowledge remain polynomially PAC learnable in the presence of noise. We point out that the sample size can be decreased by using dependencies among the literals.
%P 315-336


%0 Conference Proceedings
%T Stochastic propositionalization of non-determinate background knowledge
%A Kramer, Stefan
%A Pfahringer, Bernhard
%A Helma, Christoph
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027312
%X Both propositional and relational learning algorithms require a good representation to perform well in practice. Usually such a representation is either engineered manually by domain experts or derived automatically by means of so-called constructive induction. Inductive Logic Programming (ILP) algorithms put a somewhat less burden on the data engineering effort as they allow for a structured, relational representation of background knowledge. In chemical and engineering domains, a common representational device for graph-like structures are so-called non-determinate relations. Manually engineered features in such domains typically test for or count occurrences of specific substructures having specific properties. However, representations containing non-determinate relations pose a serious efficiency problem for most standard ILP algorithms. Therefore, we have devised a stochastic algorithm to automatically derive features from non-determinate background knowledge. The algorithm conducts a top-down search for first-order clauses, where each clause represents a binary feature. These features are used instead of the non-determinate relations in a subsequent induction step. In contrast to comparable algorithms search is not class-blind and there are no arbitrary size restrictions imposed on candidate clauses. An empirical investigation in three chemical domains supports the validity and usefulness of the proposed algorithm.
%P 80-94


%0 Report
%T Bayes Optimal Metasearch: A Probabilistic Model for Combining the Results of Multiple Retrieval Systems
%D 2000
%A Javed A. Aslam
%A Mark Montague
%X We introduce a new, probabilistic model for combining the outputs of an arbitrary number of query retrieval systems. By gathering simple statistics on the average performance of a given set of query retrieval systems, we construct a Bayes optimal mechanism for combining the outputs of these systems. Our construction yields a metasearch strategy whose empirical performance nearly always exceeds the performance of any of the constituent systems. Our construction is also robust in the sense that if ``good'''' and ``bad'''' systems are combined, the performance of the composite is still on par with, or exceeds, that of the best constituent system. Finally, our model and theory provide theoretical and empirical avenues for the improvement of this metasearch strategy.

%0 Conference Proceedings
%T Multiple explanation patterns
%A Schild, Uri J.
%A Kerner, Yaakov
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_99
%X In the Case-Based Reasoning paradigm cases are often given initially in natural language in the form of a âstoryâ. While this textual form is appropriate for humans, it is often not suitable for direct application by a computer. Our paper uses the legal domain of sentencing for criminal offences to illustrate an approach to indexing, knowledge representation of stories and their application in reasoning. This approach extends the well-known concept of Explanation Patterns.
%P 353-364


%0 Conference Proceedings
%T Relational distance-based clustering
%A Kirsten, Mathias
%A Wrobel, Stefan
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027330
%X Work on first-order clustering has primarily been focused on the task of conceptual clustering, i.e., forming clusters with symbolic generalizations in the given representation language. By contrast, for propositional representations, experience has shown that simple algorithms based exclusively on distance measures can often outperform their concept-based counterparts. In this paper, we therefore build on recent advances in the area of first-order distance metrics and present RDBC, a bottom-up agglomerative clustering algorithm for first-order representations that relies on distance information only and features a novel parameter-free pruning measure for selecting the final clustering from the cluster tree. The algorithm can empirically be shown to produce good clusterings (on the mutagenesis domain) that, when used for subsequent prediction tasks, improve on previous clustering results and approach the accuracies of dedicated predictive learners.
%P 261-270


%0 Conference Proceedings
%T A Rule-Based Question Answering System For Reading Comprehension Tests
%D 2000
%A Riloff, Ellen
%A Thelen, Michael
%X We have developed a rule-based system, Quarc, that can read a short story and find the sentence in the story that best answers a given question. Quarc uses heuristic rules that look for lexical and semantic clues in the question and the story. We have tested Quarc on reading comprehension tests typically given to children in grades 3--6. Overall, Quarc found the correct sentence 40% of the time, which is encouraging given the simplicity of its rules. 
%0 Conference Proceedings
%T Explanation-based similarity: A unifying approach for integrating domain knowledge into case-based reasoning for diagnosis and planning tasks
%A Bergmann, Ralph
%A Pews, Gerd
%A Wilke, Wolfgang
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_86
%X Case-based problem solving can be significantly improved by applying domain knowledge (in opposition to problem solving knowledge), which can be acquired with reasonable effort, to derive explanations of the correctness of a case. Such explanations, constructed on several levels of abstraction, can be employed as the basis for similarity assessment as well as for adaptation by solution refinement. The general approach for explanation-based similarity can be applied to different real world problem solving tasks such as diagnosis and planning in technical areas. This paper presents the general idea as well as the two specific, completely implemented realizations for a diagnosis and a planning task.
%P 182-196


%0 Conference Proceedings
%T REMEX - A Case-Based Approach for Reusing Software Measurement Experienceware
%A von GresseWangenheim, Christiane
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_13
%X For the improvement of software quality and productivity, organizations need to systematically build up and reuse software engineering know-how, promoting organizational learning in software development. Therefore, an integrated support platform has to be developed for capturing, storing and retrieving software engineering knowledge. Technical support is complicated through specific characteristics of the software engineering domain, such as the lack of explicit domain models in practice and the diversity of environments. Applying Case-Based Reasoning, we propose an approach for the representation of relevant software engineering experiences, the goal-oriented and similarity-based retrieval tailorable to organization-specific characteristics and the continuous acquisition of new experiences. The approach is applied and validated in the context of the Goal/Question/Metric (GQM) approach, an innovative technology for software measurement.
%P 173-187


%0 Conference Proceedings
%T Solving Selection Problems Using Preference Relation Based on Bayesian Learning
%A Nakano, Tomofumi
%A Inuzuka, Nobuhiro
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_9
%X This paper defines a selection problem which selects an appropriate object from a set that is specified by parameters. We discuss inductive learning of selection problems and give a method combining inductive logic programming (ILP) and Bayesian learning. It induces a binary relation comparing likelihood of objects being selected. Our methods estimate probability of each choice by evaluating variance of an induced relation from an ideal binary relation. Bayesian learning combines a prior probability of objects and the estimated probability. By making several assumptions on probability estimation, we give several methods. The methods are applied to Part-of-Speech tagging.
%P 147-164


%0 Conference Proceedings
%T Learning User Preferences in Case-Based Software Reuse
%A Gomes, Paulo
%A Bento, Carlos
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_11
%X Case-Based Reasoning is a good framework for Software Reuse because it provides a flexible and powerful searching mechanism for software components. In a CBR system for software reuse it is important to learn the user preferences adapting the system software choices to the user. In a complex domain as software design, the similarity metric will also be complex, thus creating the necessity for a learning algorithm capable of weight learning. In this paper we present an evolutionary approach to similarity weight learning in a CBR system for software reuse. This approach is justified by the similarity metric complexity and recursive nature, which makes other learning methods to fail. We present experimental work showing the feasibility of this approach and we also present a parametric study, exploring several crossover and mutation strategies.
%P 112-123


%0 Journal Article
%T Efficient reliable communication over partially authenticated networks
%A Beimel, Amos
%A Malka, Lior
%J Distributed Computing
%D 2005
%8 July 01
%V 18
%N 1
%@ 1432-0452
%F Beimel2005
%X Reliable communication between processors in a network is a basic requirement for executing any protocol. Dolev [7] and Dolev etÂ al. [8] showed that reliable communication is possible if and only if the communication network is sufficiently connected. Beimel and Franklin [1] showed that the connectivity requirement can be relaxed if some pairs of processors share authentication keys. That is, costly communication channels can be replaced by authentication keys.
%9 journal article
%R 10.1007/s00446-004-0119-y
%U https://doi.org/10.1007/s00446-004-0119-y
%P 1-19


%0 Conference Proceedings
%T Learning a local similarity metric for case-based reasoning
%A Ricci, Francesco
%A Avesani, Paolo
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_27
%X This paper presents a new class of local similarity metrics, called AASM, that are not symmetric and that can be adopted as the basic retrieval method in a CBR system. An anytime learning procedure is also introduced that, starting from an initial set of stored cases, improves the retrieval accuracy by modifying the local definition of the metric. The learning procedure is a reinforcement learning algorithm and can be run as a black box since no particular setting is required. With the aid of classical test sets it is shown that AASM can improve in many cases the accuracy of both nearest neighbour methods and Salzberg's NGE. Moreover, AASM can achieve significant data compression (10%) while maintainig the same accuracy as NN.
%P 301-312


%0 Journal Article
%T Buses for Anonymous Message Delivery 
%A Beimel
%A Dolev
%J Journal of Cryptology
%D 2003
%8 January 01
%V 16
%N 1
%@ 1432-1378
%F Beimel2003
%X Abstract.  This work develops a novel approach to hide the senders and the receivers of messages. The intuition is taken from an everyday activity that hides the ``communication pattern''âthe public transportation system. To describe our protocols, buses are used as a metaphor: Buses, i.e., messages, are traveling on the network, each piece of information is allocated a seat within the bus. Routes are chosen and buses are scheduled to traverse these routes. Deterministic and randomized protocols are presented, the protocols differ in the number of buses in the system, the worst case traveling time, and the required buffer size in a ``station.'' In particular, a protocol that is based on cluster partition of the network is presented; in this protocol there is one bus traversing each cluster. The clusters' size in the partition gives time and communication tradeoffs. One advantage of our protocols over previous works is that they are not based on statistical properties for the communication pattern. Another advantage is that they only require the processors in the communication network to be busy periodically.
%9 journal article
%R 10.1007/s00145-002-0128-6
%U https://doi.org/10.1007/s00145-002-0128-6
%P 25-39


%0 Conference Proceedings
%T Integrating CBR and Heuristic Search for Learning and Reusing Solutions in Real-time Task Scheduling
%A AdÃ¡n Coello, Juan Manuel
%A Camilo dos Santos, Ronaldo
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_7
%X This paper presents the Case-Based Reasoning Real-Time Scheduling System (CBR-RTS) that integrates into a case-based reasoning framework a heuristic search component. The problem addressed involves scheduling sets of tasks with precedence, ready time and deadline constraints. CBR-RTS reuses the solution of known cases to simplify and solve new problems. When the system does not have applicable cases, it tries to find a solution using heuristic search. A particularly interesting feature of CBR-RTS is its learning ability. New problems solved by the heuristic scheduler can be added to the case base for future reuse. Performed tests have shown that small bases of cases carefully chosen allow to substantially reduce the time needed to solve new complex problems
%P 89-103


%0 Conference Proceedings
%T Maintaining unstructured case bases
%A Racine, Kirsti
%A Yang, Qiang
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_524
%X With the dramatic proliferation of case based reasoning systems in commercial applications, many case bases are now becoming legacy systems. They represent a significant portion of an organization's assets, but they are large and difficult to maintain. One of the contributing factors is that these case bases are often large and yet unstructured; they are represented in natural language text. Adding to the complexity is the fact that the case bases are often authored and updated by different people from a variety of knowledge sources, making it highly likely for a case base to contain redundant and inconsistent knowledge. In this paper, we present methods and a system for maintaining large and unstructured case bases. We focus on two difficult problems in case-base maintenance: redundancy and inconsistency detection. These two problems are particularly pervasive when one deals with an unstructured case base. We will discuss both algorithms and a system for solving these problems. As the ability to contain the knowledge acquisition problem is of paramount importance, our methods allow one to express relevant domain expertise for detecting both redundancy and inconsistency naturally and effortlessly. Empirical evaluations of the system prove the effectiveness of the methods in several large domains.
%P 553-564


%0 Conference Proceedings
%T Experiments in computer-assisted annotation of audio
%A Tzanetakis, George
%A Cook, Perry R.
%D 2000
%X

%0 Conference Proceedings
%T New Conditions for the Existence of Least Generalizations under Relative Subsumption
%A Yamamoto, Akihiro
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_16
%X Least common generalization under relative subsumption (LGRS) is a fundamental concept in Inductive Logic Programming. In this paper we give several new conditions for the existence of LGRSs. In previous researches the existence of LGRSs was guaranteed when a background theory is logically equivalent to conjunction of finitely many ground literals. Each of our conditions allows a background theory to have clauses with variables in it. The conditions are obtained using the bottom method (or the bottom generalization method), with which any clause subsuming a positive example relative to a background theory can be derived. We also compare the conditions with those for the existence of relative least generalizations under generalized subsumption (LGGSs).
%P 253-264


%0 Conference Proceedings
%T Knowledge engineering for CBR systems from a cognitive science perspective
%A Strube, G.
%A Enzinger, A.
%A Janetzko, D.
%A Knauff, M.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_51
%X Although CBR has been advertised as a technique to elude knowledge engineering (KE), we argue that knowledge-level modeling in KE is of eminent importance to the success of CBR systems, both for practical and theoretical reasons. Cases are knowledge structures linked to some underlying database (although not necessarily in a one-to-one fashion), and in order to define case structures and their relations to the database, domain knowledge is needed. In this paper, we focus on KE for CBR in the domain of architectural design, first looking at general analyses of work processes and information use, then discussing microanalyses of task structure in order to define case size, finally proceeding to knowledge-level evaluation of the domain knowledge acquired and modeled so far.
%P 548-558


%0 Conference Proceedings
%T Spatial composition using cases: IDIOM
%A Smith, Ian
%A Lottaz, Claudio
%A Faltings, Boi
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_9
%X This paper describes a system called IDIOM (Interactive Design using Intelligent Objects and Models) that was developed in order to study model-based case combination and adaptation in design. Intelligent objects are defined to be parts of cases that are interpreted at run-time by domain models and through user interaction. Incremental parameterization and dimensionality reduction ensures that design solutions are proposed quickly and reliably. An implementation in the domain of spatial composition for building designs demonstrates several aspects of the approach.
%P 88-97


%0 Conference Proceedings
%T Running head: LEARNING FROM TEXT Learning from text: Matching readers and texts by Latent Semantic Analysis
%D 1998
%A Wolfe, Michael Wehring
%A Schreiner, Maureen Elizabeth
%A Rehder, Bob
%A Laham, Darrell
%X This study examines the hypothesis that the ability of a reader to learn from text depends on the match between the background knowledge of the reader and the difficulty of the text information. Latent Semantic Analysis (LSA), a statistical technique that represents the content of a document as a vector in highâdimensional semantic space based on a large text corpus, is used to predict how much readers will learn from texts based on the estimated conceptual match between their topic knowledge and the text information. Participants completed tests to assess their knowledge of the human heart and circulatory system, then read one of four texts that ranged in difficulty from elementary to medical school level, then completed the tests again. Results show a nonmonotonic relation in which learning was greatest for texts that were neither too easy nor too difficult. LSA proved as effective at predicting learning from these texts as traditional knowledge assessment measures. For these texts, optimal assignment of text on the basis of either prereading measure would have increased the amount learned significantly.

%0 Conference Proceedings
%T Probabilistic first-order classification
%A Pompe, UroÅ¡
%A Kononenko, Igor
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_52
%X We discuss the problem of classification using the first order hypotheses. This paper proposes an enhancement of classification based on the naive Bayesian scheme that is able to overcome the conditional independence assumption. Several experiments, involving some artificial and real-world, both propositional and relational domains, were conducted. The results indicate that the classification performance of propositional learners is reached when the richer first-order knowledge representation is not mandatory. This holds also in the domains where such representation is more convenient. Our framework can also benefit from the use of the hypotheses describing negative information. In such case, the classification becomes more noise resistant.
%P 235-242


%0 Conference Proceedings
%T Evaluating the application of CBR in mesh design for simulation problems
%A Hurley, Neil
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_18
%X One of the great difficulties facing a designer of a knowledge-based interface to a numerical simulation engine is acquiring sufficient domain knowledge to cover a significant range of problems to a depth that will make the system useful for real problem-solving. It is difficult to enumerate a priori all the different scenarios which may be encountered and to devise rules to cater for each. Indeed, it is true to say that often the tuneable parameters of a numerical algorithm (such as the error tolerance in a matrix inversion technique or the mesh density in a finite element analysis) are determined on a trial and error basis when the problem is first encountered. Setting up a knowledge-base therefore requires a lot of time-consuming experimentation over a range of different problems. There is no easy way to avoid this knowledge acquisition task if a robust system to tackle real-world problems is to be created. Furthermore, we must accept that the system at some stage is likely to encounter problems outside its coverage. It is therefore worthwhile examining alternative reasoning techniques which can be utilised when domain knowledge is lacking, as well as ways that new knowledge can be incorporated into the knowledge-base as problem-solving takes place. Towards this end, we have examined the application of case-based reasoning (CBR) to finite element simulation and in particular to the sub-task of finite element mesh design. In [5] a CBR approach to mesh design was outlined. In the current paper we evaluate that system, assess its performance at problem solving, discuss the lessons learned from its development and what implications these have for CBR in general.
%P 193-204


%0 Journal Article
%T MARSYAS: A framework for audio analysis
%D 1999
%A George Tzanetakis
%A Perry Cook 
%X Existing audio tools handle the increasing amount of computer audio data inadequately. The typical tape-recorder paradigm for audio interfaces is inflexible and time consuming, especially for large data sets. On the other hand, completely automatic audio analysis and annotation is impossible using current techniques. Alternative solutions are semi-automatic user interfaces that let users interact with sound in flexible ways based on content. This approach offers significant advantages over manual browsing, annotation and retrieval. Furthermore, it can be implemented using existing techniques for audio content analysis in restricted domains. This paper describes MARSYAS, a framework for experimenting, evaluating and integrating such techniques. As a test for the architecture, some recently proposed techniques have been implemented and tested. In addition, a new method for temporal segmentation based on audio texture is described. This method is combined with audio analysis techniques and used for hierarchical browsing, classification and annotation of audio files.

%0 Conference Proceedings
%T Integrating Rule-Based and Case-Based Decision Making in Diabetic Patient Managementâ
%A Bellazzi, Riccardo
%A Montani, Stefania
%A Portinale, Luigi
%A Riva1, Alberto
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_28
%X The integration of rule-based and case-based reasoning is particularly useful in medical applications, where both general rules and specific patient cases are usually available. In the present paper we aim at presenting a decision support tool for Insulin Dependent Diabetes Mellitus management relying on such a kind of integration. This multi-modal reasoning system aims at providing physicians with a suitable solution to the problem of therapy planning by exploiting, in the most flexible way, the strengths of the two selected methods. In particular, the integration is pursued without considering one of the modality as the most prominent reasoning method, but exploiting complementarity in all possible ways. In fact, while rules provide suggestions on the basis of a situation detection mechanism that relies on structured prior knowledge, CBR may be used to specialize and dynamically adapt the rules on the basis of the patientâs characteristics and of the accumulated experience. On the other hand, if a particular patient class is not sufficiently covered by cases, the use of rules may be exploited to try to learn suitable situations, in order to improve the competence of the case-based component. Such a work will be integrated in the EU funded project T-IDDM architecture, and has been preliminary tested on a set of cases generated by a diabetic patient simulator.
%P 386-400


%0 Conference Proceedings
%T Case-based reasoning in a simulation environment for biological neural networks
%A Wendel, Oliver
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_105
%X This paper presents a case-based simulation environment devised to assist neurophysiologists in the design and analysis of simulation experiments with biologically realistic neural networks. We describe the problem domain and our specific notion of a case, discuss the complex structure of such cases and present a method to automatically transform the numerical raw data derived from simulations into a symbolic behavioral description that can be used for further inferences by the system.
%P 424-435


%0 Conference Proceedings
%T A reflective architecture for integrated memory-based learning and reasoning
%A Arcos, Josep LluÃ­s
%A Plaza, Enric
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_94
%X In this paper we will discuss the role of case-based reasoning and learning as a tool for integrating different methods of inference and different methods of learning. The Massive Memory Architecture, an experimental framework for experience-based learning and reasoning, is described. Its reflective capabilities are described and we put forth the hypothesis that learning methods are inference methods able to inspect the problem solving process and modify the system itself so as to improve its behavior. Therefore, learning methods require a self-model of the system. Self-models and method implementation are based on conceptual, knowledge-level descriptions of inference.
%P 289-300


%0 Conference Proceedings
%T An Assessment of ILP-assisted models for toxicology and the PTE-3 experiment
%A Srinivasan, Ashwin
%A King, Ross D.
%A Bristol, Douglas W.
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_27
%X The Predictive Toxicology Evaluation (or PTE) Challenge provided Machine Learning techniques with the opportunity to compete against specialised techniques for toxicology prediction. Toxicity models that used findings from ILP programs have performed creditably in the PTE-2 experiment proposed under this challenge. We report here on an assessment of such models along scales of: (1) quantitative performance, in comparison to models developed with expert collaboration; and (2) potential explanatory value for toxicology. Results appear to suggest the following: (a) across of range of class distributions and error costs, some explicit models constructed with ILP-assistance appear closer to optimal than most expert-assisted ones. Given the paucity of test-data, this is to be interpreted cautiously; (b) a combined use of propositional and ILP techniques appears to yield models that contain unusual combinations of structural and biological features; and (c) significant effort was required to interpret the output, strongly indicating the need to invest greater effort in transforming the output into a âtoxicologist-friendlyâ form. Based on the lessons learnt from these results, we propose a new predictive toxicology evaluation experiment â PTE-3 â which will address some important shortcomings of the previous study.
%P 291-302


%0 Conference Proceedings
%T Development and Utilization of a Case-Based Help-Desk Support System in a Corporate Environment
%A GÃ¶ker, Mehmet
%A Roth-Berghofer, Thomas
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_10
%X Current Case-Based Reasoning (CBR) process models present CBR as a low maintenance AI-technology and do not take the processes that have to be enacted during system development and utilization into account. Since a CBR system can only be useful if it is integrated into an organizational structure and used by more than one user, processes for continuous knowledge acquisition, -utilization and -maintenance have to be put in place. In this paper the short-comings of classical CBR process models are analyzed, and, based on the experiences made during the development of the case-based help-desk support system HOMER, the managerial, organizational and technical processes related to the development and utilization of CBR systems described.
%P 132-146


%0 Conference Proceedings
%T Personalized Conversational Case-Based Recommendation
%A GÃ¶ker, Mehmet H.
%A Thompson, Cynthia A.
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_10
%X In this paper, we describe the Adaptive Place Advisor, a user adaptive, conversational recommendation system designed to help users decide on a destination, specifically a restaurant. We view the selection of destinations as an interactive, conversational process, with the advisory system inquiring about desired item characteristics and the human responding. The user model, which contains preferences regarding items, attributes, values, value combinations, and diversification, is also acquired during the conversation. The system enhances the userâs requirements with the user model and retrieves suitable items from a case-base. If the number of items found by the system is unsuitable (too high, too low) the next attribute to be constrained or relaxed is selected based on the information gain associated with the attributes. We also describe the current status of the system and future work.
%P 99-111


%0 Conference Proceedings
%T Learning to refine indexing by introspective reasoning
%A Fox, Susan
%A Leake, David B.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_39
%X A significant problem for case-based reasoning (CBR) systems is determining the features to use in judging case similarity for retrieval. We describe research that addresses the feature selection problem by using introspective reasoning to learn new features for indexing. Our method augments the CBR system with an introspective reasoning component which monitors system performance to detect poor retrievals, identifies features which would lead retrieval of more adaptable cases, and refines the indexing criteria to include the needed features to avoid future failures. We explore the benefit of introspective reasoning by performing empirical tests on the implemented system. These tests examine the effect of introspective index refinement, and the effects of problem order on case and index learning, and show that introspective learning of new index features improves performance across the different problem orders.
%P 431-440


%0 Conference Proceedings
%T Representing and indexing building refurbishment cases for multiple retrieval of adaptable pieces of cases
%A Marir, Farhi
%A Watson, Ian
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_6
%X CBRefurb is a case-based reasoning (CBR) system for the strategic cost estimation for building refurbishment. This domain is characterised by many uncertainties and variation. Its cost estimation involves large amount of interrelated factors whose impact is difficult to assess. This paper report on the problems faced by the building cost information Services (BCIS) databases and several rule-based expert systems to tackle this complex cost estimation problem and, the design and evaluation of CBRefurb system implemented using ReMind Shell. CBRefurb imitates the domain expert in its approach of breaking down the whole building work into smaller work (building items) by organising the refurbishment cases as a hierarchical structure composed of cases and subcases. The process of estimation imitate the expert by considering only these pieces of previous cases of similar situation (or context). For this purpose, CBRefurb defines some of the building and its component (or items) features as a global context and local context information used to classify cases and subcases into context cases and subcases, and to decompose the cost estimation problem into adaptable subproblems. This is followed by a two indexing schemes to suit the hierarchical structure of the case and the problem decomposition and to allow classification and retrieval of contextual cases. CBRefurb features consolidate the aim of the project that is allowing multiple retrieval of appropriate pieces of the refurbishment which are easier to adapt, reflecting the expert method of estimating cost for complex refurbishment work.
%P 55-66


%0 Conference Proceedings
%T A case-based reasoner adaptive to different cognitive tasks
%A Bichindaritz, Isabelle
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_35
%X Case-based reasoning systems are generally devoted to the realization of a single cognitive task. The need for such systems to perform various cognitive tasks questions how to organize their memory to permit them to be task-adaptive. The case-based reasoning system adaptive to cognitive tasks presented here is capable to adapt to analysis tasks as well as synthesis tasks. Its adaptability comes from its memory composition, both cases and concepts, and from its hierarchical memory organization, based on multiple points of view, some of them associated to the various cognitive tasks it performs. For analytic tasks, the most specific cases are preferably used for the reasoning process. For synthesis tasks, the most specific concepts, learnt by conceptual clustering, are used. An example of this system abilities, in the domain of eating disorders in psychiatry, is briefly presented.
%P 391-400


%0 Conference Proceedings
%T Generalizing Refinement Operators to Learn Prenex Conjunctive Normal Forms
%A Nienhuys-Cheng, Shan-Hwei
%A Van Laer, Wim
%A Ramon, Jan
%A De Raedt, Luc
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_23
%X Inductive Logic Programming considers almost exclusively universally quantified theories. To add expressiveness we should consider general prenex conjunctive normal forms (PCNF) with existential variables. ILP mostly uses learning with refinement operators. To extend refinement operators to PCNF, we should first extend substitutions to PCNF. If one substitutes an existential variable in a formula, one often obtains a specializtion rather than a generalization. In this article we define substitutions to specialize a given PCNF and a weakly complete downward refinement operator. Based on this operator, we have implemented a simple learning system PCL on some type of PCNF.
%P 245-256


%0 Conference Proceedings
%T A priori selection of mesh densities for adaptive finite element analysis, using a case-based reasoning approach
%A Hurley, Neil
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_101
%X This paper describes the application of case-based reasoning (CBR) techniques to a complex domain, namely, mesh specification for finite element analysis. The case-base provides a high-level store of information extracted through CPU-intensive numerical error analysis of previously solved problems, making it available for mesh specification before the simulation of new similar problems. Using this information, a near-to-optimum mesh is specified as input to the simulation engine, avoiding time-consuming computation during simulation. The paper describes the system, case representation, organisation and retrieval, and compares the CBR approach with the more usual rule-based approaches to this application domain.
%P 379-391


%0 Conference Proceedings
%T A utility-based approach to learning in a mixed case-based and model-based reasoning architecture
%A van Someren, Maarten
%A Surma, Jerzy
%A Torasso, Pietro
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_517
%X Case-based reasoning (CBR) can be used as a form of âcachingâ solved problems to speedup later problem solving. Using âcachedâ cases brings additional costs with it due to retrieval time, case adaptation time and also storage space. Simply storing all cases will result in a situation in which retrieving and trying to adapt old cases will take more time (on average) than not caching at all. This means that caching must be applied selectively to build a case memory that is actually useful. This is a form of the utility problem [4, 2]. The approach taken here is to construct a âcost modelâ of a system that can be used to predict the effect of changes to the system. In this paper we describe the utility problem associated with âcachingâ cases and the construction of a âcost modelâ. We present experimental results that demonstrate that the model can be used to predict the effect of certain changes to the case memory.
%P 477-488


%0 Journal Article
%T A Corpus-Based Approach for Building Semantic Lexicons
%D 1997 
%A Riloff, Ellen
%A Shepherd, Jessica
%X Semantic knowledge can be a great asset to natural language processing systems, but it is usually hand-coded for each application. Although some semantic information is available in general-purpose knowledge bases such as WordNet and Cyc, many applications require domain-specific lexicons that represent words and categories for a particular topic. In this paper, we present a corpus-based method that can be used to build semantic lexicons for specific categories. The input to the system is a small set of seed words for a category and a representative text corpus. The output is a ranked list of words that are associated with the category. A user then reviews the top-ranked words and decides which ones should be entered in the semantic lexicon. In experiments with five categories, users typically found about 60 words per category in 10-15 minutes to build a core semantic lexicon. 
%0 Conference Proceedings
%T On the Complexity of Plan Adaptation by Derivational Analogy in a Universal Classical Planning Framework
%A Au, Tsz-Chiu
%A MuÃ±oz-Avila, HÃ©ctor
%A Nau, Dana S.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_3
%X In this paper we present an algorithm called DerUCP, which can be regarded as a general model for plan adaptation using Derivational Analogy. Using DerUCP, we show that previous results on the complexity of plan adaptation do not apply to Derivational Analogy. We also show that Derivational Analogy can potentially produce exponential reductions in the size of the search space generated by a planning system.
%P 13-27


%0 Conference Proceedings
%T Theoretical analysis of case retrieval method based on neighborhood of a new problem
%A Okamoto, Seishi
%A Yugami, Nobuhiro
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_505
%X The retrieval of similar cases is often performed by using the neighborhood of a new problem. The neighborhood is usually denned by a certain fixed number of most similar cases (k nearest neighbors) to the problem. This paper deals with an alternative definition of neighborhood that comprises the cases within a certain distance, d, from the problem. We present an average-case analysis of a classifier, the d-nearest neighborhood method (d-NNh), that retrieves cases in this neighborhood and predicts their majority class as the class of the problem. Our analysis deals with m-of-n/l target concepts, and handles three types of noise. We formally compute the expected classification accuracy of d-NNh, then we explore the predicted behavior of d-NNh. By combining this exploration for d-NNh and one for k-nearest neighbor method (k-NN) in our previous study, we compare the predicted behavior of each in noisy domains. Our formal analysis is supported with Monte Carlo simulations.
%P 349-358


%0 Conference Proceedings
%T Defining Similarity Measures: Top-Down vs. Bottom-Up
%A Stahl, Armin
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_30
%X Defining similarity measures is a crucial task when developing CBR applications. Particularly, when employing utility-based similarity measures rather than pure distance-based measures one is confronted with a difficult knowledge engineering task. In this paper we point out some problems of the state-of-the-art procedure to defining similarity measures. To overcome these problems we propose an alternative strategy to acquire the necessary domain knowledge based on a Machine Learning approach. To show the feasibility of this strategy several application scenarios are discussed and some results of an experimental evaluation for one of these scenarios are presented.
%P 406-420


%0 Conference Proceedings
%T Similarity Measures for Structured Representations: A Definitional Approach
%A Falkman, GÃ¶ran
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_33
%X A similarity framework for definitional representations is presented. Similarity assessment is based on the computation and estimation of structural relationships (connections) among definitions. The framework is general enough to capture many different types of similarity measures: ordinal and cardinal measures, asymmetric measures, and measures between any number of objects. By definition, the similarity measures retrieve the cases that need the least adaptation.
%P 380-392


%0 Conference Proceedings
%T A scalable approach for question based indexing of encyclopedic texts
%A Wisdo, Christopher
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_492
%X This paper describes a tool set developed to aid a human content analyst index texts for use in a particular form of structured hypermedia known as an ASK System. The tool set assists the content analyst by employing a library of question templates to represent the types of questions the output ASK system might contain. Question templates provided roughly a six-fold increase in the rate with which texts are indexed compared to manual techniques. Indexing progress is linear throughout, indicating that the methodology can be used to effectively index a large body of texts.
%P 200-210


%0 Conference Proceedings
%T Diversity-Conscious Retrieval
%A McSherry, David
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_17
%X There is growing awareness of the need for recommender systems to offer a more diverse choice of alternatives than is possible by simply retrieving the cases that are most similar to a target query. Recent research has shown that major gains in recommendation diversity can often be achieved at the expense of relatively small reductions in similarity. However, there are many domains in which it may not be acceptable to sacrifice similarity in the interest of diversity. To address this problem, we examine the conditions in which similarity can be increased without loss of diversity and present a new approach to retrieval which is designed to deliver such similarity-preserving increases in diversity when possible. We also present a more widely applicable approach to increasing diversity in which the requirement that similarity is fully preserved is relaxed to allow some loss of similarity, provided it is strictly controlled.
%P 219-233


%0 Conference Proceedings
%T Supporting combined human and machine planning: An interface for planning by analogical reasoning
%A Cox, Michael T.
%A Veloso, Manuela M.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_522
%X Realistic and complex planning situations require a mixed-initiative planning framework in which human and automated planners interact to mutually construct a desired plan. Ideally, this joint cooperation has the potential of achieving better plans than either the human or the machine can create alone. Human planners often take a case-based approach to planning, relying on their past experience and planning by retrieving and adapting past planning cases. Planning by analogical reasoning in which generative and case-based planning are combined, as in Prodigy/Analogy, provides a suitable framework to study this mixed-initiative integration. However, having a human user engaged in this planning loop creates a variety of new research questions. The challenges we found creating a mixed-initiative planning system fall into three categories: planning paradigms differ in human and machine planning; visualization of the plan and planning process is a complex, but necessary task; and human users range across a spectrum of experience, both with respect to the planning domain and the underlying planning technology. This paper presents our approach to these three problems when designing an interface to incorporate a human into the process of planning by analogical reasoning with Prodigy/Analogy. The interface allows the user to follow both generative and case-based planning, it supports visualization of both plan and the planning rationale, and it addresses the variance in the experience of the user by allowing the user to control the presentation of information.
%P 531-540


%0 Conference Proceedings
%T Towards the integration of case-based, schema-based and model-based reasoning for supporting complex design tasks
%A Bartsch-SpÃ¶rl, Brigitte
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_14
%X This paper presents an approach of how to build bridges between case-based and model-based reasoning. Unlike other approaches, these bridges do not intend to surmount the whole âabstraction distanceâ between concrete cases and generic models in one step. Instead they introduce and use a web of supporting columns which consist of useful intermediate representations called schemata, prototypes, patterns, templates or whatever is a suitable characterisation for their functional role in the design process.
%P 145-156


%0 Conference Proceedings
%T Partial Orders and Indifference Relations: Being Purposefully Vague in Case-Based Retrieval
%A Ferguson, Alex
%A Bridge, Derek
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_8
%X In this paper, we look at case retrieval systems for product selection. Such systems are interactive. This places demands on the technology: customers must be able to specify their requirements in ways that are meaningful to them; and, the cases that are retrieved must be comprehensible in terms of the customer requirements. To meet these demands, we introduce to case retrieval the notions of similarity metrics with partially- ordered return types and of relations that express indifference between degrees of similarity.
%P 74-85


%0 Conference Proceedings
%T Experiments on adaptation-guided retrieval in case-based design
%A Smyth, Barry
%A Keane, Mark T.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_28
%X Case-based reasoning (CBR) has been applied with some success to complex planning and design tasks. In such systems, the best case is retrieved and adapted to solve a particular target problem. Often, the best case is that which can be most easily adapted to the target problem (as the overhead in adaptation is generally very high). Standard CBR systems use semantic-similarity to retrieve cases, on the assumption that the most similar case is the easiest case to adapt. However, this assumption can be shown to be flawed. In this paper, we report a novel retrieval method, called adaptation-guided retrieval, that is sensitive to the ease-of-adaptation of cases. In the context of a CBR system for software-design, called DÃ©jÃ  Vu, we show through a series of experiments that adaptation-guided retrieval is more accurate than standard retrieval techniques, that it scales well to large case-bases and that it results in more efficient overall problem-solving performance. The implications of this method and these results are discussed.
%P 313-324


%0 Conference Proceedings
%T An initial experiment into stereochemistry-based drug design using inductive logic programming
%A Muggleton, Stephen
%A Page, David
%A Srinivasan, Ashwin
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_46
%X Previous applications of Inductive Logic Programming to drug design have not addressed stereochemistry, or the three-dimensional aspects of molecules. While some success is possible without consideration of stereochemistry, researchers within the pharmaceutical industry consider stereochemistry to be central to most drug design problems. This paper reports on an experimental application of the ILP system P-Progol to stereochemistry-based drug design. The experiment tests whether P-Progol can identify the structure responsible for the activity of ACE (angiotensin-converting enzyme inhibitors from 28 positive examples, that is, from 28 molecules that display the activity of ACE inhibition. ACE inhibitors are a widely-used form of medication for the treatment of hypertension. It should be stressed that this structure was already known prior to the experiment and therefore is not a new discovery; the experiment was proposed by a researcher within the pharmaceutical industry to test the applicability of ILP to stereochemistry-based drug design. While the result of the experiment is quite positive, one challenge remains before ILP can be applied to a multitude of drug design problems.
%P 23-40


%0 Conference Proceedings
%T Learning phonetic rules in a speech recognition system
%A Alexin, ZoltÃ¡n
%A Csirik, JÃ¡nos
%A GyimÃ³thy, Tibor
%A Jelasity, Mark
%A TÃ³th, LÃ¡szlÃ³
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_33
%X Current speech recognition systems can be categorized into two broad classes; the knowledge-based approach and the stochastic one. In this paper we present a rule-based method for the recognition of Hungarian vowels. A spectrogram model was used as a front-end module and some acoustic features were extracted (e.g. locations, intensities and shapes of local maxima) from spectrograms by using a genetic algorithm method. On the basis of these features we developed a rule set for the recognition of isolated Hungarian vowels. These rules represented by Prolog clauses were refined by the IMPUT Inductive Logic Programming method.
%P 35-44


%0 Conference Proceedings
%T Integrating semantic structure and technical documentation in case-based service support Systems
%A Kamp, Gerd
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_102
%X Help desk systems are one of the most successful application areas of case-based reasoning. However, case-based reasoning techniques cover only parts of the whole help desk scenario. One missing part is providing access to the technical documentation. Combining these becomes especially important in the area of service support systems, where the service person has no access to the printed documentation. This paper presents a concept how to integrate CBR and technical documentation for service support systems.
%P 392-403


%0 Conference Proceedings
%T Improving Case Representation and Case Base Maintenance in Recommender Agents
%A Montaner, Miquel
%A LÃ³pez, Beatriz
%A de la Rosa, Josep LluÃ­s
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_18
%X Recommendations by salespeople are always based on knowledge about the products and expertise about your tastes, preferences, interests and behavior in the shop. In an attempt to model the behavior of salespeople, AI research has been focussed on the so called recommender agents. Such agents draw on previous results from machine learning and other advances in AI technology to develop user models and to anticipate and predict user preferences. In this paper we introduce a new approach to recommendation, based on Case-Based Reasoning (CBR). CBR is a paradigm for learning and reasoning through experience, as salesmen do. We present a user model based on cases in which we try to capture both explicit interests (the user is asked for information) and implicit interests (captured from user interaction) of a user on a given item. Retrieval is based on a similarity function that is constantly tuned according to the user model. Moreover, in order to cope with the utility problem that current CBR system suffer from, our approach includes a forgetting mechanism (the drift attribute) that can be extended to other applications beyond e-commerce.
%P 234-248


%0 Conference Proceedings
%T A memory-based hierarchical planner
%A Khemani, Deepak
%A Prasad, P. V. S. R. Bhanu
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_46
%X This paper describes a memory-based planning system. The memory constitutes a collection of generalized plans, which we call skeletons. Each skeleton embodies a style, and organizes planning knowledge in a packaging hierarchy. Traversal of this hierarchy results in hierarchical plan development, and the process is guided by a secondary memory which organizes the properties of ingredients into an inheritance hierarchy. A simple indexing hierarchy allows access to each skeleton, which is quite distinct and captures a whole class of plans in that style. Stepwise refinement of the plan is accompanied by modifications which add ingredient specific steps on the way. A system has been implemented in the culinary domain.
%P 501-509


%0 Conference Paper
%T Empirical Development of an Exponential Probabilistic Model for Text Retrieval
%D 2003
%A Jaime Teevan
%A David R. Karger 
%X Much work in information retrieval focuses on using a model of documents and queries to derive retrieval algorithms. Model based development is a useful alternative to heuristic development because in a model the assumptions are explicit and can be examined and refined independent of the particular retrieval algorithm. We explore the explicit assumptions underlying the naÃ¯ve framework by performing computational analysis of actual corpora and queries to devise a generative document model that closely matches text. Our thesis is that a model so developed will be more accurate than existing models, and thus more useful in retrieval, as well as other applications. We test this by learning from a corpus the best document model. We find the learned model better predicts the existence of text data and has improved performance on certain IR tasks.

%0 Conference Proceedings
%T Distance induction in first order logic
%A Sebag, MichÃ¨le
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_55
%X A distance on the problem domain allows one to tackle some typical goals of machine learning, e.g. classification or conceptual clustering, via robust data analysis algorithms (e.g. k-nearest neighbors or k-means).
%P 264-272


%0 Journal Article
%T Relational Reinforcement Learning
%A DÅ¾eroski, SaÅ¡o
%A De Raedt, Luc
%A Driessens, Kurt
%J Machine Learning
%D 2001
%8 April 01
%V 43
%N 1
%@ 1573-0565
%F DÅ¾eroski2001
%X Relational reinforcement learning is presented, a learning technique that combines reinforcement learning with relational learning or inductive logic programming. Due to the use of a more expressive representation language to represent states, actions and Q-functions, relational reinforcement learning can be potentially applied to a new range of learning tasks. One such task that we investigate is planning in the blocks world, where it is assumed that the effects of the actions are unknown to the agent and the agent has to learn a policy. Within this simple domain we show that relational reinforcement learning solves some existing problems with reinforcement learning. In particular, relational reinforcement learning allows us to employ structural representations, to abstract from specific goals pursued and to exploit the results of previous learning phases when addressing new (more complex) situations.
%9 journal article
%R 10.1023/A:1007694015589
%U https://doi.org/10.1023/A:1007694015589
%P 7-52


%0 Conference Proceedings
%T MacRad: Radiology image resource with a case-based retrieval system
%A Macura, Robert T.
%A Macura, Katarzyna J.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_5
%X We have compiled a case-based retrieval system for radiology, MacRad, that is structured around descriptors for radiology image findings. Our goal is to provide a feature-coded image resource that allows the user to formulate image content-based queries when searching for reference images. MacRad is implemented as a relational database with an image archive. Each image in the library is indexed according to its radiologic content. We structured an index for coding image content as a hierarchical image description index using the relational format. The hierarchical index of radiologic findings allows multilevel query formulation that depends upon the user's level of experience. The system uses rules to control the search direction within the case library and generate lists of diagnostic hypotheses for decision support. Rules are embedded within the database structure. At present, the case library consists of 300 cases and 3,000 images that present intracranial masses on skull X-rays, CTs, MRIs, and angiograms.
%P 43-54


%0 Conference Proceedings
%T A case study of case-based CBR
%A Leake, David B.
%A Kinley, Andrew
%A Wilson, David
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_507
%X Case-based reasoning depends on multiple knowledge sources beyond the case library, including knowledge about case adaptation and criteria for similarity assessment. Because hand coding this knowledge accounts for a large part of the knowledge acquisition burden for developing CBR systems, it is appealing to acquire it by learning, and CBR is a promising learning method to apply. This observation suggests developing case-based CBR systems, CBR systems whose components themselves use CBR. However, despite early interest in case-based approaches to CBR, this method has received comparatively little attention. Open questions include how case-based components of a CBR system should be designed, the amount of knowledge acquisition effort they require, and their effectiveness. This paper investigates these questions through a case study of issues addressed, methods used, and results achieved by a case-based planning system that uses CBR to guide its case adaptation and similarity assessment. The paper discusses design considerations and presents empirical results that support the usefulness of case-based CBR, that point to potential problems and tradeoffs, and that directly demonstrate the overlapping roles of different CBR knowledge sources. The paper closes with general lessons about case-based CBR and areas for future research.
%P 371-382


%0 Conference Proceedings
%T A Strong Complete Schema for Inductive Functional Logic Programming
%A HernÃ¡ndez-Orallo, J.
%A RamÃ­rez-Quintana, M. J.
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_12
%X A new IFLP schema is presented as a general framework for the induction of functional logic programs (FLP). Since narrowing (which is the most usual operational semantics of (FLP) performs a infication (mgu) followed by a replacement, we introduce two main operators in our IFLP schema: a generalisation and an inverse replacement or property of equality. We prove that this schema is strong complete in tha way that, given some evidence, it is possible to induce any program which could have generated that evidence. We outline some possible restrictions in order to improve the tractability of the schema. We also show that inverse narrowing is just a special case of our IFLP schema. Finally, a straightforward extension of the IFLP schema to function invention is illustrated.
%P 116-127


%0 Conference Proceedings
%T An Application of Case-Based Reasoning to the Adaptive Management of Wireless Networks
%A Barbera, Massimo
%A Barbero, Cristina
%A Dal Zovo, Paola
%A Farinaccio, Fernanda
%A Gkroustiotis, Evangelos
%A Kyriazakos, Sofoklis
%A Mura, Ivan
%A Previti, Gianluca
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_36
%X This paper describes an innovative application of Case-Based Reasoning methodologies for the dynamic management of wireless telecommunications systems. In spite of the very dynamic nature of mobile communications, wireless networks only possess limited adaptive management capabilities, which are unable to adequately follow traffic fluctuations through flexible and real-time resource assignment reconfigurations. The study described in this paper is an attempt to improve over these limitations, by allowing wireless networks to alleviate the effects of traffic overloads through an automated reasoning about its performance levels and an on-the-fly reconfiguration of resources assignment. The proposed Case-Based Reasoning approach provides a suitable framework to define a simple and scalable solution that easily incorporates the preferences of the network operators.
%P 490-504


%0 Conference Proceedings
%T An Experimental Study of Increasing Diversity for Case-Based Diagnosis
%A Zhang, Lu
%A Coenen, Frans
%A Leng, Paul
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_33
%X Increasing dversity for case-based reasoning (CBR) is an issue that has recently drawn the attention of researchers in the CBR field. Several diversification techniques have been proposed and discussed in the literature. However, whether and to what extent those techniques can bring about benefits to end-users remains in question. In this paper, we report an experiment in applying a diversification technique to a case-based diagnosis tool in a product maintenance domain. The results of this offer some evidence in support of diversification techniques.
%P 448-459


%0 Conference Proceedings
%T DOM-ArC: An active decision support system for quality assessment of cases
%A Bakhtari, Shirin
%A Oertel, Wolfgang
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_34
%X There is a general acceptance that a case-based assistance system that can meet the requirements of real-world complex applications should maintain a core of domain specific knowledge in combination with its case store. The presented DOM-ArC incorporates a domain ontology and is situated within a case-based design support system. The domain ontology incorporates not only deep domain knowledge, but also the decision making knowledge that ensures the quality and reliability of the domain cases. The DOM-ArC undertakes the role of an active assistant that supports the case-based reasoner with the following services. It reviews and analyses a case and makes suggestions about which case to retain, how to overcome deficiencies in a proposed solution, which solution to reject, and how to construct a case from scratch.
%P 381-390


%0 Journal Article
%T Metrics for evaluating database selection techniques
%A French, James C.
%A Powell, Allison L.
%J World Wide Web
%D 2000
%8 November 01
%V 3
%N 3
%@ 1573-1413
%F French2000
%X The increasing availability of online databases and other information resources in digital libraries and on the World Wide Web has created the need for efficient and effective algorithms for selecting databases to search. A number of techniques have been proposed for query routing or database selection. We have developed a methodology and metrics that can be used to directly compare competing techniques. They can also be used to isolate factors that influence the performance of these techniques so that we can better understand performance issues. In this paper we describe the methodology we have used to examine the performance of database selection algorithms such as gGlOSS and CORI. In addition we develop the theory behind a ârandomâ database selection algorithm and show how it can be used to help analyze the behavior of realistic database selection algorithms.
%9 journal article
%R 10.1023/A:1019241915635
%U https://doi.org/10.1023/A:1019241915635
%P 153-163


%0 Conference Proceedings 
%T Multimedia structuring using trees
%D 2000
%A Tzanetakis, George
%A Julia, Luc E. 
%X Traditionally work on multimedia structuring has been centered on the creation of indices and their use for searching. Although searching is important there are many cases where the user just wants to browse through the data to find something interesting without having any particular search goal. Multimedia data exhibits hierarchical structure that can be exploited for more natural user interaction with the content. In order to handle the large amounts of multimedia data more structure than what is currently available is required. In this paper, we have focused on structuring multimedia data using trees to describe both temporal and categorical relations. The pervasive use of trees to express hierarchies facilitates browsing, profiling, and authoring. Our main target application is the implementation of a personalized TV-guide. The constraints imposed by this application caused the development of a new simple compact graphical user interface for tree browsing.

%0 Conference Proceedings
%T Multilingual Information Retrieval Based on Parallel Texts from the Web
%A Nie, Jian-Yun
%A Simard, Michel
%A Foster, George
%Y Peters, Carol
%S Cross-Language Information Retrieval and Evaluation
%D 2001
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44645-3
%F 10.1007/3-540-44645-1_18
%X In this paper, we describe our approach in CLEF Cross-Language IR (CLIR) tasks. In our experiments, we used statistical translation models for query translation. Some of the models are trained on parallel web pages that are automatically mined from the Web. Others are trained from bilingual dictionaries and lexical databases. These models are combined in query translation. Our goal in this series of experiments is to test if the parallel web pages can be used effectively to translate queries in multilingual IR. In particular, we compare models trained on Web documents with models that also combine other resources such as dictionaries. Our results show that the models trained on the parallel web pages can achieve reasonable CLIR performance. However, combining models effectively is a difficult task, and single models Zstill yield better results.
%P 188-201


%0 Conference Proceedings
%T What you saw is what you want: Using cases to seed information retrieval
%A Daniels, Jody J.
%A Rissland, Edwina L.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_503
%X This paper presents a hybrid case-based reasoning (CBR) and information retrieval (IR) system, called SPIRE, that both retrieves documents from a full-text document corpus and from within individual documents, and locates passages likely to contain information about important problem-solving features of cases. SPIRE uses two case-bases, one containing past precedents, and one containing excerpts from past case texts. Both are used by SPIRE to automatically generate queries, which are then run by the INQUERY full-text retrieval engine on a large text collection in the case of document retrieval and on individual text documents for passage retrieval.
%P 325-336


%0 Conference Proceedings
%T Induction of Recursive Theories in the Normal ILP Setting: Issues and Solutions
%A Esposito, Floriana
%A Malerba, Donato
%A Lisi, Francesca A.
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_6
%X Induction of recursive theories in the normal ILP setting is a complex task because of the non-monotonicity of the consistency property. In this paper we propose computational solutions to some relevant issues raised by the multiple predicate learning problem. A separate-and-parallel-conquer search strategy is adopted to interleave the learning of clauses supplying predicates with mutually recursive definitions. A novel generality order to be imposed to the search space of clauses is investigated in order to cope with recursion in a more suitable way. The consistency recovery is performed by reformulating the current theory and by applying a layering technique based on the collapsed dependency graph. The proposed approach has been implemented in the ILP system ATRE and tested in the specific context of the document understanding problem within the WISDOM project. Experimental results are discussed and future directions are drawn.
%P 93-111


%0 Conference Proceedings
%T Inductive Learning for Case-Based Diagnosis with Multiple Faults
%A Baumeister, Joachim
%A AtzmÃ¼ller, Martin
%A Puppe, Frank
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_4
%X We present adapted inductive methods for learning similarities, parameter weights and diagnostic profiles for case-based reasoning. All of these methods can be refined incrementally by applying different types of background knowledge. Diagnostic profiles are used for extending the conventional CBR to solve cases with multiple faults. The context of our work is to supplement a medical documentation and consultation system by CBR techniques, and we present an evaluation with a real-world case base.
%P 28-42


%0 Conference Proceedings
%T Reasoning with reasons in case-based comparisons
%A Ashley, Kevin D.
%A McLaren, Bruce M.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_13
%X In this work, we are interested in how rational decision makers reason with and about reasons in a domain, practical ethics, where they appear to reason about reasons symbolically in terms of both abstract moral principles and case comparisons. The challenge for reasoners, human and artificial, is to use abstract knowledge of reasons and principles to inform decisions about the salience of similarities and differences among cases while still accounting for a case's or problem's specific contextual circumstances. TRUTH-TELLER is a program we have developed and tested that compares pairs of cases presenting ethical dilemmas about whether to tell the truth. The program's methods for reasoning about reasons help it to make context sensitive assessments of the salience of similarities and differences.
%P 133-144


%0 Conference Proceedings
%T Massively parallel case-based reasoning with probabilistic similarity metrics
%A MyllymÃ¤ki, Petri
%A Tirri, Henry
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_83
%X We propose a probabilistic case-space metric for the case matching and case adaptation tasks. Central to our approach is a probability propagation algorithm adopted from Bayesian reasoning systems, which allows our case-based reasoning system to perform theoretically sound probabilistic reasoning. The same probability propagation mechanism actually offers a uniform solution to both the case matching and case adaptation problems. We also show how the algorithm can be implemented as a connectionist network, where efficient massively parallel case retrieval is an inherent property of the system. We argue that using this kind of an approach, the difficult problem of case indexing can be completely avoided.
%P 144-154


%0 Conference Proceedings
%T Information Extraction as a Stepping Stone toward Story Understanding
%A Riloff, Ellen
%D 1999
%X Historically, story understanding systems have depended on a great deal of hand-crafted knowledge. Natural language understanding systems that use conceptual knowledge structures [SA77, Cul78, Wil78, Car79, Leh81, Kol83] typically rely on enormous amounts of manual knowledge engineering. While much of the work on conceptual knowledge structures has been hailed as pioneering research in cognitive modeling and narrative understanding, from a practical perspective it has also been viewed with skepticism because of the underlying knowledge engineering bottleneck. The thought of building a large-scale conceptual natural language processing (NLP) system that can understand open-ended text is daunting even to the most ardent enthusiasts. So must we grit our collective teeth and assume that story understanding will be limited to prototype systems in the foreseeable future? Or will conceptual natural language processing ultimately depend on a massive, broad-scale manual knowledge engineering effort, such as CYC [LPS86]?


%0 Conference Proceedings
%T Discovering New Knowledge from Graph Data Using Inductive Logic Programming
%A Miyahara, Tetsuhiro
%A Shoudai, Takayoshi
%A Uchida, Tomoyuki
%A Kuboyama, Tetsuji
%A Takahashi, Kenichi
%A Ueda, Hiroaki
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_21
%X We present a method for discovering new knowledge from structural data which are represented by graphs in the framework of inductive logic programming. A graph, or network, is widely used for representing relations between various data and expressing a small and easily understandable hypothesis. Formal Graph System (FGS) is a kind of logic programming system which directly deals with graphs just like first order terms. By employing refutably inductive inference algorithms and graph algorithmic techniques, we are developing a knowledge discovery system KD-FGS, which acquires knowledge directly from graph data by using FGS as a knowledge representation language.
%P 222-233


%0 Conference Proceedings
%T Linguistic Annotation for the Semantic Web
%D 2003
%A Buitelaar, Paul
%A Declerck, Thierry
%X Establishing the semantic web on a large scale implies the widespread annotation of web documents with ontology-based knowledge markup. For this purpose, tools have been developed that allow for semi-automatic annotation of web documents with ontology-based metadata. However, given that a large number of web documents consist either fully or at least partially of free text, language technology tools will be needed to support this authoring process by providing an automatic analysis of the semantic structure of textual documents. In this way, free text documents will become available as semi-structured documents, from which meaningful units can be extracted automatically (information extraction) and organized through clustering or classification (text mining). Obviously, this is of importance for both knowledge markup and ontology development, i.e. the dynamic adaptation of ontologies to evolving applications and domains. In this paper we present the following linguistic analysis steps that underlie both of these: morphological analysis, part-of-speech tagging, chunking, dependency structure analysis, semantic tagging. Examples for each are given in the context of two projects that use linguistic and semantic annotation for the purpose of cross-lingual information retrieval and content-based multimedia access. 

%0 Journal Article
%T Japanese/English Cross-Language Information Retrieval: Exploration of Query Translation and Transliteration
%A Fujii, Atsushi
%A Ishikawa, Tetsuya
%J Computers and the Humanities
%D 2001
%X Cross-language information retrieval (CLIR), where queriesand documents are in different languages, has of late become one ofthe major topics within the information retrieval community. Thispaper proposes a Japanese/English CLIR system, where we combine aquery translation and retrieval modules. We currently target theretrieval of technical documents, and therefore the performance of oursystem is highly dependent on the quality of the translation oftechnical terms. However, the technical term translation is stillproblematic in that technical terms are often compound words, and thusnew terms are progressively created by combining existing basewords. In addition, Japanese often represents loanwords based on itsspecial phonogram. Consequently, existing dictionaries find itdifficult to achieve sufficient coverage. To counter the firstproblem, we produce a Japanese/English dictionary for base words, andtranslate compound words on a word-by-word basis. We also use aprobabilistic method to resolve translation ambiguity. For the secondproblem, we use a transliteration method, which corresponds wordsunlisted in the base word dictionary to their phonetic equivalents inthe target language. We evaluate our system using a test collectionfor CLIR, and show that both the compound word translation andtransliteration methods improve the system performance.


%0 Conference Proceedings
%T Cases as terms: A feature term approach to the structured representation of cases
%A Plaza, Enric
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_24
%P 265-276


%0 Conference Proceedings
%T Ranking and Selecting Synsets by Domain Relevance
%D 2001
%A Buitelaar, Paul
%A Dfki, Bogdan Sacaleanu
%XThe paper presents a novel method for domain specific sense assignment. The method determines the domain specific relevance of GermaNet synsets on the basis of the relevance of their constituent terms that cooccur within representative domain corpora. The approach is task independent and completely automatic. Experiments show results on three selected domains: business, soccer and medical. 

%0 Conference Proceedings
%T Adaptation through interpolation for time-critical case-based reasoning
%A Chatterjee, N.
%A Campbell, J. A.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_89
%X The paper introduces and examines the relevance of the notion of âinterpolationâ between case features, to facilitate fast adaptation of existing cases to a current situation. When this situation is time-critical there is not enough time for exhaustive comparison of various aspects of all the stored cases, so it may not be possible to retrieve a high-quality match for a current problem within a specified time-limit. Viewing imperfect adaptation as a process of interpolation (or a set of possible processes with different qualities of interpolation) then gives a robust and novel perspective for time-critical reasoning, as well as being equally relevant for case-based reasoning (CBR) in general. Although interpolation-like adaptation techniques have been used in some existing CBR systems, they have not previously been treated explicitly from this perspective.
%P 221-233


%0 Conference Proceedings
%T PBL: Prototype-based learning algorithm
%A Uehara, Kuniaki
%A Tanizawa, Masayuki
%A Maekawa, Sadao
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_92
%X In this paper, we will introduce an inductive learning algorithm called Prototype-Based Learning (PBL). PBL learns a concept description, which consists of both prototypical attributes and attribute importances, by using a distance metric based on prototype-theory and information-theory. PBL can learn the concept description from even a small set of training cases and is tolerant of inappropriate cases. Furthermore, even the attribute importance differs depending on the combinations of the other attribute-value pairs present describing the case, PBL can learn the concept description and highly utilize it so as to do the accurate classification. Finally, PBL can learn indexing knowledge directly from the concept description, which is useful for a human expert to understand and verify the concept description generated by the learning algorithm.
%P 261-273


%0 Journal Article
%T Analyses for Elucidating Current Question Answering Technology
%D 2001
%A Marc Light
%A Gideon S. Mann
%A Ellen Riloff
%A Eric Breck 
%X In this paper, we take a detailed look at the performance of components of an idealized question answering system on two different tasks: the TREC Question Answering task and a set of reading comprehension exams. We carry out three types of analysis: inherent properties of the data, feature analysis, and performance bounds. Based on these analyses we explain some of the performance results of the current generation of Q/A systems and make predictions on future work. In particular, we present four findings: (1) Q/A system performance is correlated with answer repetition; (2) relative overlap scores are more effective than absolute overlap scores; (3) equivalence classes on scoring functions can be used to quantify performance bounds; and (4) perfect answer typing still leaves a great deal of ambiguity for a Q/A system because sentences often contain several items of the same type.

%0 Conference Proceedings
%T Using case-based reasoning for reusing software knowledge
%A Tautz, Carsten
%A Althoff, Klaus-Dieter
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_488
%X Reuse of software knowledge is a principle for improving productivity and reliability of software development. To achieve this, reuse must be done systematically. This means that processes for retrieving, reusing, revising, and retaining have to be defined. At the same time organizational issues (such as the establishment of a separate organizational unit responsible for organizational learning) must be considered. In this paper we compare software knowledge reuse models to the CBR cycle of Aamodt and Plaza [1] and show that the approaches are very similar. We suggest to extend the CBR cycle by including organizational issues explicitly and conclude that CBR is a promising technology for realizing software knowledge reuse if our suggested organizational extensions are considered.
%P 156-165


%0 Conference Proceedings
%T Similarity Assessment for Generalizied Cases by Optimization Methods
%A Mougouie, Babak
%A Bergmann, Ralph
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_19
%X Generalized cases are cases that cover a subspace rather than a point in the problem-solution space. Generalized cases can be represented by a set of constraints over the case attributes. For such representations, the similarity assessment between a point query and generalized cases is a difficult problem that is addressed in this paper. The task is to find the distance (or the related similarity) between the point query and the closest point of the area covered by the generalized cases, with respect to some given similarity measure. We formulate this problem as a mathematical optimization problem and we propose a new cutting plane method which enables us to rank generalized cases according to their distance to the query.
%P 249-263


%0 Conference Proceedings
%T Cse-Based Quality Management System using Expectation Values
%A Taki, Hirokazu
%A Hori, Satoshi
%A Abe, Norihiro
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_42
%X This paper describes a quality management system (called CBQM: Case-Based Quality Management) using the case-based reasoning mechanism which is based on a cost expectation value. The cost expectation value is calculated from objective and subjective values. We developed a quality management system that emplys a stochastic method. However, in some cases, this stochastic-based system failed to select good cases. Therefore, we have integrated some expectation values into the case selection mechanism. The CBQM has an expectation measurement. Its case selection criteria use not only similarity, but also some expectation values. If unforeseen malfunctions may occur due to inappropriate design, manufacturing condition and/or unsuitable usage, the similarity is not enough to select useful cases from a casebase. That is because the similarity is mainly based on products themselves. The CBQM adopts the cost expectation value in order to pick up useful cases. The CBQMâs selection criteria is based on the wuality of cases, which considers repair time, repair part cost, trouble recurrence, the confidence of diagnosis and repair difficulty. We validated this system in real product repair problems which field servive engineers repair home appliances.
%P 572-580


%0 Conference Proceedings
%T Learning programs in the event calculus
%A Moyle, Stephen
%A Muggleton, Stephen
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_49
%X The event calculus is a formalism for reasoning about actions and change in dynamic systems. It has been used in diverse areas including planning and communications protocol specification. Writing event calculus programs requires the construction of domain specific axioms (DSAs) - a programming task which is non-trivial, and one that hinders the broader use of the event calculus. This work demostrates that such axioms can be learned from temporal observations using Inductive Logic programming (ILP) techniques, in particular theory c0ompletion. The theory of logical back-propagation as a mechanism for theory completion is described and its implementation in the ILP system Progol is used here. These techniques were used to investigate learning DSAS for the traditional AI blocks world. In the experiments Progol, utilising logical back-propagation, learned correct DSAs. These results provide encouragement and highlight the possibility of discovering causal relationships from data in temporal databases, and also learning the domain specific knowledge necessary in the development of plans.
%P 205-212


%0 Conference Proceedings
%T A knowledge level model of knowledge-based reasoning
%A Armengol, Eva
%A Plaza, Enric
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_76
%X We propose to analyze CBR systems at knowledge level following the Components of Expertise methodology. This methodology has been used for design and construction of KBS applications. We have applied it to analyze learning methods of existing systems at knowledge level. As example we develop the knowledge level analysis of CHEF. Then a common task structure of CBR systems is explained. We claim that this sort of analysis can be a first step to integrate different learning methods into case-based reasoning systems.
%P 51-64


%0 Conference Proceedings
%T Learning to Adapt for Case-Based Design
%A Wiratunga, Nirmalie
%A Craw, Susan
%A Rowe, Ray
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_31
%X Design is a complex open-ended task and it is unreasonable to expect a case-base to contain representatives of all possible designs. Therefore, adaptation is a desirable capability for case-based design systems, but acquiring adaptation knowledge can involve significant effort. In this paper adaptation knowledge is induced separately for different criteria associated with the retrieved solution, using knowledge sources implicit in the case-base. This provides a committee of learners and their combined advice is better able to satisfy design constraints and compatibility requirements compared to a single learner. The main emphasis of the paper is to evaluate the impact of specific-to-general and general-to-specific learning on adaptation knowledge acquired by committee members. For this purpose we conduct experiments on a real tablet formulation problem which is tackled as a decomposable design task. Evaluation results suggest that adaptation achieves significant gains compared to a retrieve-only CBR system, but shows that both learning biases can be beneficial for different decomposed sub-tasks.
%P 421-435


%0 Conference Proceedings
%T Learning to improve case adaptation by introspective reasoning and CBR
%A Leake, David B.
%A Kinley, Andrew
%A Wilson, David
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_21
%X In current CBR systems, case adaptation is usually performed by rule-based methods that use task-specific rules hand-coded by the system developer. The ability to define those rules depends on knowledge of the task and domain that may not be available a priori, presenting a serious impediment to endowing CBR systems with the needed adaptation knowledge. This paper describes ongoing research on a method to address this problem by acquiring adaptation knowledge from experience. The method uses reasoning from scratch, based on introspective reasoning about the requirements for successful adaptation, to build up a library of adaptation cases that are stored for future reuse. We describe the tenets of the approach and the types of knowledge it requires. We sketch initial computer implementation, lessons learned, and open questions for further study.
%P 229-240


%0 Conference Proceedings
%T Examining locally varying weights for nearest neighbor algorithms
%A Howe, Nicholas
%A Cardie, Claire
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_515
%X Previous work on feature weighting for case-based learning algorithms has tended to use either global weights or weights that vary over extremely local regions of the case space. This paper examines the use of coarsely local weighting schemes, where feature weights are allowed to vary but are identical for groups or clusters of cases. We present a new technique, called class distribution weighting (CDW), that allows weights to vary at the class level. We further extend CDW into a family of related techniques that exhibit varying degrees of locality, from global to local. The class distribution techniques are then applied to a set of eleven concept learning tasks. We find that one or more of the CDW variants significantly improves classification accuracy for nine of the eleven tasks. In addition, we find that the relative importance of classes, features, and feature values in a particular domain determines which variant is most successful.
%P 455-466


%0 Conference Proceedings
%T Repeat learning using predicate invention
%A Khan, Khalid
%A Muggleton, Stephen
%A Parson, Rupert
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027320
%X Most of machine learning is concerned with learning a single concept from a sequence of examples. In repeat learning the teacher chooses a series of related concepts randomly and independently from a distribution D. A finite sequence of examples is provided for each concept in the series. The learner does not initially know D, but progressively updates a posterior estimation of D as the series progresses. This paper considers predicate invention within Inductive Logic Programming as a mechanism for updating the learner's estimation of D. A new predicate invention mechanism implemented in Progol4.4 is used in repeat learning experiments within a chess domain. The results indicate that significant performance increases can be achieved. The paper develops a Bayesian framework and demonstrates initial theoretical results for repeat learning.
%P 165-174


%0 Conference Proceedings
%T Similarity Guided Learning of the Case Description and Improvement of the System Performance in an Image Classification System
%A Perner, Petra
%A Perner, Horst
%A MÃ¼ller, Bernd
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_44
%X The development of an automatic image classification system is a hard problem since such a system must imitate the visual strategy of a human expert when interpreting the particular image. Usually it is not easy to make this strategy explicit. Rather than describing the visual strategy and the image features human are able to judge the similarity between the objects. This judgement can be the basis for a guideline of the development process. This guideline can help the developer to understand what kind of case description/features are necessary for a sufficient system performance and can give an idea what system performance can be achieved. In the paper we describe a novel strategy which can support a developer in building image classification systems. The development process as well as the elicitation of the case description is similarity-guided. Based on the similarity between the objects the system developer can provide new image features and improve the system performance until a system performance is reached that fits to the experts understanding about the relationship among the different objects.
%P 604-612


%0 Conference Proceedings
%T Automating the construction of authority files in digital libraries: A case study
%A French, James C.
%A Powell, Allison L.
%A Schulman, Eric
%A Pfaltz, John L.
%Y Peters, Carol
%Y Thanos, Costantino
%S Research and Advanced Technology for Digital Libraries
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69597-4
%F 10.1007/BFb0026721
%X The issue of quality control has become increasingly important as more online databases are integrated into digital libraries. This can have a dramatic effect on the search effectiveness of an online system. Authority work, the need to discover and reconcile variant forms of strings in bibliographic entries, will become more difficult. Spelling variants, misspellings, translation and transliteration differences all increase the difficulty of retrieving information. This paper is a case study of our efforts to automate the creation of an authority file for authors' institutional affiliations in the Astrophysics Data System. The techniques surveyed here for the detection and categorization of variant forms have broader applicability and may be used to help automate authority work for other bibliographic fields.
%P 55-71


%0 Conference Proceedings
%T Route planning by analogy
%A Haigh, Karen Zita
%A Veloso, Manuela
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_16
%X There have been several efforts to create and use real maps in computer applications that automatically find good map routes. In general, online map representations do not include information that may be relevant for the purpose of generating good realistic routes, including for example traffic patterns, construction, or number of lanes. Furthermore, the notion of a good route is dependent on a variety of factors, such as the time of the day, and may also be user dependent. This motivation leads to our work on the accumulation and reuse of previously traversed routes as cases. In this paper, we demonstrate our route planning method which retrieves and reuses multiple past routing cases that collectively form a good basis for generating a new routing plan. We briefly present our similarity metric for retrieving a set of similar routes. The metric effectively takes into account the geometric and continuous-valued characteristics of a city map. We then present the replay mechanism and how the planner produces the route plan by analogizing from the retrieved similar past routes. We discuss in particular the strategy used to merge a set of cases and generate the new route. We use illustrative examples and show some empirical results from a detailed online map of the city of Pittsburgh containing over 18,000 intersections and 25,000 street segments.
%P 169-180


%0 Conference Proceedings
%T Similarity evaluation between observed behaviours for the prediction of processes
%A Rougegrez, Sophie
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_84
%X This article deals with the prediction of processes. Research work on this topic considers some well known processes. Their prediction is based on a model which takes precisely into account the influence of the parameters involved in the modification of their state. Such models are not conceivable here: the point is indeed of some processes that human beings control little, like forest fires, which is the subject of the system presented here. The reasoning that it uses relies on cases. We consider indeed that if two processes behaved the same way during a certain interval then their behaviours are very likely to be similar afterwards. The matching is based on an approximate string matching. Because of the complexity of the handled processes, points of view have been introduced. Their consideration requires a matching adapted to each one. They are presented here.
%P 155-166


%0 Conference Proceedings
%T Hybrid-search and storage of semi-structured information
%D 1998
%A Adar, Eytan
%X Given today's tangle of digital information, one of the hardest tasks for computer users of information systems is finding anything in the mess. For a number of well documented reasons including the amazing growth in the Internet's popularity and the drop in the cost of storage, the amount of information on the net as well as on a user's local computer, has increased dramatically in recent years. Although this readily available information should be extremely beneficial for computer users, paradoxically it is now much harder to find anything. Many different solutions have been proposed to the general information seeking task of users, but few if any have addressed the needs of individuals or have leveraged the benefit of single-user interaction. The Haystack project is an attempt to answer the needs of the individual user. Once the user's information is represented in Haystack, the types of questions users may ask are highly varied. In this thesis we will propose a means of representing information in a robust framework within Haystack. Once the information is represented we describe a mechanism by which the diverse questions of the individual can be answered. This novel method functions by using a combination of existing information systems. We will call this combined system a hybrid-search system.

%0 Conference Proceedings
%T Induction of Slovene nominal paradigms
%A DÅ¾eroski, SaÅ¡o
%A Erjavec, TomaÅ¾
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_42
%X The paper presents results of using FoIDL, an inductive logic programming system, to learn the inflectional paradigms of Slovene nouns. Foidl learns first-order decision lists, defined as ordered list of clauses; it has been previously tested on the problem of inducing rules for forming the past tense of English verbs. Slovene, unlike English, has rich inflectional morphology, and the paper reports the result of applying Foidl over a large lexicon of Slovene word-forms to induce rules for the synthesis and analysis of the full inflectional paradigms of Slovene nouns.
%P 141-148


%0 Conference Proceedings
%T Running head: TEXTUAL COHERENCE USING LATENT SEMANTIC ANALYSIS The Measurement of Textual Coherence with Latent Semantic Analysis
%D 1998
%A Foltz, Peter W.
%A Landauer, Thomas K.
%X Latent  Semantic  Analysis  is  used  as  a  technique  for  measuring  the  coherence  oftexts.  By comparing the vectors for two adjoining segments of text in a high-dimensional  semantic  space,  the  method  provides  a  characterization  of  the  degree  ofsemantic  relatedness  between  the  segments.    We  illustrate  the  approach  forpredicting coherence through re-analyzing sets of texts from two studies thatmanipulated  the  coherence  of  texts  and  assessed  readers'  comprehension.    Theresults indicate that the method is able to predict the effect of  text coherence oncomprehension  and  is  more  effective  than  simple  term-term  overlap  measures.    Inthis  manner,  LSA  can  be  applied  as  an  automated  method  that  produces  coherencepredictions  similar  to  propositional  modeling.    We  describe  additional  studiesinvestigating  the  application  of  LSA  to  analyzing  discourse  structure  and  examinethe potential of LSA as a psychological model of coherence effects in textcomprehension.

%0 Conference Proceedings
%T Case-based planning to learn
%A Murdock, J. William
%A Shippey, Gordon
%A Ram, Ashwin
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_516
%X Learning can be viewed as a problem of planning a series of modifications to memory. We adopt this view of learning and propose the applicability of the case-based planning methodology to the task of planning to learn. We argue that relatively simple, fine-grained primitive inferential operators are needed to support flexible planning. We show that it is possible to obtain the benefits of case-based reasoning within a planning to learn framework.
%P 467-476


%0 Conference Proceedings
%T Least generalizations under implication
%A Nienhuys-Cheng, Shan-Hwei
%A de Wolf, Ronald
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_61
%X One of the most prominent approaches in Inductive Logic Programming is the use of least generalizations under subsumption of given clauses. However, subsumption is weaker than logical implication, and not very well suited for handling recursive clauses. Therefore an important open question in this area concerns the existence of least generalizations under implication (LGIs). Our main new result in this paper is the existence and computability of such an LGI for any finite set of clauses which contains at least one non-tautologous function-free clause. We can also define implication relative to background knowledge. In this case, least generalizations only exist in a very limited case.
%P 283-298


%0 Conference Proceedings
%T Empirically Validated Web Page Design Metrics
%D 2001
%A Ivory, Melody Y.
%A Sinha, Rashmi R.
%A Hearst, Marti A.
%X A quantitative analysis of a large collection of expert-rated web sites reveals that page-level metrics can accurately predict if a site will be highly rated. The analysis also provides empirical evidence that important metrics, including page composition, page formatting, and overall page characteristics, differ among web site categories such as education, community, living, and finance. These results provide an empirical foundation for web site design guidelines and also suggest which metrics can be most important for evaluation via user studies.

%0 Conference Proceedings
%T Solution-relevant abstractions constrain retrieval and adaptation
%A Melis, Erica
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_508
%X Two major problems in case-based reasoning are the efficient and justified retrieval of source cases and the adaptation of retrieved solutions to the conditions of the target. For analogical theorem proving by induction, we describe how a solution-relevant abstraction can restrict the retrieval of source cases and the mapping from the source problem to the target problem and how it can determine reformulations that further adapt the source solution.
%P 383-392


%0 Conference Proceedings
%T Deleting and Building Sort Out Techniques for Case Base Maintenance
%A SalamÃ³, Maria
%A Golobardes, Elisabet
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_27
%X Early work on case based reasoning reported in the literature shows the importance of case base maintenance for successful practical systems. Different criteria to the maintenance task have been used for more than half a century. In this paper we present different sort out techniques for case base maintenance. All the sort out techniques proposed are based on the same principle: a Rough Sets competence model. First of all, we present sort out reduction techniques based on deletion of cases. Next, we present sort out techniques that build new reduced competent case memories based on the original ones. The main purpose of these methods is to maintain the competence and reduce, as much as possible, its size. Experiments using different domains, most of them from the UCI repository, show that the reduction techniques maintain the competence obtained by the original case memory. The results are analysed with those obtained using well-known reduction techniques.
%P 365-379


%0 Conference Proceedings
%T Lessons learned from deployed CBR systems and design decisions made in building a commercial CBR tool
%A Shimazu, Hideo
%A Takashima, Yosuke
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_487
%X This paper reports our experiences in several CBR system building projects. Based on the lessons learned in these projects, we have developed a help desk support tool, Help Desk Builder. It consists of a knowledge management tool and a customer information management tool. The knowledge management tool includes case-based retrieval functions. This paper focuses on the design decisions and architecture of the case-based functions in Help Desk Builder.
%P 144-155


%0 Conference Proceedings
%T A Knowledge-level Task Model of Adaptation in Case-Based Reasoning
%A Fuchs, BÃ©atrice
%A Mille, Alain
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_9
%X The adaptation step is central in case-based reasoning (CBR), because it conditions the obtaining of a solution to a problem. This step is difficult from the knowledge acquisition and engineering points of view. We propose a knowledge level analysis of the adaptation step in CBR using the reasoning task concept. Our proposal is based on the study of several CBR systems for complex applications which imply the adaptation task. Three of them are presented to illustrate our analysis. We sketch from this study a generic model of the adaptation process using the task concept. This model is in conformity with other CBR formal models.
%P 118-131


%0 Conference Proceedings
%T Learning Query Behavior in the Haystack System
%D 2000
%A Chien, Wendy S.
%X Haystack is a personalized information retrieval system that allows users to store, maintain, and query for information. This thesis describes how learning is added to the system so that when a user makes a query on a topic similar to a previous query, the system can use the relevance feedback information from before to provide an improved result set for the current query. The learning module was designed to be modular and extensible so more sophisticated learning algorithms and techniques can be easily implemented in the future. Testing of our system showed that learning based on relevance feedback somewhat improved the results of the queries.

%0 Conference Proceedings
%T Cost estimation of software projects through case base reasoning
%A Bisio, Rossella
%A Malabocchia, Fabio
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_2
%X One of the most challenging goals for the software development community is the definition and assessment of techniques and tools enabling the cost estimation of projects in the early phases of the software life cycle. Despite of the increasing needs and the available tools and methods, a satisfactory solution is still to be found.
%P 11-22


%0 Conference Proceedings
%T Efficient Similarity Determination and Case Construction Techniques for Case-Based Reasoning
%A Patterson, David W.
%A Rooney, Niall
%A Galushka, Mykola
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_22
%X In this paper, we present three techniques for knowledge discovery in case-based reasoning. The first two techniques D-HS and D-HS+SR are concerned with the discovery of similarity knowledge and operate on an uncompacted case-base while the third technique D-HS+PSR is concerned with the discovery of both similarity and case knowledge and operates on a compacted case-base. All three techniques provide a very efficient and competent means of similarity determination in CBR, which are empirically shown to be up to 25 times faster than k-NN without any loss in competency. D-HS+PSR proposes a novel approach to automatically engineering compact case-bases with a minimal overhead to the system, compared to other approaches such as case deletion/addition. Additionally as the approach provides a means for automatically reducing the number of cases required in the case-base without any loss in problem solving competency it has the greatest implication of the three techniques for reducing the effects of the utility problem in CBR.
%P 292-305


%0 Conference Proceedings
%T An Approach to Aggregating Ensembles of Lazy Learners That Supports Explanation
%A Zenobi, Gabriele
%A Cunningham, PÃ¡draig
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_32
%X Ensemble research has shown that the aggregated output of an ensemble of predictors can be more accurate than a single predictor. This is true also for lazy learning systems like Case-Based Reasoning (CBR) and k-Nearest-Neighbour. Aggregation is normally achieved by voting in classification tasks and by averaging in regression tasks. For CBR, this increased accuracy comes at the cost of interpretability however. If we consider the use of retrieved cases for explanation to be one of the advantages of CBR then this is lost in an ensemble. This is because a large number of cases will have been retrieved by the ensemble members. In this paper we present a new technique for aggregation that obtains excellent results and identifies a small number of cases for use in explanation. This new approach might be viewed as a transformation process whereby cases are transformed from their feature based representation to a representation based on the predictions of ensemble members. This new representation produces very accurate predictions and allows a small number of similar neighbours to be identified.
%P 436-447


%0 Conference Proceedings
%T Using Guidelines to Constrain Interactive Case-Based HTN Planning
%A MuÃ±oz-Avila, HÃ©ctor
%A McFarlane, Daniel C.
%A Aha, David W.
%A Breslow, Len
%A Ballas, â¡James A.
%A Nau, Dana S.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_21
%X This paper describes HICAP, a general-purpose, interactive case-based plan authoring architecture that can be applied to decision support tasks to yield a hierarchical course of action. It integrates a hierarchical task editor with a conversational case-based planner. HICAP maintains both a task hierarchy representing guidelines that constrain the final plan and the hierarchical social organization responsible for these tasks. It also supports bookkeeping, which is crucial for real-world large-scale planning tasks. By selecting tasks corresponding to the hierarchyâs leaf nodes, users can activate the conversational case-based planner to interactively refine guideline tasks into a concrete plan. Thus, HICAP can be used to generate context sensitive plans and should be useful for assisting with planning complex tasks such as noncombatant evacuation operations. We describe an experiment with a highly detailed military simulator to investigate this claim. The results show that plans generated by HICAP were superior to those generated by alternative approaches.
%P 288-302


%0 Conference Proceedings
%T An average-case analysis of k-nearest neighbor classifier
%A Okamoto, Seishi
%A Satoh, Ken
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_23
%X In this paper, we perform an average-case analysis of k-nearest neighbor classifier (k-NNC) for a subclass of Boolean threshold functions. Our average-case analysis is based on the formal computation for the predictive accuracy of the classifier under the assumption of noise-free Boolean features and a uniform instance distribution. The predictive accuracy is represented as a function of the number of features, the threshold, the number of training instances, and the number of nearest neighbors. We also present the predictive behavior of the classifier by systematically varying the values of the parameters of the accuracy function. We plot the behavior of the classifier by varying the value of k, and then we observe that the performance of the classifier improves as k increases, then reaches a maximum before starting to deteriorate. We further investigate the relationship between the number of training instances and the optimal value of k. We then observe that optimum k increases gradually as the number of training instances increases.
%P 253-264


%0 Conference Proceedings
%T Using introspective learning to improve retrieval in CBR: A case study in air traffic control
%A Bonzano, Andrea
%A Cunningham, PÃ¡draig
%A Smyth, Barry
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_500
%X We can learn a lot about what features are important for retrieval by comparing similar cases in a case-base. We can determine which features are important in predicting outcomes and we can assign weights to features accordingly. In the same manner we can discover which features are important in specific contexts and determine localised feature weights that are specific to individual cases. In this paper we describe a comprehensive set of techniques for learning local feature weights and we evaluate these techniques on a case-base for conflict resolution in air traffic control. We show how introspective learning of feature weights improves retrieval and how it can be used to determine context sensitive local weights. We also show that introspective learning does not work well in case-bases containing only pivotal cases because there is no redundancy to be exploited.
%P 291-302


%0 Conference Proceedings
%T Learning first-order acyclic Horn programs from entailment
%A Reddy, Chandra
%A Tadepalli, Prasad
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027308
%X In this paper, we consider learning first-order Horn programs from entailment. In particular, we show that any subclass of first-order acyclic Horn programs with constant arity is exactly learnable from equivalence and entailment membership queries provided it allows a polynomial-time subsumption procedure and satisfies some closure conditions. One consequence of this is that first-order acyclic determinate Horn programs with constant arity are exactly learnable from equivalence and entailment membership queries.
%P 23-37


%0 Conference Proceedings
%T ELSI: A Medical Equipment Diagnostic System
%A Cuddihy, Paul
%A Cheetham, William
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_30
%X A case-based reasoning system for diagnosing medical equipment, called ELSI, has been in use by the GE corporation since 1994. When a customer or field engineer calls the service center for help with a problem, the equipmentâs error log is automatically downloaded. In ninety seconds or less, ELSI displays a sorted list of the best-matching logs in a case base of previous known problems, shows the fix, service notes, explains which sections of the log match, and which fixes each section predicts. This diagnostic information allows the service center engineer to recommend a temporary work-around or remote fixes to a customer, or helps a field engineer show up on site with the right parts the first time.
%P 415-425


%0 Conference Proceedings
%T Integrated case-based building design
%A Hua, Kefeng
%A Smith, Ian
%A Faltings, Boi
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_106
%X A building design task can be viewed according to many different abstractions. For example, an architect views a building as a collection of spaces with particular properties, while a civil engineer might consider it to be a structure made up of load-bearing elements. In order to produce a workable design, it is important to be able to combine these different viewpoints. Difficulties associated with combining viewpoints lead to what we term the integration problem. The casebased design (CBD) methodology presented in this paper provides an opportunity to model the intentions of several professions and trades using cases of previous good designs. Therefore, CBD provides pre-formulated solutions to integration problems. We describe a prototype design system, Cadre, which applies CBD to several examples of building design.
%P 436-445


%0 Conference Proceedings
%T Using a case base of surfaces to speed-up reinforcement learning
%A Drummond, Chris
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_513
%X This paper demonstrates the exploitation of certain vision processing techniques to index into a case base of surfaces. The surfaces are the result of reinforcement learning and represent the optimum choice of actions to achieve some goal from anywhere in the state space. This paper shows how strong features that occur in the interaction of the system with its environment can be detected early in the learning process. Such features allow the system to identify when an identical, or very similar, task has been solved previously and to retrieve the relevant surface. This results in an orders of magnitude increase in learning rate.
%P 435-444


%0 Conference Proceedings
%T A new design and implementation of progol by bottom-up computation
%A Fujita, Hiroshi
%A Yagi, Naoki
%A Ozaki, Tomonobu
%A Furukawa, Koichi
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_54
%X This paper describes a parallel version of Progol based on MGTP which is a theorem prover employing bottom-up inference suitable for parallel implementation. Hypothesis formation in Progol, which is performed by top-down computation with Prolog in the sequential implementation, will be performed more efficiently by bottom-up computation with MGTP in the new implementation. For the Progol's generalto-specific search for hypotheses through the subsumption lattice, we developed a new way of calculating a heuristic function for the A*-like algorithm, which was also implemented with MGTP. Since MGTP already has very efficient parallel implementations on parallel inference machines, an efficient implementation of parallel-Progol will readily be realized as well.
%P 161-174


%0 Conference Proceedings
%T A New Approach for the Incremental Development of Adaptation Functions for CBR
%A Khan, Abdus Salam
%A Hoffmann, Achim
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_23
%X This paper introduces a new approach to building complex adaptation functions for case-based reasoning systems.
%P 260-272


%0 Conference Proceedings
%T Encouraging self-explanation through case-based tutoring: A case study
%A Redmond, Michael
%A Phillips, Susan
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_486
%X This paper presents a case-based tutor, CECELIA 1.1, that is based on techniques from CELIA, a computer model of case-based apprenticeship learning [Redmond 1992]. The teaching techniques include: interactive, step by step presentation of case solution steps, student predictions of an expert's actions, presentation of the expert's steps, student explanations of the expert's actions, and presentation of the expert's explanation. In addition, CECELIA takes advantage of a technique from VanLehn's [1987] SIERRA â presenting examples in an order so that solutions only differ by one branch, or disjunct, from previously presented examples. CECELIA relies on its teaching strategy encouraging greater processing of the examples by the student, rather than on embedding great amounts of intelligence in the tutor. CECELIA is implemented using HyperCard on an Apple Macintosh, and has been pilot tested with real students. The tests suggest that the approach can be helpful, but also suggest that eliciting self-explanations from students who normally do not self-explain may be challenging.
%P 132-143


%0 Conference Proceedings
%T Improving Full-Text Precision on Short Queries using Simple Constraints
%D 1996
%A Hearst, Marti A.
%X We show that two simple constraints, when applied to short user queries (on the order of 5{10 words) can yield precision scores comparable to or better than those achieved using long queries (50{85 words) at low document cuto levels. These constraints are meant to detect documents that have subtopic passages that includes the most important components of the query. The constraints are: (i) a simple Boolean constraint which requires the user to specify the query as a list of topics; this list is converted into a conjunct of disjuncts by the system, and (ii) a subtopic-sized proximity constraint imposed over the Boolean constraint. The vector space model is used to rank the documents that satisfy both constraints. Experiments run over 45 TREC queries show signi cant, almost consistent improvements over rankings that use no constraints. These results have important rami cations for interactive systems intended for casual users, such as those searching on the World Wide Web.

%0 Conference Proceedings
%T A case-based approach for developing writing tools aimed at non-native English users
%A AluÃ­sio, Sandra M.
%A Oliveira, Osvaldo N.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_12
%X A writing tool has been developed for helping non-native English users to produce a first draft of Introductory Sections of scientific papers. A corpus analysis was carried out in 54 papers of Experimental Physics which allowed one to identify the schematic structure of Introductions and 30 rhetorical strategies generally employed. Each one of the Introductions analysed constituted a case. The user chooses from menus features related to the rhetorical strategies for each component and gives the intended order for his/her Introduction, thus forming the requisition. Using three types of metric, the tool recovers the best-match cases that can be later modified in a revision process. Preliminary experiments showed that high precision and recall will only be obtained if the number of cases in the case base is considerably increased. In the revision process, four operations are suggested which consist in modifying/adding/deleting the different rhetorical messages that constitute the strategies of the chosen case.
%P 121-132


%0 Conference Proceedings
%T Handling Vague and Qualitative Criteria in Case-Based Reasoning Applications
%A Vollrath, Ivo
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_27
%X In some case-based reasoning (CBR) applications for decision support there are a number of vague or qualitative criteria that have to be taken into account by the similarity measure. Sometimes, these criteria are very hard to acquire or quantify and they often conflict with the âmainâ quality criterion that is measured by the similarity function. Surprisingly, this sometimes is true even for cost criteria (mostly believed to be quite quantitative): in certain applications, the acceptable cost limit depends mostly on the quality that is available and thus cannot be specified a priori. This paper discusses the problems arising from this kind of implicit criteria and shows approaches of how they can be integrated into the similarity measure of a case-based reasoning system without the need of artificially quantifying them.
%P 309-321


%0 Conference Proceedings
%T A Digital Libraries System based on Multi-level Agents
%D 1999
%A Hamard, K.
%A Nie, Jing
%A Bochmann, Gregor von
%A Godin, Robert
%A KerhervÃ©, Brigitte
%A Radhakrishnan, Thiruvengadam
%A Shinghal, Rajjan
%A Turner, James Milton
%A Berouti, Fadi
%A Ferrie, Frank P.
%X In this paper, we describe an agent-based architecture for digital library (DL) systems and its implementation. This architecture is inspired from Harvest and UMDL, but several extensions have been made. The most important extension concerns the building of multi-level indexing and cataloguing. Search agents are either local or global. A global search agent interacts with other agents of the system, and manages a set of local search agents. We extended the Z39.50 standard in order to support the visual characteristics of images and we also integrated agents for multilingual retrieval. This work shows that the agent-based architecture is flexible enough to integrate various kinds of agents and services in a single system.

%0 Conference Proceedings
%T Case-Based Reasoning for Antibiotics Therapy Advice
%A Schmidt, Rainer
%A Gierl, Lothar
%A Pollwein, Bernhard
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_40
%X In this paper, we describe case-based techniques in a medical application. We have developed a prototype of an antibiotics therapy adviser within the ICONS project, where the main advantage of applying CBR techniques is to speed-up the process of computing advisable therapies. However, some adaptations do not really belong to the Case-Based Reasoning paradigm though information from former cases is considered. They deal with rather typical medical tasks, namely modifications due to information updates. In our incrementally working system we have attempted to solve the problem of the continuously increasing number of stored cases by generalising from specific single cases to more general prototypes and by subsequently erasing redundant cases. Here we present results of experiments with threshold settings for our prototype architecture. The results show that the chosen design, which has mainly been founded on experiences with diagnostic applications, is not only advantageous for this therapeutic task, but that it contains a slight drawback as well.
%P 550-560


%0 Conference Proceedings
%T Detecting traffic problems with ILP
%A DÅ¾eroski, SaÅ¡o
%A Jacobs, Nico
%A Molina, Martin
%A Moure, Carlos
%A Muggleton, Stephen
%A Van Laer, Wim
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027332
%X Expert systems for decision support have recently been suc- cessfully introduced in road transport management. These systems include knowledge on traffic problem detection and alleviation. The paper describes experiments in automated acquisition of knowledge on traffic problem detection. The task is to detect road sections where a problem has occured (critical sections) from sensor data. It is necessary to use inductive logic programming (ILP) for this purpose as relational back- ground knowledge on the road network is essential. In this paper, we apply three state-of-the art ILP systems to learn how to detect traffic problems and compare their performance to the performance of a propositional learning system on the same problem.
%P 281-290


%0 Conference Proceedings
%T Generating, Visualizing, and Evaluating High-Quality Clusters for Information Organization
%D 1998
%A Aslam, Javed A.
%A Pelekhov, Katya
%A Rus, Daniela
%X We present and analyze the star clustering algorithm. We discuss an implementation of this algorithm that supports browsing and document retrieval through information organization. We define three parameters for evaluating a clustering algorithm to measure the topic separation and topic aggregation achieved by the algorithm. In the absence of benchmarks, we present a method for randomly generating clustering data. Data from our user study shows evidence that the star algorithm is effective for organizing information.


%0 Conference Proceedings
%T A Support System Based on CBR for the Design of Rubber Compounds in Motor Racing
%A Bandini, Stefania
%A Manzoni, Sara
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_30
%X This work presents P-Race, a knowledge-based system developed for the Motorsports Department of Pirelli Tyres. The system supports the formulation of rubber compounds of tyre tread, in order to take part (and win) in motor racing. Multiple knowledge representations have been adopted and integrated into a single Case-Based Reasoning (CBR) computational framework in order to capture the different competence involved in the decision making process. Moreover, a dedicated representation formalism called Abstract Compounds Machine (ACM) has been introduced in order to represent, compute, and integrate in the CBR architecture the core knowledge regarding rubber compounds. The result is a general case-based architecture where the adaptation step is demanded to a component based on the ACM model.
%P 348-357


%0 Conference Proceedings
%T SCAN YOUR LIFE: Integrating OCR into your Personal Haystack!
%D 2000
%A Holt, A. L.
%X built a self-serve OCR station where anybody can scan in documents at high-speed -- a public yet private ATM that accepts document deposits of a wider assortment than just checks. Depending on whether you scan a business card, an article or your entire filing cabinet, CPU-intensive recognition continues after you leave the station, and you are emailed options for secure web pickup. Users of MIT's Haystack personal repositories can even do "1-click" merging of o ine literary artifacts into their online lives. The paperless pipe dream may never happen, but cheap digital optics and a mundane 40-year old technology (OCR) are converging to change the game. The mindless convenience of my $6000 kiosk suggests OCR will become a regulated munition in the coming intellectual property and privacy wars. As OCR proliferates into cheap PDA's, neither publisher nor individual may ever again rely on humanity's oldest form of copy protection: paper.
%0 Conference Proceedings
%T Maximum Entropy modeling with Clausal Constraints
%A Dehaspe, Luc
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_39
%X We present the learning system Maccent which addresses the novel task of stochastic MAximum ENTropy modeling with Clausal Constraints. Maximum Entropy method is a Bayesian method based on the principle that the target stochastic model should be as uniform as possible, subject to known constraints. Maccent incorporates clausal constraints that are based on the evaluation of Prolog clauses in examples represented as Prolog programs. We build on an existing maximum-likelihood approach to maximum entropy modeling, which we upgrade along two dimensions: (1) Maccent can handle larger search spaces, due to a partial ordering defined on the space of clausal constraints, and (2) uses a richer first-order logic format. In comparison with other inductive logic programming systems, MACCENT seems to be the first that explicitly constructs a conditional probability distribution p(C|I) based on an empirical distribution $$\tilde p$$(C|I) (where p(C|I) ($$\tilde p$$(C|I)) equals the induced (observed) probability of an instance I belonging to a class C). First experiments indicate MACCENT may be useful for prediction, and for classification in cases where the induced model should be combined with other stochastic information sources.
%P 109-124


%0 Conference Proceedings
%T Automatically Selecting Strategies for Multi-Case-Base Reasoning
%A Leake, David B.
%A Sooriamurthi, Raja
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_16
%X Case-based reasoning (CBR) systems solve new problems by retrieving stored prior cases, and adapting their solutions to fit new circumstances. Traditionally, CBR systems draw their cases from a single local case-base tailored to their task. However, when a systemâs own set of cases is limited, it may be beneficial to supplement the local case-base with cases drawn from external case-bases for related tasks. Effective use of external case-bases requires strategies for multi-case-base reasoning (MCBR): (1) for deciding when to dispatch problems to an external case-base, and (2) for performing cross-case-base adaptation to compensate for differences in the tasks and environments that each case-base reflects. This paper presents methods for automatically tuning MCBR systems by selecting effective dispatching criteria and cross-case-base adaptation strategies. The methods require no advance knowledge of the task and domain: they perform tests on an initial set of problems and use the results to select strategies reflecting the characteristics of the local and external case-bases. We present experimental illustrations of the performance of the tuning methods for a numerical prediction task, and demonstrate that a small sample set can be sufficient to make high-quality choices of dispatching and cross-case-base adaptation strategies.
%P 204-218


%0 Conference Proceedings
%T Combining statistical and relational methods for learning in hypertext domains
%A Slattery, SeÃ¡n
%A Craven, Mark
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027309
%X We present a new approach to learning hypertext classifiers that combines a statistical text-learning method with a relational rule learner. This approach is well suited to learning in hypertext domains because its statistical component allows it to characterize text in terms of word frequencies, whereas its relational component is able to describe how neighboring documents are related to each other by hyperlinks that connect them. We evaluate our approach by applying it to tasks that involve learning definitions for (i) classes of pages; (ii) particular relations that exist between pairs of pages, and (iii) locating a particular class of information in the internal structure of pages. Our experiments demonstrate that this new approach is able to learn more accurate classifiers than either of its constituent methods alone.
%P 38-52


%0 Conference Proceedings
%T Using case-based reasoning to focus model-based diagnostic problem solving
%A Portinale, Luigi
%A Torasso, Pietro
%A Ortalda, Carlo
%A Giardino, Antonio
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_97
%X The aim of this paper is to present an approach to the integration of Case-Based Reasoning with Model-Based Reasoning in diagnostic problem solving. Such an integration is exploited by defining adaptation criteria on solutions retrieved by a case-based reasoner, in order to focus the model-based reasoner in the search for the solution of the current case and avoiding, as much as possible, the computation of the solution from scratch. Such adaptation criteria strictly rely on a formad theory of diagnosis that allows us to define different adaptation levels, relative to the trade-off between âaccuracy of the solutionâ and âcomputational effortâ. A simple example in the domain of car engine faults is presented and some important aspects are finally pointed out on the basis of our preliminary experiments.
%P 325-337


%0 Conference Proceedings
%T Case-Based Reasoning with Confidence
%A Cheetham, William
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_3
%X A case-based reasoning system can produce both a solution and an estimate of the confidence in that solution. The confidence value can be used to determine whether the solution does or does not have the needed accuracy. A statistical method can be used to compute a confidence value from information generated during the case-based reasoning process. This confidence value allows users to know when the results of the system should and should not be used.
%P 15-25


%0 Conference Proceedings
%T Realizing Progol by forward reasoning
%A Ozaki, Tomonobu
%A Furukawa, Koichi
%A Murakami, Tomoko
%A Ueno, Ken
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_51
%X Current implementation of coverage check for evaluating the candidate hypothesis in A'-like search in Progol is based on backward reasoning of Prolog. But it contains some kinds of redundancy. In this paper, we propose an alternative algorithm based on forward reasoning of extended MGTP (Model Generation Theorem Prover). Since this alternative can remove the redundant computations, we can expect to realize a more efficient search process.
%P 227-234


%0 Conference Paper
%T Little Words Can Make a Big Difference for Text Classification
%D 1995
%A Ellen Riloff 
%X Most information retrieval systems use stopword lists and stemming algorithms. However, we have found that recognizing singular and plural nouns, verb forms, negation, and prepositions can produce dramatically different text classification results. We present results from text classification experiments that compare relevancy signatures, which use local linguistic context, with corresponding indexing terms that do not. In two different domains, relevancy signatures produced better results than the simple indexing terms. These experiments suggest that stopword lists and stemming algorithms may remove or conflate many words that could be used to create more effective indexing terms.

%0 Conference Proceedings
%T Fuzzy modelling of case-based reasoning and decision
%A Dubois, Didier
%A Esteva, Francesc
%A Garcia, Pere
%A Godo, Lluis
%A de MÃ¡ntaras, Ramon L.
%A Prade, Henri
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_528
%X This paper is an attempt at providing a fuzzy set-based formalization of case-based reasoning. The proposed approach, which does not take into account the learning aspects of case-based reasoning, assumes a principle stating that âthe more similar are the problem description attributes, the more similar are the outcome attributesâ. A weaker form of this principle is also considered. These two forms of the case-based reasoning principle are modelled in terms of fuzzy rules. Then an approximate reasoning machinery taking advantage of this principle enables us to apply the information stored in the memory of precedent cases to the current problem. A particular instance of case-based reasoning, named case-based decision, is especially investigated. A logical model of case-based inference is also described.
%P 599-610


%0 Conference Proceedings
%T 1BC: A First-Order Bayesian Classifier
%A Flach, Peter
%A Lachiche, Nicolas
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_10
%X In this paper we present 1BC, a first-order Bayesian Classifier. Our approach is to view individuals as structured terms, and to distinguish between structural predicates referring to subterms (e.g. atoms from molecules), and properties applying to one or several of these subterms (e.g. a bond between two atoms). We describe an individual in terms of elementary features consisting of zero or more structural predicates and one property; these features are considered conditionally independent following the usual naive Bayes assumption. 1BC has been implemented in the context of the first-order descriptive learner Tertius, and we describe several experiments demonstrating the viability of our approach.
%P 92-103


%0 Conference Proceedings
%T Case-Based reasoning in an ultrasonic rail-inspection system
%A Jarmulak, Jacek
%A Kerckhoffs, Eugene J. H.
%A van't Veen, Peter Paul
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_477
%X Non-destructive testing (NDT) is often used for periodical inspection of infrastructure (e.g. railroads, pipelines). The inspection results in huge amounts of data which usually has to be analysed by an operator (or a team of operators) for occurrence of defect indications. This paper presents an example of use of case-based reasoning in interpretation of data from non-destructive testing, namely, a prototype for classification of images from an ultrasonic rail-inspection system. The reasons for the choice of case-based reasoning instead of statistical classification or a rule-based expert-system approach are explained. The overall design of the prototype is described and observations and conclusions relating to the prototype and generally to the use of CBR for NDT are presented.
%P 43-52


%0 Conference Paper
%T CorpusÂ­Based Identification of NonÂ­Anaphoric Noun Phrases
%D %D 1999
%A David L. Bean
%A Ellen Riloff 
%X Coreference resolution involves finding antecedents for anaphoric discourse entities, such as definite noun phrases. But many definite noun phrases are not anaphoric because their meaning can be understood from general world knowledge (e.g., "the White House" or "the news media"). We have developed a corpus-based algorithm for automatically identifying definite noun phrases that are non-anaphoric, which has the potential to improve the efficiency and accuracy of coreference resolution systems. Our algorithm generates lists of non-anaphoric noun phrases and noun phrase patterns from a training corpus and uses them to recognize non-anaphoric noun phrases in new texts. Using 1600 MUC-4 terrorism news articles as the training corpus, our approach achieved 78% recall and 87% precision at identifying such noun phrases in 50 text documents.

%0 Conference Proceedings
%T Ocram-CBR: A Shell for Case-Based Educational Systems
%A Papagni, Marco
%A Cirillo, Vincenzo
%A Micarelli, Alessandro
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_483
%X This paper presents a case-based authoring system for training and educational applications. The system, called Ocram-CBR and developed in JAVA(tm), can plan lessons for any application domain whatsoever. Ocram-CBR contains a User Modeling module, capable of building a representation of the user objectives and characteristics, that allows personalizing the teaching interaction. A distinguishing feature of the User Modeling module is the use of a hybrid approach, in which case-based components and an artificial neural network are integrated into one coherent system so that each component performs the tasks for which it is best suited. The Training module of Ocram-CBR plans lessons using a library of cases indexed and successively retrieved by means of a discrimination search and serial search. The system has been adapted for a training course in âInformation Systemsâ and for a second application which will teach learners to write business letters more effectively.
%P 104-113


%0 Conference Proceedings
%T Managing Complex Knowledge in Natural Sciences
%A Conruyt, NoÃ«l
%A Grosser, David
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_29
%X In many fields dependant upon complex observation, the structuring, depiction and treatment of knowledge can be of great complexity. For example in Systematics, the scientific discipline that investigates bio-diversity, the descriptions of specimens are often highly structured (composite objects, taxonomic attributes), noisy (erroneous or unknown data), and polymorphous (variable or imprecise data). In this paper, we present IKBS, an Iterative Knowledge Base System for dealing with such complex phenomena. The originality of this system is to implement the scientific method in biology: experimenting (learning rules from examples) and testing (identifying new individuals, improving the initial model and descriptions). This methodology is applied in the following ways in IKBS: 1 - Knowledge is acquired through a descriptive model that suits the semantic demand of experts. 2 - Knowledge is processed with an algorithm derived from C4.5 in order to take into account structured knowledge introduced in the previous descriptive model of the domain. 3 - Knowledge is refined through the use of an iterative process to evaluate the robustness of the descriptive model and descriptions. The IKBS system is presented here as a life science application facilitating the identification of coral specimens of the family PocilloporidÃ¦.
%P 401-415


%0 Conference Proceedings
%T Searching the Subsumption Lattice by a Genetic Algorithm
%A Tamaddoni-Nezhad, Alireza
%A Muggleton, Stephen H.
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_15
%X A framework for combining Genetic Algorithms with ILP methods is introduced and a novel binary representation and relevant genetic operators are discussed. It is shown that the proposed representation encodes a subsumption lattice in a complete and compact way. It is also shown that the proposed genetic operators are meaningful and can be interpreted in ILP terms such as lgg(least general generalization) and mgi(most general instance). These operators can be used to explore a subsumption lattice efficiently by doing binary operations (e.g. and/or). An implementation of the proposed framework is used to combine Inverse Entailment of CProgol with a genetic search.
%P 243-252


%0 Conference Proceedings
%T Case Acquisition in a Project Planning Environment
%A Mukkamalla, Sasidhar
%A MuÃ±oz-Avila, HÃ©ctor
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_20
%X In this paper, we propose an approach to acquire cases in the context of project planning, without any extra effort from the end user. Under our definition, a case has a one to one correspondence with the standard elements of a project plan. We exploit this correspondence to capture cases automatically from project planning episodes. We provide an algorithm for extracting cases from project plans. We implemented this algorithm on top of a commercial project-planning tool and perform experiments evaluating our approach.
%P 264-277


%0 Conference Proceedings
%T Maintaining Case-Based Reasoning Systems Using Fuzzy Decision Trees
%A Shiu, Simon Chi Keung
%A Sun, Cai Hung
%A Wang, Xi Zhao
%A Yeung, Daniel So
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_25
%X This paper proposes a methodology of maintaining Case Based Reasoning (CBR) systems by using fuzzy decision tree induction - a machine learning technique. The methodology is mainly based on the idea that a large case library can be transformed to a small case library together with a group of adaptation rules, which are generated by fuzzy decision trees. Firstly, an approach to learning feature weights automatically is used to evaluate the importance of different features in a given case-base. Secondly, clustering of cases will be carried out to identify different concepts in the case-base using the acquired feature knowledge. Thirdly, adaptation rules will be mined for each concept using fuzzy decision trees. Finally, a selection strategy based on the concepts of Îµ-coverage and Îµ-reachability is used to select representative cases. The effectiveness of the method is demonstrated experimentally using two sets of testing data.
%P 285-296


%0 Conference Proceedings
%T Search and Adaptation in a Fuzzy Object Oriented Case Base
%A Ruet, Magali
%A Geneste, Laurent
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_26
%X In this paper we propose to represent a case using an object oriented model that enables the description of imprecise knowledge using possibility distributions. The proposed search process is based on this modeling and a fuzzy similarity measure is defined. The adaptation process is achieved with propagation of domain constraints in a neighborhood of the retrieved case. We propose a method to define this neighborhood. We illustrate our proposition by an example in the field of machining operation configuration.
%P 350-364


%0 Conference Proceedings
%T Supporting Reusability in a System Design Environment by Case-Based Reasoning Techniques
%A Praehofer, Herbert
%A Kerschbaummayr, Josef
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_39
%X CASA (computer aided systems architecting) is a methodology and tool to support the design of complex technical systems. It combines approaches from systems and requirement engineering and AI. System design in CASA is requirement-driven and works by a hierarchical stepwise top-down refinement of designs and a hierarchical decision making process. One important task in CASA deals with reusability of existing design artifacts and is supported by case-based reasoning techniques. Based on given structural specifications and formal requirements, a search procedure finds the best inexact match in a design base and computes an estimated degree of fulfillment for requirements. The approach employs efficient graph matching and indexing scheme for case retrieval and structural similarities and has adapted usual similarity measures to compute degree of fulfillment of requirements. It has been show by different example projects that the developed methods can be of great practical assistance for a designer.
%P 535-549


%0 Conference Proceedings
%T Distance between Herbrand interpretations: A measure for approximations to a target concept
%A Nienhuys-Cheng, Shan-Hwei
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_50
%X We can use a metric to measure the differences between elements in a domain or subsets of that domain (i.e. concepts). Which particular metric should be chosen, depends on the kind of difference we want to measure. The well known Euclidean metric on ân and its generalizations are often used for this purpose, but such metrics are not always suitable for concepts where elements have some structure different from real numbers. For example, in (Inductive) Logic Programming a concept is often expressed as an Herbrand interpretation of some firstorder language. Every element in an Herbrand interpretation is a ground atom which has a tree structure. We start by defining a metric d on the set of expressions (ground atoms and ground terms), motivated by the structure and complexity of the expressions and the symbols used therein. This metric induces the Hausdorff metric h on the set of all sets of ground atoms, which allows us to measure the distance between Herbrand interpretations. We then give some necessary and some sufficient conditions for an upper bound of h between two given Herbrand interpretations, by considering the elements in their symmetric difference.
%P 213-226


%0 Conference Proceedings
%T Estimating software development effort with case-based reasoning
%A Finnie, G. R.
%A Wittig, G. E.
%A Desharnais, J. -M.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_474
%X Software project effort estimation is a difficult problem complicated by a variety of interrelated factors. Current regression-based models have not had much success in accurately estimating system size. This paper describes a case based reasoning approach to software estimation which performs somewhat better than regression models based on the same data and which has some similarity to human expert judgement approaches. An analysis is performed to determine whether different forms of averaging and adaptation improve the overall quality of the estimate.
%P 13-22


%0 Conference Proceedings
%T Approximate ILP Rules by Backpropagation Neural Network: A Result on Thai Character Recognition
%A Kijsirikul, Boonserm
%A Sinthupinyo, Sukree
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_16
%X This paper presents an application of Inductive Logic Programming (ILP) and Backpropagation Neural Network (BNN) to the problem of Thai character recognition. In such a learning problem, there exist several different classes of examples; there are 77 different Thai characters. Using examples constructed from character images, ILP learns 77 rules each of which defines each character. However, some unseen character images, especially the noisy images, may not exactly match any learned rule, i.e., they may not be covered by any rule. Therefore, a method for approximating the rule that best matches the unseen data is needed. Here we employ BNN for finding such rules. Experimental results on noisy data show that the accuracy of rules learned by ILP without the help of BNN is comparable to other methods. Furthermore, combining BNN with ILP yields the significant improvement and surpasses the other methods tested in our experiment.
%P 162-173


%0 Conference Proceedings
%T On the automatic generation of case libraries by chunking chess games
%A Flinter, Stephen
%A Keane, Mark T.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_38
%X As a research topic computer game playing has contributed problems to AI that manifest exponential growth in the problem space. For the most part, in games such as chess and checkers these problems have been surmounted with enormous computing power on brute-force search methods using massive databases. It remains to be seen whether such techniques will extend to other games such as go and shogi. One suggestion is that these games and even chess might benefit from a knowledge-based treatment but such approaches have met with limited success. The problem, as ever from such approaches, is the characterisation of the knowledge to be used by the system. This paper deals with the Tal system, which employs case-based reasoning techniques for chess playing. In the paper, rather than focus on playing, we concentrate on the automatic generation of suitable case knowledge using a chunking technique on a corpus of grandmaster games.
%P 421-430


%0 Conference Proceedings
%T Inductive logic program synthesis with DIALOGS
%A Flener, Pierre
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_55
%X DIALOGS (Dialogue-based Inductive and Abductive LOGic program Synthesizer) is a schema-guided synthesizer of recursive logic programs; it takes the initiative and queries a (possibly computationally naive) specifier for evidence in her/his conceptual language. The specifier must know the answers to such simple queries, because otherwise s/he wouldn't even feel the need for the synthesized program. DIALOGS can be used by any learner (including itself) that detects, or merely conjectures, the necessity of invention of a new predicate. Due to its foundation on a powerful codification of a ârecursion-theoryâ (by means of the template and constraints of a divide-and-conquer schema), DIALOGS needs very little evidence and is very fast.
%P 175-198


%0 Conference Proceedings
%T Displaying Dynamic Information
%D 2001
%A Teevan, Jaime
%X In this paper I introduce the problem of displaying dynamic information. I give several examples where an individual must interact with information that is changing beyond her control. The challenge in displaying this information is to discover how the user's context can be maintained while giving her access to the new information that becomes available. The user should feel in control of the information despite the fact that it is changing. This can be done effectively by understanding what conceptual anchors the user creates into the data, and keeping them constant while changing the other information as needed. 

%0 Conference Proceedings
%T How Well Can Passage Meaning be Derived without Using Word Order? A Comparison of Latent Semantic Analysis and Humans
%D 1997
%A Landauer, Thomas K.
%A Laham, Darrell
%A Rehder, Bob
%A Schreiner, Maureen Elizabeth
%X How much of the meaning of a naturally occurring English passage is derivable from its combination of words without considering their order? An exploratory approach to this question was provided by asking humans to judge the quality and quantity of knowledge conveyed by short student essays on scientific topics and comparing the interrater reliability and predictive accuracy of their estimates with the performance of a corpus-based statistical model that takes no account of word order within an essay. There was surprisingly little difference between the human judges and the model. In the studies reported here, experts were asked to read short student essays about scientific topics with the goal of determining how much knowledge was accurately reflected in a given essay. We measured the readersâ success by how well their ratings agreed with each other and how well they predicted scores on an objective test on the same subject. All current accounts of human discourse understanding.

%0 Conference Proceedings
%T KBS maintenance as learning two-tiered domain representation
%A Agre, Gennady
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_11
%X The paper deals with the problem of improving problem-solving behavior of traditional KBS in the course of its real operation which is a part of the maintenance task. The solution of the problem is searched in integration of the KBS with a specially designed case-based reasoning module used for correcting solutions produced by the KBS. Special attention is paid to the methods of case matching and reconciling conflicts between CBR and RBR. The proposed solution for both problems is based on treating the maintenance task as a problem for learning two-tiered domain representation. From this view point rules form the first domain tier reflecting existing strong patterns in the representation of domain concepts, while the second tier is formed by the newly solved cases along with a special domain-dependent procedure for case matching. The main ideas of the approach are illustrated by the results of some experiments with the experimental system CoRCase.
%P 109-120


%0 Conference Proceedings
%T Function-free Horn clauses are hard to approximate
%A Nock, Richard
%A Jappy, Pascal
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027323
%X In this paper, we show two hardness results for approximating the best function-free Horn clause by an element of the same class. Our first result shows that for some constant k > 0, the error rate of the best k-Horn clause cannot be approximated in polynomial time to within any constant factor by an element of the same class. Our second result is much stronger. Under some frequently encountered complexity hypothesis, we show that if we replace the constant number of Horn clauses by a small, poly-logarithmic number, the constant factor blows up exponentially to a quasi-polynomial factor nlogkn, where n is the number of predicates of the problem, a measure of its complexity. Our main result links the difficulty of error approximation with the number of clauses allowed. We finally give an outline of the incidence of our result on systems that learn using ILP (Inductive Logic Programming) formalism.
%P 195-204


%0 Conference Proceedings
%T Induction of Constraint Grammar-rules using Progol
%A Eineborg, Martin
%A Lindberg, Nikolaj
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027315
%X The paper reports a pilot study aiming at inducing rules for disambiguating words with different possible part of speech readings in unrestricted Swedish text. The rules, which are inspired by Constraint Grammar, are learnt using the Progol inductive logic programming system. The training data is sampled from the part of speech tagged one million word Stockholm-UmeÃ¥ Corpus. The results show that the induction of disambiguation rules using Progol is a realistic way of learning rules of good quality with a minimum of manual effort. When tested on unseen data, 97% of the words retain the correct reading after tagging leaving an ambiguity of 1.15 readings per word.
%P 116-124


%0 Journal Article
%T Looking Under the Hood : Tools for Diagnosing your Question Answering Engine
%J ArXiv
%D 2001
%A Breck, Eric
%A Light, Marc
%A Mann, Gideon S.
%A Riloff, Ellen
%A Brown, Brianne
%A Anand, Pranav
%A Rooth, Mats
%A Thelen, Michael
%X In this paper we analyze two question answering tasks : the TREC-8 question answering task and a set of reading comprehension exams. First, we show that Q/A systems perform better when there are multiple answer opportunities per question. Next, we analyze common approaches to two subproblems: term overlap for answer sentence identification, and answer typing for short answer extraction. We present general tools for analyzing the strengths and limitations of techniques for these subproblems. Our results quantify the limitations of both term overlap and answer typing to distinguish between competing answer candidates.

%0 Conference Proceedings
%T Flexibly Interleaving Processes
%A Melisâ, Erica
%A Ullrich, Carsten
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_19
%X We discuss several problems of analogy-driven proof plan construction which prevent a solution for more difficult target problems or make a solution very expensive. Some of these problems are due to the previously assumed fixed order of matching, reformulation, and replay in case-based reasoning and from a too restricted combination of planning from first principles with the analogy process. In order to overcome these problems we suggest to interleave matching and replay as well as casebased planning with planning from first principles.
%P 263-275


%0 Conference Proceedings
%T From troubleshooting to process design: Closing the manufacturing loop
%A Price, C. J.
%A Pegler, I. S.
%A Ratcliffe, M. B.
%A McManus, A.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_484
%X This paper describes the dual use of a case base for diagnosis and for improving the design of a manufacturing process. In the short term, the case base is used to provide past experience in dealing with similar problems during the manufacture of aluminum components. In the longer term, it is used to feed that experience into the design of the manufacturing process for new components.
%P 114-121


%0 Conference Proceedings
%T A Case-based approach for elaboration of design requirements
%A Gomes, Paulo
%A Bento, Carlos
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_476
%X The process of Case-Based Creative Design comprises: problem specification, problem elaboration, case retrieval, case adaptation, and verification. Problem specification and elaboration are crucial stages in the design process. Notwithstanding most of the current systems do not address this phase, assuming that the problem is well defined and complete, which is not a valid assumption for most of the situations.
%P 33-42


%0 Conference Proceedings
%T An explicit representation of reasoning failures
%A Cox, Michael T.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_493
%X This paper focuses upon the content and the level of granularity at which representations for the mental world should be placed in case-based explainers that employ introspective reasoning. That is, for a case-based reasoning system to represent thinking about the self, about the states and processes of reasoning, at what level of detail should one attempt to declaratively capture the contents of thought? Some claim that a mere set of two mental primitives are sufficient to represent the utterances of humans concerning verbs of thought such as âI forgot his birthday.â Alternatively, many in the CBR community have built systems that record elaborate traces of reasoning, keep track of knowledge dependencies or inference, or encode much metaknowledge concerning the structure of internal rules and defaults. The position here is that a system should be able instead to capture enough details to represent causally a common set of reasoning failure symptoms. I propose a simple model of expectation-driven reasoning, derive a taxonomy of reasoning failures from the model, and present a declarative representation of the failure symptoms that have been implemented in a CBR simulation. Such representations enable a system to explain reasoning failures by mapping from symptoms of the failures to causal factors involved.
%P 211-222


%0 Conference Proceedings
%T An investigation of marker-passing algorithms for analogue retrieval
%A Wolverton, Michael
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_32
%X If analogy and case-based reasoning systems are to scale up to very large case bases, it is important to analyze the various methods used for retrieving analogues to identify the features of the problem for which they are appropriate. This paper reports on one such analysis, a comparison of retrieval by marker passing or spreading activation in a semantic network with Knowledge-Directed Spreading Activation, a method developed to be well-suited for retrieving semantically distant analogues from a large knowledge base. The analysis has two complementary components: (1) a theoretical model of the retrieval time based on a number of problem characteristics, and (2) experiments showing how the retrieval time of the approaches varies with the knowledge base size. These two components, taken together, suggest that KDSA is more likely than SA to be able to scale up to retrieval in large knowledge bases.
%P 359-370


%0 Conference Proceedings
%T Audio Information Retrieval (AIR) Tools
%D 2000
%A Cook, Perry R.
%A Tzanetakis, George
%X Most of the work in music Information Retrieval (MIR) and analysis has been performed using symbolic representation like MIDI. The recent advances in computing power and network connectivity have made large amounts of raw digital audio data available in the form of unstructured monolithic sound files. In this work the focus is on tools that work directly on real world audio data without attempting to transcribe the music. To distinguish from symbolicâbased music IR for the remainder of the paper we use the term audio IR (AIR) to refer to techniques that work directly on raw audio signals. Obviously these signals can contain music as well as other types of audio like speech. We describe a series of tools based on current and newly developed techniques for AIR integrated under MARSYAS, our framework for audio analysis. For related work refer to (Foote, 1999). The tools developed are based on Signal Processing, Pattern Recognition and Visualization techniques. Finally, due to the immature state of the available techniques and to the inherent complexity of the task it is important to take advantage of the human user in the system. We have developed two user interfaces to integrate and improve our techniques: an augmented sound editor and TimbreGrams a novel graphical representation for soundfiles. The previously unpublished contributions of this paper are the genre classification method, the segmentationâ based retrieval and summarization, and the definition of the TimbreGram. Featureâbased audio analysis The developed analysis tools are based on the calculation of shortâtime feature vectors. The signal is processed in small chunks so that its statistical characteristics are relativily stable. For each chunk some form of spectral analysis is performed and based on that analysis a vector of feature values is calculated. In our system features based on FFT (Fast Fourier Transform) analysis, MPEG filterbank analysis, LPC (Linear Predictive Coding) and MFCC (MelâFrequency cepstrum coefficients) are supported. In addition derivatives and running statistics are used to express temporal changes. The flexible architecture of MARSYAS allows the easy integration and experimentation of new features. Based on the calculated features different types of audio analysis processes can be performed.

%0 Conference Proceedings
%T Case Library Reduction Applied to Pile Foundations
%A Lei, Celestino
%A Babka, Otakar
%A Garanito, Laurinda A. G.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_17
%X The case-based reasoning paradigm is applied in support of decision making processes related to pile foundations. Based on this paradigm, the system accumulates experience from previously realized pile foundations. This experience can be drawn when new situations with similar attributes of geotechnical situation of the site and geometric characteristics of the piles are encountered. Two case libraries were created based on previously realized sites. The representativeness of the case libraries and the efficiency of the search process are facilitated by the use of a genetic algorithm reduction.
%P 233-247


%0 Conference Proceedings
%T Case-deliverer: Making cases relevant to the task at hand
%A Nakakoji, Kumiyo
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_107
%X Designers are limited in exploiting a catalog knowledge base of design cases because they may be unable to articulate what they are looking for, or may be unaware that potentially useful catalog examples exist. Kid (Knowing-In-Design), a domain-oriented, knowledge-based design environment for kitchen floor plan design, integrates the use of the catalog-base with its design tools. The information given through KidSpecification (for specifying a design requirement) and KidConstruction (for graphically constructing a floor plan) provides representations of the designers' task at hand, and recorded design rationale in its argumentation-base is used to infer the relevance of catalog examples to the task at hand. The Case-Deliverer component orders catalog examples according to the partial specification, and the CatalogExplorer subsystem allows designers to explore further the catalog space in terms of the task at hand. The study and assessment of the mechanisms have revealed that delivered cases helped designers reframe both a problem and a solution, and have encouraged designers to articulate a new portion of design knowledge, which addresses the knowledge acquisition problem.
%P 446-457


%0 Conference Proceedings
%T DOGMA: A GA-based relational learner
%A Hekanaho, Jukka
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027324
%X We describe a GA-based concept learning/theory revision system DOGMA and discuss how it can be applied to relational learning. The search for better theories in DOGMA is guided by a novel fitness function that combines the minimal description length and information gain measures. To show the efficacy of the system we compare it to other learners in two relational domains.
%P 205-214


%0 Conference Proceedings
%T Case-Based Reasoning for Estuarine Model Design
%A Passone, Sara
%A Chung, Paul W. H.
%A Nassehi, Vahid
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_43
%X Estuaries are complex natural water systems. Their behaviour depend on many factors, which are possible to analyse only by adopting different study approaches. The physical processes within estuaries, such as floods and pollutant dispersion, are generally investigated through computer modelling. In this paper the application of case-based reasoning technology to support the design of estuarine models is described. The system aims to provide a nonexpert user in modelling with the necessary guidance for selecting a model that matches his goal and the nature of the problem to be solved. The system is based on three components: a case-based reasoning scheme, a genetic algorithm and a library of numerical estuarine models. An example based on the Upper Milford Haven estuary (UK) is used to demonstrate the efficacy of the systemâs structure for supporting estuarine model design.
%P 590-603


%0 Conference Proceedings
%T Towards a Unified Theory of Adaptation in Case-Based Reasoning
%A Fuchs, BÃ©atrice
%A Lieber, Jean
%A Mille, Alain
%A Napoli, Amedeo
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_8
%X Case-based reasoning exploits memorized problem solving episodes, called cases, in order to solve a new problem. Adaptation is a complex and crucial step of case-based reasoning which is generally studied in the restricted framework of an application domain. This article proposes a first analysis of case adaptation independently from a specific application domain. It proposes to combine the retrieval and adaptation steps in a unique planning process that builds an ordered sequence of operations starting from an initial state (the stated problem) and leading to a final state (the problem once solved). Thus, the issue of case adaptation can be addressed by studying the issue of plan adaptation. Finally, it is shown how case retrieval and case adaptation can be related thanks to reformulations and similarity paths.
%P 104-117


%0 Conference Proceedings
%T A Fuzzy Case Retrieval Approach Based on SQL for Implementing Electronic Catalogs
%A Portinale, Luigi
%A Montani, Stefania
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_24
%X Providing a flexible and efficient way of consulting a catalog in e-commerce applications is of primary importance in order to guarantee the customer with a set of products actually related to his/her interests. Most electronic catalogs exploit standard database techniques both for storage and retrieval of product information. However, a naive application of ordinary databases may produce unsatisfactory results, since standard query tools are not able to retrieve information (i.e. products) that only partially match the user/customer specification. The use of CBR may alleviate some of the above problems, because of the ability of a CBR system of retrieving products having characteristics similar to the ones specified by the user. While the majority of the approaches is based on k-NN retrieval techniques, in the present paper we propose fuzzy-based retrieval as a natural way for implementing flexible search on electronic catalogs. Since the exploitation of standard DBMS technology is of paramount importance for deploying any E-commerce application, we also propose to use a fuzzy extension to SQL for retrieving a set of products that the customer specifies using precise as well as vague or imprecise features. The proposed implementation is based on a client/server web-based architecture working on top of a relational standard DBMS. A specific example concerning an on-line wine shop is used to demonstrate the capabilities of the approach.
%P 321-335


%0 Conference Proceedings
%T Learning strategies for explanation patterns: Basic game patterns with application to chess
%A Kerner, Yaakov
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_45
%X In this paper we describe game-independent strategies, capable of learning explanation patterns (XPs) for evaluation of any basic game pattern. A basic game pattern is defined as a minimal configuration of a small number of pieces and squares which describes only one salient game feature. Each basic pattern can be evaluated by a suitable XP. We have developed five game-independent strategies (replacement, specialization, generalization, deletion, and insertion) capable of learning XPs or parts of them. Learned XPs can direct players' attention to important analysis that might have been overlooked otherwise. These XPs can improve their understanding, evaluating and planning abilities. At present, the application is only in the domain of chess. The proposed strategies have been further developed into 21 specific chess strategies, which are incorporated in an intelligent educational chess system that is under development.
%P 491-500


%0 Conference Proceedings
%T Analysis and prediction of piano performances using inductive logic programming
%A Van Baelen, Erika
%A De Raedt, Luc
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_48
%X Starting from the work of Matthew Dovey on analysing Rachmaninoff's piano performances using inductive logic programming, we show how to apply the clausal discovery engine Claudien to induce theories for predicting MIDI files from the musical analysis of a score. This extends Dovey's work in several directions: MIDI-encodings are used instead of the older Ampico, a richer musical analysis within LaRue's SHMRG-model is applied, a much finer qualitative analysis of features is learned (making it nearly quantitative), and predictions are made. The application is not only relevant as yet another inductive logic programming benchmark, but also as a demonstration of the need for multiple predicate learning, sequence prediction and number handling in inductive logic programming. Furthermore, the results presented here can be considered the first original application of the clausal discovery engine Claudien.
%P 55-71


%0 Conference Proceedings
%T Using logical decision trees for clustering
%A De Raedt, Luc
%A Blockeel, Hendrik
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_41
%X A novel first order clustering system, called C 0.5, is presented. It inherits its logical decision tree formalism from the TILDE system, but instead of using class information to guide the search, it employs the principles of instance based learning in order to perform clustering. Various experiments are discussed, which show the promise of the approach.
%P 133-140


%0 Conference Proceedings
%T A Bounded Search Space of Clausal Theories
%A Midelfart, Herman
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_20
%X In this paper the problem of induction of clausal theories through a search space consisting of theories is studied. We order the search space by an extension of Î¸-subsumption for theories, and find a least generalization and a greatest specialization of theories. A most specific theory is introduced, and we develop a refinement operator bounded by this theory.
%P 210-221


%0 Conference Proceedings
%T On the complexity of some Inductive Logic Programming problems
%A Gottlob, Georg
%A Leone, Nicola
%A Scarcello, Francesco
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_31
%X The bounded ILP-consistency problem for function-free Horn clauses is described as follows. Given a set E+ and Eâ of function-free ground Horn clauses and an integer k polynomial in E+âªEâ, does there exist a function-free Horn clause C with no more than k literais such that C subsumes each element in E+ and C does not subsume any element in Eâ. It is shown that this problem is Î£2Pcomplete. We derive some related results on the complexity of ILP and discuss the usefulness of such complexity results.
%P 17-32


%0 Conference Proceedings
%T Collaborative Case-Based Recommender Systems
%A Aguzzoli, Stefano
%A Avesani, Paolo
%A Massa, Paolo
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_34
%X We introduce an application combining CBR and collaborative filtering techniques in the music domain. We describe a scenario in which a new kind of recommendation is required, which is capable of summarizing many recommendations in one suggestion. Our claim is that recommending one set of goods is different from recommending a single good many times. The paper illustrates how a case-based reasoning approach can provide an effective solution to this problem reducing the drawbacks related to the user profiles. CoCoA, a compilation compiler advisor, will be described as a running example of a collaborative case-based recommendation system.
%P 460-474


%0 Conference Proceedings
%T Evaluating MultiÂ­lingual Information Retrieval and Clustering at ULIS
%D 2001
%A Fujii, Atsushi
%A Ishikawa, Tetsuya
%X This paper describes our retrieval system for NTCIR-2 Japanese/English CLIR and MLIR tasks. We integrate query and document translation with monolingual retrieval to improve retrieval accuracy, and perform clustering to improve browsing efficiency. We also introduce an entropy-driven technique in evaluating clustering methods. 
%0 Conference Proceedings
%T Image background search: combining object detection techniques with content-based image retrieval (CBIR) systems
%D 1999
%A R. Srihari
%A Zhongfei Zhang
%A Aibing Rao
%X A framework for combining object detection techniques with a content based image retrieval (CBIR) system is discussed. As an example, a special CBIR system which focuses on human faces as foreground and decides the similarity of images based on background features is presented. This system may be useful in automatically generating albums from consumer photos.

%0 Conference Proceedings
%T CBR for the Reuse of Image Processing Knowledge: a Recursive Retrieval/Adaptation Strategy
%A Ficet-Cauchard, ValÃ©rie
%A Porquet, Christine
%A Revenu, Marinette
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_32
%X . The development of an Image Processing (IP) application is a complex activity, which can be greatly alleviated by user-friendly graphical programming environments. Our major objective is to help IP experts reuse parts of their applications. A first work towards knowledge reuse has been to propose a suitable representation of the strategies of IP experts by means of IP plans (trees of tasks, methods and tools). This paper describes the CBR module of our interactive system for the development of IP plans. After a brief presentation of the overall architecture of the system and its other modules, we explain the distinction between an IP case and an IP plan, and give the selection criteria and functions that are used for similarity calculation. The core of the CBR module is a search/adaptation algorithm, whose main steps are detailed: retrieval of suitable cases, recursive adaptation of the selected one and memorization of new cases. The systemâs implementation is presently completed; its functioning is described in a session showing the kind of assistance provided by the CBR module during the development of a new IP application.
%P 438-452


%0 Conference Proceedings
%T A Case-Based Personal Travel Assistant for Elaborating User Requirements and Assessing Offers
%A Coyle, Lorcan
%A Cunningham, PÃ¡draig
%A Hayes, Conor
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_37
%X This paper describes a case-based approach to user profiling in a Personal Travel Assistant (based on the 1998 FIPA Travel Scenario). The approach is novel in that the user profile is made up of a set of cases capturing previous interactions rather than as a single composite case. This has the advantage that the profile is always up-to-date and also allows for the borrowing of cases from similar users when coverage is poor. Profile data is retrieved from a database in an XML format and loaded into a case-retrieval net in memory. This case-retrieval net is then used to support the two key tasks of requirements elaboration and ranking offers.
%P 505-518


%0 Conference Proceedings
%T ICARUS: Design and Deployment of a Case-Based Reasoning System for Locomotive Diagnostics
%A Varma, Anil
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_43
%X Locomotives, like many modern complex machines, are equipped with the capability to generate on-board fault messages indicating the presence of anomalous conditions. Such messages tend to generate in large quantities and difficult and time consuming to interpret manually. This paper presents the design and development of a case-based reasoning system for diagnosing locomotive faults using such fault messages as input. The process of using historical repair data and expert input for case generation and validation is described. An algorithm for case matching is presented along with some results on pilot data.
%P 581-596


%0 Conference Proceedings
%T Extending Synsets with Medical Terms
%D 2002 
%A Buitelaar, Paul
%A Sacaleanu, Bogdan
%X An important problematic issue with general semantic lexicons like WordNet or GermaNet is that they do not cover many terms and concepts specific to certain domains. Therefore, these resources need to be tuned to a specific domain at hand. This involves selecting those senses that are most appropriate for the domain, as well as extending the sense inventory with novel terms and novel senses that are specific to the domain. In this paper we focus on extending GermaNet synsets with domain specific terms, taking into account the domain relevance of senses (i.e. synsets).


%0 Conference Proceedings
%T A Method for Predicting Solutions in Case-Based Problem Solving
%A HÃ¼llermeier, Eyke
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_12
%X In order to predict the solution to a new problem we proceed from the âsimilar problem-similar solutionâ assumption underlying case-based reasoning. The concept of a similarity hypothesis is introduced as a formal model of this meta-heuristic. It allows for realizing a constraint-based inference scheme which derives a prediction in the form of a set of possible candidates. We propose an algorithm for learning a suitable similarity hypothesis from a sequence of observations. Basing the inference process on hypotheses thus defined yields (set-valued) predictions that cover the true solution with high probability. Our method is meant to support the overall (case-based) problem solving process by bringing a promising set of possible solutions into focus.
%P 124-135


%0 Conference Proceedings
%T A Product Customization Module Based on Adaptation Operators for CBR Systems in E-Commerce Environments
%A Schmitt, Sascha
%A Maximini, Rainer
%A Landeck, Gerhard
%A Hohwiller, JÃ¶rg
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_43
%X Existing electronic shops based on CBR technology allow customers to search for adequate products by only specifying the attributes for the products in a fuzzy way. Unfortunately, most electronic shops do not further support customers after the retrieval step. However, especially configurable products could be customized at this stage. Based on the approach of interactive adaptation operators, we present a flexible system architecture for a customization module which can be easily integrated in electronic shops. Our approach of a modular adaptation concept is implemented and currently tested within the ESPRIT project WEBSELL 1
%P 504-516


%0 Conference Proceedings
%T Case Representation, Acquisition, and Retrieval in SIROCCO
%A McLaren, Bruce
%A Ashley, Kevin
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_18
%X As part of our investigation of how abstract principles are operationalized to facilitate their application to specific fact situations, we have begun to develop and experiment with SIROCCO (System for Intelligent Retrieval of Operationalized Cases and COdes), a CBR retrieval and analysis system applied to the domain of engineering ethics. SIROCCO is intended to retrieve decided engineering ethics cases and previously applied ethics codes to assist engineers and students in analyzing new cases. Here we describe a limited but expressive language designed to represent a wide range of ethics cases in SIROCCO, a world-wide web tool developed to perform case acquisition and support a measure of consistency in representation, and an experiment to validate the initial phase of SIROCCOâs retrieval algorithm and test its sensitivity to small variations in case description.
%P 248-262


%0 Conference Proceedings
%T A connectionist indexing approach for CBR systems
%A Malek, Maria
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_48
%X An important factor that plays a major role in determining the performances of a CBR system is the complexity and the accuracy of the case retrieval phase. Both flat memory and inductive approaches suffer from serious drawbacks. In the first approach, the search time becomes considerable when dealing with large scale memory base, while in the second one the modifications of the case memory becomes very complex because of its sophisticated architecture.
%P 520-527


%0 Conference Proceedings
%T Speed-up, Quality and Competence in Multi-Modal Case-Based Reasoning
%A Portinale, Luigi
%A Torasso, Pietro
%A Tavano, Paolo
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_22
%X The paper discusses the different aspects concerning performance arising in multi-modal systems combining Case-Based Reasoning and Model-Based Reasoning for diagnostic problem solving. In particular, we examine the relation among speed-up of problems solving, competence of the system and quality of produced solutions. Because of the well-know utility problem, there is no general strategy for improving all these parameters at the same time, so the trade-off among such parameters must be carefully analyzed. We have developed a case memory management strategy which allows the interleaving of learning of new cases with forgetting phases, where useless and potentially dangerous cases are identified and removed. This strategy, combined with a suitable tuning on the precision required for the retrieval of cases (in terms of estimated adaptation cost), provides an effective mechanism for taking under control the utility problem. Experimental analysis performed on a real-world domain shows in fact that improvements over both speed-up and competence can be obtained, without compromising in a significant way the quality of solutions.
%P 303-317


%0 Conference Proceedings
%T Integration of case based retrieval with a relational database system in Aircraft Technical Support
%A Allen, Jonathan R. C.
%A Patterson, David W. R.
%A Mulvenna, Maurice D.
%A Hughes, John G.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_1
%X Case-Based Reasoning (CBR) is suited to problem solving in domains where there are recurring problems. This paper describes the development of a CBR system for use in such a domain, the Technical Support department of an aircraft manufacturing company. The system uses three types of indexing: knowledge-guided induction, inductive indexing and nearest neighbour matching. The resultant system integrates case based retrieval with a relational database system to provide a rich environment to help manage the life cycle of a technical support query. In early tests with the system, staff can discern if a new query is a recurring problem and has been solved before or if it is a completely new unsolved technical query.
%P 1-10


%0 Conference Proceedings
%T Applying memory-based learning to indexing of reference ships for case-based conceptual ship design
%A Lee, Dongkon
%A Kang, Jaeho
%A Ryu, Kwang Ryel
%A Lee, Kyung-Ho
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_480
%X This paper presents a method of applying a memory-based learning (MBL) technique to automatic building of an indexing scheme for accessing reference cases during the conceptual design phase of a new ship. The conceptual ship design process begins with selecting previously designed reference ships of the same type with similar sizes and speeds. These reference ships are used for deriving an initial design of a new ship, and then the initial design is kept modified and repaired until the design reaches a level of satisfactory quality. The selection of good reference ships is essential for deriving a good initial design, and the quality of the initial design affects the efficiency and quality of the whole conceptual design process. The selection of reference ships has so far been done by design experts relying on their experience and engineering knowledge of ship design and structural mechanics. We developed an MBL method that can build an effective indexing scheme for retrieving good reference cases from a case base of previous ship designs. Empirical results show that the indexing scheme generated by MBL outperforms those by other learning methods such as the decision tree learning.
%P 74-83


%0 Conference Proceedings
%T Adaptation Using Iterated Estimations
%A Falkman, GÃ¶ran
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_8
%X A model for adaptation in case-based reasoning (cbr) is presented. Similarity assessment is based on the computation and the iterated estimation of structural relationships among representations, and adaptation is given as a special case of the general process.
%P 88-102


%0 %0 Conference Paper
%T Discovering Internet Resources to Enrich a Structured Personal Information Space
%D 2000
%A %A MichÃ¨le Ouellet
%A Jan Gecsei
%A Jian-Yun Nie 
%X The Internet is a tremendous resource where one can find documents to enrich a personal information space. The question is: how can one find relevant documents and how can these be organized into an information space? In this paper, we describe a prototype which aims to provide the user with assistance in these two tasks. Our approach assumes the existence of an initial concept structure set up by the user. This structure may contain only rudimentary descriptions for each concept. The system's task is to find relevant documents from the Internet and to insert them in the appropriate places in the concept structure.
%0 Conference Proceedings
%T Integrating Hybrid Rule-Based with Case-Based Reasoning
%A Prentzas, Jim
%A Hatzilygeroudis, Ioannis
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_25
%X In this paper, we present an approach integrating neurule-based and case-based reasoning. Neurules are a kind of hybrid rules that combine a symbolic (production rules) and a connectionist representation (adaline unit). Each neurule is represented as an adaline unit. One way that the neurules can be produced is from symbolic rules by merging the symbolic rules having the same conclusion. In this way, the number of rules in the rule base is decreased. If the symbolic rules, acting as source knowledge of the neurules, do not cover the full complexities of the domain, accuracy of the produced neurules is affected as well. To improve accuracy, neurules can be integrated with cases representing their exceptions. The integration approach enhances a previous method integrating symbolic rules with cases. The use of neurules instead of symbolic rules improves the efficiency of the inference mechanism and allows for drawing conclusions even if some of the inputs are unknown.
%P 336-349


%0 Conference Proceedings
%T Applying case-based reasoning to automated deduction
%A Fuchs, Marc
%A Fuchs, Matthias
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_475
%X The use of CBR has been very profitable for many areas of artificial intelligence. Applying CBR to automated deduction, however, is a very intricate problem. The premise âsmall changes of a problem cause small changes of its solutionâ is definitely not satisfied by automated deduction. Therefore, case adaptation by means of symbolic proof transformation techniques is very limited.
%P 23-32


%0 Conference Proceedings
%T Reuse of knowledge: Empirical studies
%A Visser, Willemien
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_30
%X This paper presents empirical studies, mainly from psychology, on reuse of knowledge, especially in design. The results are considered relevant to research and development in the domain of CBR because of the support function generally attributed to CBR systems. The data exposed concern both representational and processing aspects of reuse. The topics discussed are: reuse vs. design âfrom scratchâ; different stages in reuse, especially retrieval; types of entity reused (with respect to their abstraction level, origin, and âproductâ-solution vs. âprocedureâ-solution character) and types of their exploitation; strategies of reuse; frequency of effective reuse; effects of reuse on designers' productivity; difficulties and risks of reuse. The paper closes with possible repercussions for CBR systems based on the results presented, and research topics in the domain of reuse of knowledge (conditions of reuse, retrieval from memory, and reuse and analogical reasoning).
%P 335-346


%0 Conference Proceedings
%T Polynomial-time learning in logic programming and constraint logic programming
%A Sebag, MichÃ¨le
%A Rouveirol, CÃ©line
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_51
%X Induction in first-order logic languages suffers from an additional factor of complexity compared to induction in attribute-value languages: the number of possible matchings between a candidate hypothesis and a training example.
%P 105-126


%0 Conference Proceedings
%T An Automated Hybrid CBR System for Forecasting
%A Fdez-Riverola, Florentino
%A Corchado, Juan M.
%A Torres, JesÃºs M.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_38
%X A hybrid neuro-symbolic problem solving model is presented in which the aim is to forecast parameters of a complex and dynamic environment in an unsupervised way. In situations in which the rules that determine a system are unknown, the prediction of the parameter values that determine the characteristic behaviour of the system can be a problematic task. The proposed system employs a case-based reasoning model that incorporates a growing cell structures network, a radial basis function network and a set of Sugeno fuzzy models to provide an accurate prediction. Each of these techniques is used in a different stage of the reasoning cycle of the case-based reasoning system to retrieve, to adapt and to review the proposed solution to the problem. This system has been used to predict the red tides that appear in the coastal waters of the north west of the Iberian Peninsula. The results obtained from those experiments are presented.
%P 519-533


%0 Conference Proceedings
%T Fault Management in Computer Networks Using Case-Based Reasoning: DUMBO System
%A Melchiors, Cristina
%A Tarouco, Liane M. R.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_37
%X Nowadays, the complexity involved in computer network fault management demands a great amount of information about the involved technologies and their associated problems. Besides, Trouble Ticket Systems have been used to store the occurred problems, actuating as an historical memory of the network. Thus, a correct approach to consolidate the network historic memory is the development of an expert system that takes in account the knowledge accumulated in the Trouble Ticket Systems to propose solutions for an average problem. This work presents a system that uses Case-Based Reasoning paradigm applied to a Trouble Ticket System to suggest solutions for a new problem occurred. This system aims to aid diagnosis and resolution stages of network management problems. Typical problems of this domain, the proposed solution and results reached with the developed prototype are described.
%P 510-524


%0 Conference Proceedings
%T Tuning rules by cases
%A Nakatani, Yoshio
%A Israel, David
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_96
%X A new method is proposed for tuning rules by cases, especially in domains in which precise and exceptionless rules are known to be unavailable. When the result of execution of a rule is not satisfactory, the system stores the name of the executed rule, the conditions under which the rule was executed, the evaluation of the execution, the attributes and values to be modified, and hypothesized alternatives, as a case. The next time the rule is to be executed under the same conditions, the relevant attributes and values are temporarily modified, by replacement by their hypothesized alternatives. After a certain number of such experiments, the maintainer of the system can reconstruct the whole rule base by referring to the stored cases. This methodology is implemented as a system, A LA CARTE, in the domain of cooking.
%P 313-324


%0 Conference Proceedings
%T A unified model for metasearch, pooling, and system evaluation
%D 2003
%A Aslam, Javed A.
%A Pavlu, Virgil
%A Savell, Robert
%X We present a unified model which, given the ranked lists of documents returned by multiple retrieval systems in response to a given query, simultaneously solves the problems of (1) fusing the ranked lists of documents in order to obtain a high-quality combined list (metasearch); (2) generating document collections likely to contain large fractions of relevant documents (pooling); and (3) accurately evaluating the underlying retrieval systems with small numbers of relevance judgments (efficient system assessment). Our approach is based on the Hedge algorithm for on-line learning. In effect, our proposed system "learns" which documents are likely to be relevant from a sequence of on-line relevance judgments. In experiments using TREC data, our methodology is shown to outperform standard methods for metasearch, pooling, and system evaluation, often remarkably so.

%0 Conference Paper
%T OneÂ­way Functions are Essential for SingleÂ­Server Private Information Retrieval
%D 1999
%A Amos Beimel
%A Yuval Ishai
%A Eyal Kushilevitz
%A Tal Malkin 
%X Private Information Retrieval (PIR) protocols allow a user to read information from a database without revealing to the server storing the database which information he has read. Kushilevitz and Ostrovsky [23] construct, based on the quadratic residuosity assumption, a single-server PIR protoco1 with small communication complexity. Cachin, Micali, and Stadler [6] present a single-server PIR protocol with a smaller communication complexity, based an the (new) *- hiding assumption. A major question, addressed in the present work, is what assumption is the minimal assumption necessary for the construction of single-server private information retrieval pro- tocols with small communication complexity. We prove that if there is a (O-error) PIR protocol in which the server sends less than n bits then one-way functions exist (where n is the number of bits in the database). That is, even saving one bit compared to the naive protocol, in which the entire database is sent, already requires one-way functions. The same result holds (but requires more work) even if we allow the retrieval to fail with probability of at most 1/(8n). Moreover, similar results hold even if we allow constant probability of error. For example, we prove that if there is a PIR protocol with error 1/4 and communication complexity less than n/1O bits, then one-way functions exist. 

%0 Conference Proceedings
%T Merge strategies for multiple case plan replay
%A Veloso, Manuela M.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_511
%X Planning by analogical reasoning is a learning method that consists of the storage, retrieval, and replay of planning episodes. Planning performance improves with the accumulation and reuse of a library of planning cases. Retrieval is driven by domain-dependent similarity metrics based on planning goals and scenarios. In complex situations with multiple goals, retrieval may find multiple past planning cases that are jointly similar to the new planning situation. This paper presents the issues and implications involved in the replay of multiple planning cases, as opposed to a single one. Multiple case plan replay involves the adaptation and merging of the annotated derivations of the planning cases. Several merge strategies for replay are introduced that can process with various forms of eagerness the differences between the past and new situations and the annotated justifications at the planning cases. In particular, we introduce an effective merging strategy that considers plan step choices especially appropriate for the interleaving of planning and plan execution. We illustrate and discuss the effectiveness of the merging strategies in specific domains.
%P 413-424


%0 Conference Proceedings
%T A hybrid knowledge-based system for technical diagnosis learning and assistance
%A Macchion, David J.
%A Vo, Dinh P.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_95
%X This paper sets out the design of a fault diagnosis system combining Model-Based, Case-Based and Rule-Based Reasoning techniques. Within the Model-Based layer, domain concepts are organized in hierarchies; different aspects of the system to be diagnosed are presented in a technical model; the Model-Based inference engine consists of basic principles operating on the technical model. Within the Case-Based layer, Model-Based or instructor processed resolutions are stored in a memory of past incident cases; indexes of various influences and more or less constraining viewpoints are invoked by the Case-Based inference engine in order to retrieve relevant cases quickly; explanations and adaptation rules are then used to make case description match and adapt case resolution. Within the Rule-Based layer, situation rules synthesizing incident description and validation rules supporting diagnosis assessment are triggered by the Rule-Based inference engine to solve well-tried, frequent or trivial problems. Integrating these knowledge layers into a unified model enhances the scope of the resultant knowledge base. Combining these reasoning modes into a coherent control strategy improves the efficiency of the target Knowledge-Based System.
%P 301-312


%0 Conference Proceedings
%T Integrating case based reasoning and tabu search for solving optimisation problems
%A Grolimund, Stephan
%A Ganascia, Jean-Gabriel
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_41
%X Tabu search is an established heuristic optimisation technique for problems where exact algorithms are not available. It belongs to the same family as simulated annealing or genetic algorithms. It extends the basic iterative improvement scheme by adding control learning. A technique of this kind, intensification, captures experience established on a frequency-based analysis of past search. Experience is reused while the same optimisation process is going on in order to guide search to better solutions.
%P 451-460


%0 Conference Proceedings
%T Normal programs and multiple predicate learning
%A Fogel, Leonardo
%A Zaverucha, Gerson
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027321
%X We study the problem of inducing normal programs of multiple predicates in the empirical ILP setting. We identify a class of normal logic programs that can be handled and induced in a top-down manner by an intensional system. We propose an algorithm called NMPL that improves the multiple predicate learning system MPL and extends its language from definite to this class of normal programs. Finally, we discuss the cost of the MPL's refinement algorithm and present theoretical and experimental results showing that NMPL can be as effective as MPL and is computationally cheaper than it.
%P 175-184


%0 Conference Proceedings
%T Supporting Tourism Culture via CBR
%A Blanzieri, Enrico
%A Ebranati, Alessandro
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_31
%X We present COOL-TOUR, a WEB-based Case Based Reasoning system for tourism culture support. Its main goal is to build the community of tourists that are interested in a geographic area. Building communities is relevant for e-commerce and CBR can support it effectively. Users interact with the system entering tours for accessing auxiliary services. The tours are stored in a case base and other users can retrieve and adapt them. The community is built around these stored experiences. The implemented version of COOL-TOUR deals with Mountain Bike tours, providing a sketch-based interaction interface. The spatial data similarity assessment is based on spatial indexing.
%P 358-369


%0 Conference Proceedings
%T Adaptation using constraint satisfaction techniques
%A Purvis, Lisa
%A Pu, Pearl
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_26
%X Case adaptation, a central component of case-based reasoning, is often considered to be the most difficult part of a case-based reasoning system. The difficulties arise from the fact that adaptation often does not converge, especially if it is not done in a systematic way. This problem, sometimes termed the assimilation problem, is especially pronounced in the case-based design problem solving domain where a large set of constraints and features are processed. Furthermore, in the design domain, multiple cases must be considered in conjunction in order to solve the new problem, resulting in the difficulty of how to efficiently combine the cases into a global solution for the new problem.
%P 289-300


%0 Conference Proceedings
%T Beyond the Query-By-Example Paradigm: New Query Interfaces for Music Information Retrieval
%D 2002
%A Tzanetakis, George
%A Ermolinskyi, Andreye
%A Cook, Perry R.
%X The majority of existing work in music information retrieval for audio signals has followed the content-based query-by-example paradigm. In this paradigm a musical piece is used as a query and the result is a list of other musical pieces ranked by their content similarity. In this paper we describe algorithms and graphical user interfaces that enable novel alternative ways for querying and browsing large audio collections. Computer audition algorithms are used to extract content information from audio signals. This automatically extracted information is used to configure the graphical user interfaces and to genereate new query audio signals for browsing and retrieval.

%0 Conference Paper
%T TileBars: Visualization of Term Distribution Information in Full Text Information Access
%D 1995
%A Marti A. Hearst 
%X The field of information retrieval has traditionally focused ontextbases consisting of titles and abstracts. As a consequence,many  underlying assumptions must be  altered for retrievalfrom full-length text collections. This paper argues for mak-ing use of text structure when retrieving from full text doc-uments, and presents a visualization paradigm, called Tile-Bars, that demonstrates the usefulness of explicit term distri-bution information in Boolean-type queries. TileBars simul-taneously and compactly indicate relative document length,query term frequency, and query term distribution. The pat-terns in a column of TileBars can be quickly scanned and de-ciphered, aiding users in making judgments about the poten-tial relevance of the retrieved documents.
%0 Conference Proceedings
%T A Similarity metric for retrieval of cases imperfectly explained
%A Bento, Carlos
%A Costa, Ernesto
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_79
%X This paper describes a new quantitative similarity metric for cases comprising an episode represented by a problem/solution pair and an interpretation in the form of a set of imperfect explanations.
%P 92-105


%0 Conference Paper
%T Automatic Musical Genre Classification Of Audio Signals
%D 2001
%A Tzanetakis, George
%X Musical genres are categorical descriptions that are used todescribe  music.  They  are  commonly  used  to  structure  theincreasing amounts of music available in digital form on theWeb  and  are  important  for  music  information  retrieval.Genre   categorization   for   audio   has   traditionally   beenperformed    manually.    A    particular    musical    genre    ischaracterized   by    statistical   properties    related   to   theinstrumentation,    rhythmic    structure    and    form    of    itsmembers.  In  this  work,  algorithms  for  the  automatic  genrecategorization   of   audio   signals   are   described.      Morespecifically,  we  propose  a  set  of  features  for  representingtexture  and  instrumentation.  In  addition  a  novel  set  offeatures  for  representing  rhythmic  structure  and  strength  isproposed.  The  performance  of  those  feature  sets  has  beenevaluated    by    training    statistical    pattern    recognitionclassifiers using real world audio collections.  Based on theautomatic  hierarchical  genre  classification  two  graphicaluser  interfaces  for  browsing  and  interacting  with  largeaudio collections have been developed.
%0 Conference Proceedings
%T Application of Different Learning Methods to Hungarian Part-of-Speech Tagging
%A HorvÃ¡th, TamÃ¡s
%A Alexin, ZoltÃ¡n
%A GyimÃ³thy, Tibor
%A Wrobel, Stefan
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_13
%X From the point of view of computational linguistics, Hungarian is a difficult language due to its complex grammar and rich morphology. This means that even a common task such as part-of-speech tagging presents a new challenge for learning when looked at for the Hungarian language, especially given the fact that this language has fairly free word order. In this paper we therefore present a case study designed to illustrate the potential and limits of current ILP and non-ILP algorithms on the Hungarian POS-tagging task. We have selected the popular C4.5 and Progol systems as propositional and ILP representatives, adding experiments with our own methods AGLEARN, a C4.5 preprocessor based on attribute grammars, and the ILP approaches PHM and RIBL. The systems were compared on the Hungarian version of the multilingual morphosyntactically annotated MULTEXT-East TELRI corpus which consists of about 100.000 tokens. Experimental results indicate that Hungarian POS-tagging is indeed a challenging task for learning algorithms, that even simple background knowledge leads to large differences in accuracy, and that instance-based methods are promising approaches to POS tagging also for Hungarian. The paper also includes experiments with some different cascade connections of the taggers.
%P 128-139


%0 Conference Proceedings
%T Completing Inverse Entailment
%A Muggleton, Stephen
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027328
%X Yamamoto has shown that the Inverse Entailment (IE) mechanism described previously by the author is complete for Plotkin's relative subsumption but incomplete for entailment. That is to say, an hypothesised clause H can be derived from an example E under a background theory B using IE if and only if H subsumes E relative to B in Plotkin's sense. Yamamoto gives examples of H for which B U H â¨ E but H cannot be constructed using IE from B and E. The main result of the present paper is a theorem to show that by enlarging the bottom set used within IE, it is possible to make a revised version of IE complete with respect to entailment for Horn theories. Furthermore, it is shown for function-free definite clauses that given a bound k on the arity of predicates used in B and E, the cardinality of the enlarged bottom set is bounded above by the polynomial function p(c + 1)k, where p is the number of predicates in B, E and c is the number of constants in B â Ä.
%P 245-249


%0 Conference Proceedings
%T Representing Knowledge for Case-Based Reasoning: The Rocade System
%A Fuchs, BÃ©atrice
%A Mille, Alain
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_9
%X This paper presents the object-based knowledge representation system Rocade, that is aimed at the development of case-based reasoning (cbr) systems. cbr is studied by reference to the two levels defined by Newell: at the knowledge level, a general detailed model of the cbr process has been proposed. This model is intended to be implemented at the symbol level materialized by the Rocade system. This paper presents these two complementary levels and focuses on Rocade. The concepts and reasoning mechanisms of Rocade are described, as well as its architecture. Then, its architecture allowing different ways to use it is presented. Rocade is illustrated with examples of two cbr systems. The implementation of 2 CBR systems are used to illustrate the rocade system the functionalities of the rocade system
%P 86-98


%0 Conference Proceedings
%T Probabilistic Relational Models
%A Koller, Daphne
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_1
%X Probabilistic models provide a sound and coherent foundation for dealing with the noise and uncertainty encountered in most real- world domains. Bayesian networks are a language for representing complex probabilistic models in a compact and natural way. A Bayesian network can be used to reason about any attribute in the domain, given any set of observations. It can thus be used for a variety tasks, including prediction, explanation, and decision making. The probabilistic seman- tics also gives a strong foundation for the task of learning models from data. Techniques currently exist for learning both the structure and the parameters, for dealing with missing data and hidden variables, and for discovering causal structure.
%P 3-13


%0 Conference Proceedings
%T A Refinement Operator for Description Logics
%A Badea, Liviu
%A Nienhuys-Cheng, Shan -Hwei
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_3
%X While the problem of learning logic programs has been extensively studied in ILP, the problem of learning in description logics (DLs) has been tackled mostly by empirical means. Learning in DLs is however worthwhile, since both Horn logic and description logics are widely used knowledge representation formalisms, their expressive powers being incomparable (neither includes the other as a fragment). Unlike most approaches to learning in description logics, which provide bottom-up (and typically overly specific) least generalizations of the examples, this paper addresses learning in DLs using downward (and upward) refinement operators. Technically, we construct a complete and proper refinement operator for the ALER description logic (to avoid overfitting, we disallow disjunctions from the target DL). Although no minimal refinement operators exist for ALER, we show that we can achieve minimality of all refinement steps, except the ones that introduce the â¥ concept. We additionally prove that complete refinement operators for ALER cannot be locally finite and suggest how this problem can be overcome by an MDL search heuristic. We also discuss the influence of the Open World Assumption (typically made in DLs) on example coverage.
%P 40-59


%0 Conference Paper
%T Growth and Server Availability of the NCSTRL Digital Library
%D 2000
%A Allison L. Powell
%A James C. French 
%X This paper reports on measurements of the NCSTRL digital library taken over a two-year period. We report the growth of the system along two dimensions: number of participating institutions and number of documents indexed by the system. We also report an aspect of reliability for this distributed digital library system.

%0 Conference Proceedings
%T Learning structurally indeterminate clauses
%A Zucker, Jean-Daniel
%A Ganascia, Jean-Gabriel
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027327
%X This paper describes a new kind of language bias, S-structural indeterminate clauses, which takes into account the meaning of predicates that play a key role in the complexity of learning in structural domains. Structurally indeterminate clauses capture an important background knowledge in structural domains such as medicine, chemistry or computational linguistics: the specificity of the component/object relation. The REPART algorithm has been specifically developed to learn such clauses. Its efficiency lies in a particular change of representation so as to be able to use propositional learners. Because of the indeterminacy of the searched clauses the propositional learning problem to be solved is a kind of Multiple-Instance problem. Such reformulations may be a general approach for learning non determinate clauses in ILP. This paper presents original results discovered by REPART that exemplify how ILP algorithms may not only scale up efficiently to large relational databases but also discover useful and computationally hard-to-learn patterns.
%P 235-244


%0 Conference Proceedings
%T Applying ILP to diterpene structure elucidation from 13C NMR spectra
%A DÅ¾eroski, SaÅ¡o
%A Schulze-Kremer, Steffen
%A Heidtke, Karsten R.
%A Siems, Karsten
%A Wettschereck, Dietrich
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_47
%X We present a novel application of ILP to the problem of diterpene structure elucidation from 13C NMR spectra. Diterpenes are organic compounds of low molecular weight that are based on a skeleton of 20 carbon atoms. They are of significant chemical and commercial interest because of their use as lead compounds in the search for new pharmaceutical effectors. The structure elucidation of diterpenes based on 13C NMR spectra is usually done manually by human experts with specialized background knowledge on peak patterns and chemical structures. In the process, each of the 20 skeletal atoms is assigned an atom number that corresponds to its proper place in the skeleton and the diterpene is classified into one of the possible skeleton types. We address the problem of learning classification rules from a database of peak patterns for diterpenes with known structure. Recently, propositional learning was successfully applied to learn classification rules from spectra with assigned atom numbers. As the assignment of atom numbers is a difficult process in itself (and possibly indistinguishable from the classification process), we apply ILP, i.e., relational learning, to the problem of classifying spectra without assigned atom numbers.
%P 41-54


%0 Conference Proceedings
%T Mining association rules in multiple relations
%A Dehaspe, Luc
%A De Raedt, Luc
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_40
%X The application of algorithms for efficiently generating association rules is so far restricted to cases where information is put together in a single relation. We describe how this restriction can be overcome through the combination of the available algorithms with standard techniques from the field of inductive logic programming. We present the system Warmr, which extends Apriori [2] to mine association rules in multiple relations. We apply Warmr to the natural language processing task of mining part-of-speech tagging rules in a large corpus of English. be applied to further constrain the space of interesting ARMR's.
%P 125-132


%0 Journal Article
%T An Empirical Study of Automated Dictionary Construction for Information Extraction in Three Domains
%D 1996
%A Riloff, Ellen
%X Abstract A primary goal of natural language processing researchers is to develop a knowledge-based natural language processing (NLP) system that is portable across domains. However, most knowledge-based NLP systems rely on a domain-specific dictionary of concepts, which represents a substantial knowledge-engineering bottleneck. We have developed a system called AutoSlog that addresses the knowledge-engineering bottleneck for a task called information extraction . AutoSlog automatically creates domain-specific dictionaries for information extraction, given an appropriate training corpus. We have used AutoSlog to create a dictionary of extraction patterns for terrorism, which achieved 98% of the performance of a hand-crafted dictionary that required approximately 1500 person-hours to build. In this paper, we describe experiments with AutoSlog in two additional domains: joint ventures and microelectronics. We compare the performance of AutoSlog across the three domains, discuss the lessons learned about the generality of this approach, and present results from two experiments which demonstrate that novice users can generate effective dictionaries using AutoSlog. 

%0 Conference Proceedings
%T The Dynamic Absorbing Model for the Web
%D 2003
%A Amati, Gianni
%A Ounis, Iadh
%A Plachouras, Vassilis
%X In this paper we propose a new theoretical method for combining both content and link structure analysis for Web information retrieval. This approach is based on performing a random walk on a modified Markov chain, induced from the Web graph. This new model is applicable either in a static way, where a global prestige score is computed for every document, or in a dynamic way, where the link structure of the results from a first pass retrieval is taken into account. The results of experiments on the TREC WT10g and .GOV collections show that it is a robust method, particularly suitable for dynamic link analysis. Moreover, we show that it outperforms PageRank under the same experimental settings. 

%0 Conference Proceedings
%T A Systematic Approach to Creating and Maintaining Software Documentation
%A Powell, Allison L.
%A French, James C.
%A Knight, John C.
%D 1996
%X Current software documentation is difficult to write and seldom meets the varying needs of its users. We propose that by considering different users and applying information retrieval techniques to the information included in software documentation, we can provide effective access to that information. We submit a set of features for inclusion in documentation database systems and describe a prototype designed to determine the usefulness of these features. 
%0 Conference Proceedings
%T Integrating Conversational Case Retrieval with Generative Planning
%A MuÃ±oz-Avila, HÃ©ctor
%A Aha, David W.
%A Breslow, Leonard A.
%A Nau, Dana S.
%A Weber, Rosina
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_19
%X Some problem-solving tasks are amenable to integrated case retrieval and generative planning techniques. This is certainly true for some decision support tasks, in which a user controls the problem-solving process but cannot provide a complete domain theory. Unfortunately, existing integrations are either non-interactive or require a complete domain theory and/or complete world state to produce acceptable plans, preventing them from being easily used in these situations. We describe a novel integrated algorithm, named SiN, that is interactive and does not require a complete domain theory or complete world state. SiN users leverage a conversational case retriever to focus both partial world state acquisition and plan generation. We highlight the benefits of SiN (e.g., quadratically fewer cases needed) in an experimental study using a new travel planning domain.
%P 210-221


%0 Conference Proceedings
%T CBR-Based Ultra Sonic Image Interpretation
%A Perner, Petra
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_41
%X The existing image interpretation systems lack robustness and accuracy. They cannot adapt to changing environmental conditions or to new objects. The application of machine learning to image interpretation is the next logical step. Our proposed approach aims at the development of dedicated machine learning techniques at all levels of image interpretation in a systematic fashion. In this paper we propose a system which uses Case-Based Reasoning (CBR) to optimize image segmentation at the low level according to changing image acquisition conditions and image quality. The intermediate-level unit extracts the case representation used by the high-level unit for further processing. At the high level, CBR is employed to dynamically adapt image interpretation.
%P 479-490


%0 Conference Proceedings
%T Using Star Clusters for Filtering
%D 2000
%A Aslam, Javed A.
%A Pelekhov, Katya
%A Rus, Daniela
%X We examine applications of clustering to the filtering task. We use the on-line version of the star algorithm [JPR98, JPR99] as the clustering tool because this algorithm computes, with high precision, naturally occuring topics in a collection and it admits an efficient on-line solution for dynamic corpora. We describe several filtering algorithms and show extensive experimental results using the TREC collection. 

%0 Conference Proceedings
%T Integrating Structural Search Capabilities Into Project Haystack
%D 2000
%A Shnitser, Svetlana
%X In this thesis, we have designed and implemented a system for performing structural searched in Haystack. The Haystack data model is semi-structured, and the challenge of this project was to develop a system that performs database-like queries on semistructured data using current relational database technologies. To achieve this goal, we have designed a database schema that would allow us to store our data model. We have specified the format in which the user can enter database queries and implemented procedures that translate user queries into SQL. We have designed a way to integrate structural search with text search in Haystack and have outlined ideas on how database queries can be used for machine learning. 

%0 Conference Proceedings
%T Separating the cases from the data: Towards more flexible case-based reasoning
%A Brown, Mike
%A Watson, Ian
%A Filer, Nick
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_15
%X The number of successful, small-scale and purpose-built applications of CBR is growing rapidly. However, CBR has so far not been widely used as a methodology for reusing the large-scale data repositories typically maintained by a corporation. To facilitate this, cases must no longer be considered as concretely represented at the data level, but as virtual views of the underlying data. This paper argues that the basic requirement to support virtual cases are mapping functions between different data representations. It is argued that the use of mapping functions can increase flexibility in a number of ways. Multiple CBR applications can exploit a single database. Similarly, a single case representation can span multiple databases. Support for communication between different CBR applications as well as the evolution of case representation within a single application are also catered for by the same methodology. The paper provides reference to related work on database systems, with respect to the issues of mapping function implementation and management.
%P 157-168


%0 Conference Proceedings
%T Learning Word Segmentation Rules for Tag Prediction
%A Kazakov, Dimitar
%A Manandhar, Suresh
%A Erjavec, TomaÅ¾
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_15
%X In our previous work we introduced a hybrid, GA&ILP-based approach for learning of stem-suffix segmentation rules from an unmarked list of words. Evaluation of the method was made difficult by the lack of word corpora annotated with their morphological segmentation. Here the hybrid approach is evaluated indirectly, on the task of tag prediction. A pair of stem-tag and suffix-tag lexicons is obtained by the application of that approach to an annotated lexicon of word-tag pairs. The two lexicons are then used to predict the tags of unseen words in two ways, (1) by using only the stem and suffix generated by the segmentation rules, and (2) for all matching combinations of stem and suffix present in the lexicons. The results show high correlation between the constituents generated by the segmentation rules, and the tags of the words in which they appear, thereby demonstrating the linguistic relevance of the segmentations produced by the hybrid approach.
%P 152-161


%0 Conference Proceedings
%T A rule-based similarity measure
%A Sebag, MichÃ¨le
%A Schoenauer, Marc
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_81
%X An induction-based method for retrieving similar cases and/or easily adaptable cases is presented in a 3-steps process: first, a rule set is learned from a data set; second, a reformulation of the problem domain is derived from this ruleset; third, a surface similarity with respect to the reformulated problem appears to be a structural similarity with respect to the initial representation of the domain. This method achieves some integration between machine learning and case-based reasoning: it uses both compiled knowledge (through the similarity measure and the ruleset it is derived from) and instanciated knowledge (through the cases).
%P 119-131


%0 Conference Proceedings
%T Shaping a CBR view with XML
%A Hayes, Conor
%A Cunningham, Padraig
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_34
%X Case Based Reasoning has found increasing application on the Internet as an assistant in Internet commerce stores and as a reasoning agent for online technical support. The strength of CBR in this area stems from its reuse of the knowledge base associated with a particular application, thus providing an ideal way to make personalised configuration or technical information available to the Internet user. Since case data may be one aspect of a companyâs entire corporate knowledge system, it is important to integrate case data easily within a companyâs IT infrastructure, using industry specific vocabulary. We suggest XML as the likely candidate to provide such integration. Some applications have already begun to use XML as a case representation language. We review these and present the idea of a standard case view in XML that can work with the vocabularies or namespaces being developed by specific industries. Earlier research has produced version 1.0 of a Case Based Mark-up Language which attempts to mark-up cases in XML to enable distributed computing. The drawbacks of this implementation are outlined in this paper as well as the developments in XML that allow us to produce an XML âViewâ of a companyâs knowledge system. We will detail the benefits of our system for industry in general in terms of extensibility, ease of reuse and interoperability.
%P 468-481


%0 Conference Proceedings
%T Bayesian Case Reconstruction
%A Hennessy, Daniel N.
%A Buchanan, Bruce G.
%A Rosenberg, John M.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_12
%X Bayesian Case Reconstruction (BCR) is a case-based technique that broadens the coverage of a case library by sampling and recombining pieces of existing cases to construct a large set of âplausibleâ cases. It employs a Bayesian Belief Network to evaluate whether implicit dependencies within the original cases have been maintained. The belief network is constructed from the expertâs limited understanding of the domain theory combined with the data available in the case library. The cases are the primary reasoning vehicle. The belief network leverages the available domain model to help evaluate whether the âplausibleâ cases have maintained the necessary internal context. BCR is applied to the design of screening experiments for Macromolecular Crystallization in the Probabilistic Screen Design program. We describe BCR and provide an empirical comparison of the Probabilistic Screen Design program against the current practice in Macromolecular Crystallization.
%P 148-158


%0 Conference Proceedings
%T An Architecture for a CBR Image Segmentation System
%A Perner, Petra
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_38
%X Image Segmentation is a crucial step if extracting information from a digital image. It is not easy to set up the segmentation parameter so that it fits best over the entire set of images, which should be segmented. In the paper, we propose a novel architecture for image segmentation method based on CBR, which can adapt to changing image qualities and environmental conditions. We describe the whole architecture, the methods used for the various components of the systems and show how it performs on medical images.
%P 525-534


%0 Conference Proceedings
%T Automatic Case Base Management in a Multi-modal Reasoning System
%A Portinale, Luigi
%A Torasso, Pietro
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_21
%X The definition of suitable case base maintenance policies is widely recognized as a major success key of CBR systems; underestimating this issue may lead to systems that that do not perform adequately under performance dimensions, namely computation time, competence and quality of solutions. The goal of the present paper is to analyse an automatic case base management strategy in the context of multi-modal architectures combining CBR and Model-Based Reasoning. The strategy, called Learning by Failure with Forgetting (LFF ) is based on incremental learning of cases interleaved with off-line processes of case deletion, in order to control the content and the size of the case library. Results from an extensive experimental analysis in an industrial plant diagnosis domain is then reported, showing the usefulness of LFF with respect to the maintenance of suitable performance level for the target system.
%P 234-246


%0 Conference Proceedings
%T Modelling the CBR Life Cycle Using Description Logics â
%A GÃ³mez-AlbarrÃ¡n, Mercedes
%A GonzÃ¡lez-Calero, Pedro A.
%A DÃ­az-Agudo, BelÃ©n
%A FernÃ¡ndez-Conde, Carlos
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_11
%X In this paper Description Logics are presented as a suitable formalism to model the CBR life cycle. We propose a general model to structure the knowledge needed in a CBR system, where adaptation knowledge is explicitly represented. Next, the CBR processes are described based on this model and the CBR system OoFRA is presented as an example of our approach.
%P 147-161


%0 Conference Proceedings
%T Problem solving with âthe incredible machineâ an experiment in case-based reasoning
%A GÃ¶ker, Mehmet H.
%A Birkhofer, Herbert
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_40
%P 441-450


%0 Conference Proceedings
%T CBR and Machine Learning for combustion system design
%A Stehr, Jutta
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_10
%X Nowadays the automotive industry has to face two major challenges. First products must meet continually increasing government requirements on fuel economy and low exhaust emission. Second the market demands product variety and short production cycles. The automobile's combustion system determines the exhaust emission rate, combustion system engineering is one of the crucial steps in the development process. Cylinder head design is a good example of showing how enhanced AI technologies like CBR and Machine Learning support high-level engineering design tasks.
%P 98-108


%0 Conference Proceedings
%T ILP: Just Do It
%A Page, David
%Y Lloyd, John
%Y Dahl, Veronica
%Y Furbach, Ulrich
%Y Kerber, Manfred
%Y Lau, Kung-Kiu
%Y Palamidessi, Catuscia
%Y Pereira, LuÃ­s Moniz
%Y Sagiv, Yehoshua
%Y Stuckey, Peter J.
%S Computational Logic â CL 2000
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44957-7
%F 10.1007/3-540-44957-4_2
%X Inductive logic programming (ILP) is built on a foundation laid by research in other areas of computational logic. But in spite of this strong foundation, at 10 years of age ILP now faces a number of new challenges brought on by exciting application opportunities. The purpose of this paper is to interest researchers from other areas of computational logic in contributing their special skill sets to help ILP meet these challenges. The paper presents five future research directions for ILP and points to initial approaches or results where they exist. It is hoped that the paper will motivate researchers from throughout computational logic to invest some time into âdoingâ ILP.
%P 25-40


%0 Conference Proceedings
%T Exploiting Taxonomic and Causal Relations in Conversational Case Retrieval
%A Gupta, Kalyan Moy
%A Aha, David W.
%A Sandhu, Nabil
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_11
%X Conversational case-based reasoning (CCBR) systems engage their users in a series of questions and answers and present them with cases that are most applicable to their decision problem. In previous research, we introduced the Taxonomic CCBR methodology, an extension of standard CCBR that improved performance by organizing features related by abstraction into taxonomies. We recently extended this methodology to include causal relations between taxonomies and claimed that it could yield additional performance gains. In this paper, we formalize the causal extension of Taxonomic CCBR, called Causal CCBR, and empirically assess its benefits using a new methodology for evaluating CCBR performance. Evaluation of Taxonomic and Causal CCBR systems in troubleshooting and customer support domains demonstrates that they significantly outperform the standard CCBR approach. In addition, Causal CCBR outperforms Taxonomic CCBR to the extent causal relations are incorporated in the case bases.
%P 133-147


%0 Conference Proceedings
%T A comparison of ILP and propositional systems on propositional traffic data
%A Roberts, Sam
%A vanLaer, Wim
%A Jacobs, Nico
%A Muggleton, Stephen
%A Broughton, Jeremy
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027333
%X This paper presents an experimental comparison of two Inductive Logic Programming algorithms, PROGOL and TILDE, with C4.5, a propositional learning algorithm, on a propositional dataset of road traffic accidents. Rebalancing methods are described for handling the skewed distribution of positive and negative examples in this dataset, and the relative cost of errors of commission and omission in this domain. It is noted that before the use of these methods all algorithms perform worse than majority class. On rebalancing, all did significantly better. The conclusion drawn from the experimental results is that on such a propositional dataset ILP algorithms perform competitively in terms of predictive accuracy with propositional systems, but are significantly outperformed in terms of time taken for learning.
%P 291-299


%0 Conference Proceedings
%T Acquiring Graphic Design Knowledge with Nonmonotonic Inductive Learning
%A Chiba, Kazuya
%A Ohwada, Hayato
%A Mizoguchi, Fumio
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_7
%X In this paper, we present a new method based on nonmonotonic learning where the Inductive Logic Programming (ILP) algorithm is used twice and apply our method to acquire graphic design knowledge. Acquiring design knowledge is a challenging task because such knowledge is complex and vast. We thus focus on principles of layout and constraints that layouts must satisfy to realize automatic layout generation. Although we do not have negative examples in this case, we can generate them randomly by considering that a page with just one element moved is always wrong. Our nonmonotonic learning method introduces a new predicate for exceptions. In our method, the ILP algorithm is executed twice, exchanging positive and negative examples. From our experiments using magazine advertisements, we obtained rules characterizing good layouts and containing relationships between elements. Moreover, the experiments show that our method can learn more accurate rules than normal ILP can.
%P 56-67


%0 Conference Proceedings
%T An Unsupervised Semantic Tagger Applied to German
%D 2001
%A Buitelaar, Paul
%A Alexandersson, Jan
%A JÃ¤ger, Tilman
%A Lesch, Stephan
%A Pfleger, Norbert
%A Raileanu, Diana
%A Berg, Tomas
%A Klockner, Kerstin
%A Neis, Holger
%A Schlarb, Hubert
%X We describe an unsupervised semantic tagger, applied to German, but which could be used with any language for which a corresponding "XNet" (WordNet, GermaNet, etc.), POS tagger and morphological analyzer are available. Disambiguation is performed by comparing co-occurrence weights on pairs of semantic classes (synsets from GermaNet). Precision is around 67% at a recall of around 65% (for all ambiguous words -81% for all words at a recall of 80%). Our results show the influence of context size and of semantic class frequency in the training corpus.


%0 Conference Proceedings
%T Analogical asides on case-based reasoning
%A Keane, Mark T.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_74
%X This paper explores some of the similarities and differences between cognitive models of analogy and case-based reasoning systems. I first point out a paradox in the treatment of adaptation in analogy and in case-based reasoning; a paradox which can be only resolved by expanding the role of adaptation in cognitive models of analogy. Some psychological research on the process of adaptation in human subjects is reported and then the implications of this research are propagated into analogy and then on into CBR. The argument is that some of the existing stages in CBR should be integrated into a more stream-lined architecture that would be more efficient than current schemes.
%P 21-32


%0 Conference Proceedings
%T Which hypotheses can be found with inverse entailment?
%A Yamamoto, Akihiro
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_58
%X In this paper we give a completeness theorem of an inductive inference rule inverse entailment proposed by Muggleton. Our main result is that a hypothesis clause H can be derived from an example E under a background theory B with inverse entailment iff H subsumes E relative to B in Plotkin's sense. The theory B can be any clausal theory, and the example E can be any clause which is neither a tautology nor implied by B. The derived hypothesis H is a clause which is not always definite. In order to prove the result we give a declarative semantics for arbitrary consistent clausal theories, and show that SB-resolution, which was originally introduced by Plotkin, is a complete procedural semantics. The completeness is shown as an extension of the completeness theorem of SLD-resolution. We also show that every hypothesis H derived with saturant generalization, proposed by Rouveirol, must subsume E w.r.t. B in Buntine's sense. Moreover we show that saturant generalization can be obtained from inverse entailment by giving some restriction to it.
%P 296-308


%0 Journal Article
%T A Novelty-based Evaluation Method for Information Retrieval
%D 2000
%J ArXiv
%A Fujii, Atsushi
%A Ishikawa, Tetsuya
%X In information retrieval research, precision and recall have long been used to evaluate IR systems. However, given that a number of retrieval systems resembling one another are already available to the public, it is valuable to retrieve novel relevant documents, i.e., documents that cannot be retrieved by those existing systems. In view of this problem, we propose an evaluation method that favors systems retrieving as many novel documents as possible. We also used our method to evaluate systems that participated in the IREX workshop. 

%0 Conference Proceedings
%T Learning multilingual morphology with Clog
%A Manandhar, Suresh
%A DÅ¾eroski, SaÅ¡o
%A Erjavec, TomaÅ¾
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027317
%X The paper presents the decision list learning system Clog and the results of using it to learn nominal inflections of English, Romanian, Czech, Slovene, and Estonian. The dataset used to induce rules for the synthesis and analysis of the inflectional paradigms of nouns and adjectives of these languages is the Multext-East multilingual tagged corpus. The ILP system FoIDL is also applied to the same dataset, and this paper compares the induction methodology and results of the two systems. The experiment shows that the accuracy of the two systems is comparable when using the same training set. However, while FOIDL is, due to efficiency reasons, severely limited in the size of the training set, CLOG does not suffer from such limitations. With the increase of the training set size possible with CLOG, it significantly outperforms FOIDL and learns highly accurate morphological rules.
%P 135-144


%0 Conference Proceedings
%T Entropy-Based vs. Similarity-Influenced: Attribute Selection Methods for Dialogs Tested on Different Electronic Commerce Domains
%A Schmitt, Sascha
%A Dopichaj, Philipp
%A DomÃ­nguez-MarÃ­n, Patricia
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_28
%X Recent research activities in the field of attribute selection for carrying on dialogs with on-line customers have focused on entropy-based approaches that make use of information gain measures. These measures consider the distribution of attribute values in the case base and are focused on their ability to reduce dialog length. The implicit knowledge contained in the similarity measures is neglected. In previous work, we proposed the similarity-influenced selection method simVar, which selects the attributes that induce the maximum change in similarity distribution amongst the candidate cases, thereby partitioning the case base into similar and dissimilar cases. In this paper we present an evaluation of the selection methods using three domains with distinct characteristics. The comparison of the selection methods is based on the quality of the dialogs generated. Statistical analysis was used to support the evaluation results.
%P 380-394


%0 Conference Proceedings
%T A framework for defining distances between first-order logic objects
%A Ramon, Jan
%A Bruynooghe, Maurice
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027331
%X Several learning systems, such as systems based on clustering and instance based learning, use a measure of distance between objects. Good measures of distance exist when objects are described by a fixed set of attributes as in attribute value learners. More recent learning systems however, use a first order logic representation. These systems represent objects as models or clauses. This paper develops a general framework for distances between such objects and reports a preliminary evaluation.
%P 271-280


%0 Conference Proceedings
%T Explanation-driven case-based reasoning
%A Aamodt, Agnar
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_93
%X Problem solving in weak theory domains should compensate for the lack of strong theories by combining the various other knowledge types involved. Such methods should be able to effectively combine general domain knowledge with specific case knowledge. A method is described that utilises a presumably extensive and dense model of general domain knowledge as explanatory support for case-based problem solving and learning. A generic reasoning method â captured in what is called the Activate-explain-focus cycle â is able to utilise a rich knowledge model in producing context-dependent explanations. A specialisation of this method for each of the main subprocesses of case-based reasoning is presented, and illustrated with examples.
%P 274-288


%0 Conference Proceedings
%T Integrating Case-Based Reasoning and Hypermedia Documentation: An Application for the Diagnosis of a Welding Robot at Odense Steel Shipyard
%A Auriol, Eric
%A Crowder, Richard M.
%A MacKendrick, Rob
%A Rowe, Roger
%A Knudsen, Thomas
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_27
%X Reliable and effective maintenance support is a vital consideration for the management within todayâs manufacturing environment. This paper discusses the development a maintenance system for the world largest robot welding facility. The developed system combines a case-based reasoning approach for diagnosis with context information, as electronic on-line manuals, linked using open hypermedia technology. The work discussed in this paper delivers not only a maintenance system for the robot stations under consideration, but also a design framework for developing maintenance systems for other similar applications.
%P 372-385


%0 Conference Paper
%T Condorcet Fusion for Improved Retrieval
%D 2002
%A Mark Montague
%A Javed A. Aslam
%X We present a new algorithm for improving retrieval results by combining document ranking functions: Condorcet-fuse. Beginning with one of the two major classes of voting procedures from Social Choice Theory, the Condorcet procedure, we apply a graph-theoretic analysis that yields a sorting-based algorithm that is elegant, efficient, and effective. The algorithm performs very well on TREC data, often outperforming existing metasearch algorithms whether or not relevance scores and training data is available. Condorcet-fuse significantly outperforms Borda-fuse, the analogous representative from the other major class of voting algorithms.
%0 Conference Proceedings
%T InfoFrax: CBR in Fused Cast Refractory Manufacture
%A Khemani, Deepak
%A Selvamani, Radhika B.
%A Dhar, Ananda Rabi
%A Michael, S. M.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_41
%X This paper describes a CBR application in manufacturing industry, a domain where CBR has by and large proved its applicability and success. The paper details a thorough understanding of the field of fused cast manufacturing basically seen from the perspective of glass furnace, where quality of glass produced is straightaway related to the refractory blocks used in furnace linings. The applicability of CBR paradigm is revisited in the present context. The CBR process needed is conceptualized and designed. The paper describes the evolution of the system beginning with tackling hurdles of knowledge acquisition, a number of pitfalls in the prototype phase, to final implementation of InfoFrax, the CBR system specially devised for the project. It gives an overall description of the architecture and usage. The paper also reports the immediate response to the software in form of direct user feedback, expectations from the existing system, and some future work already underway in the project.
%P 560-574


%0 Conference Proceedings
%T Modular System Design for Multimedial Information Handling
%A Pakucs, HandlingBotond
%A GambÃ¤ck, BjÃ¶rn
%A Hansen, Preben
%D 2007
%X Often, information retrieval from various other media is analogous to text-based retrieval; however , accessing documents in e.g. audio or video formats causes some extra problems, in particular with respect to document segmentation, choice of indexing features, and robustness. We review these diiculties, together with some previous attempts to overcome them, and then describe a very exible, modular IR system which has been designed with a speciic eye towards these issues. 

%0 Conference Proceedings
%T Digital Image Similarity for Geo-spatial Knowledge Management
%A Carswell, James D.
%A Wilson, David C.
%A Bertolotto, Michela
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_6
%X The amount and availability of high-quality geo-spatial image data, such as digital satellite and aerial photographs, is increasing dramatically. Task-based management of such visual information and associated knowledge is a central concern for organisations that rely on digital imagery. We are developing geo-spatial knowledge management techniques that employ case-based reasoning as the core methodology. In order to provide effective retrieval of task-based experiences that center around geo-spatial imagery, we need to forward novel similarity metrics for directly comparing the image components of experience cases. Based on work in geo-spatial image database retrieval, we are building an effective similarity metric for geo-spatial imagery that makes comparisons based on derived image features, their shapes, and the spatial relations between them. This paper gives an overview of the geo-spatial knowledge management context, describes our image similarity metric, and provides an initial evaluation of the work.
%P 58-72


%0 Conference Proceedings
%T A logical representation for relevance criteria
%A Ashley, Kevin D.
%A Aleven, Vincent
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_98
%X As CBR system designers confront the problem of building programs that can explain their results, a logical representation of relevance concepts will be useful. Our application, tutoring students to reason with cases, necessitated adopting a declarative, logical representation of case-based relevance concepts. Representing relevance criteria in first-order logic with LOOM has turned out not to be prohibitively expensive computationally and has had considerable advantages: it facilitates the use of multiple, changing relevance criteria involving complex relationships among cases, we have made some progress in enabling a program to explain aspects of its relevance criteria by example, and even students are beginning to express their own queries in a simplified version of the language for CATO, our tutoring program, to interpret.
%P 338-352


%0 Conference Proceedings
%T A scalable approach for question based indexing of encyclopedic texts
%A Wisdo, Christopher
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_492
%X This paper describes a tool set developed to aid a human content analyst index texts for use in a particular form of structured hypermedia known as an ASK System. The tool set assists the content analyst by employing a library of question templates to represent the types of questions the output ASK system might contain. Question templates provided roughly a six-fold increase in the rate with which texts are indexed compared to manual techniques. Indexing progress is linear throughout, indicating that the methodology can be used to effectively index a large body of texts.
%P 200-210


%0 Conference Proceedings
%T Application of inductive logic programming to discover rules governing the three-dimensional topology of protein structure
%A Turcotte, Marcel
%A Muggleton, Stephen H.
%A Sternberg, Michael J. E.
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027310
%X Inductive Logic Programming (ILP) has been applied to discover rules governing the three-dimensional topology of protein structure. The data-set unifies two sources of information; SCOP and PROMOTIF. Cross-validation results for experiments using two background knowledge sets, global (attribute-valued) and constitutional (relational), are presented. The application makes use of a new feature of Progol4.4 for numeric parameter estimation. At this early stage of development, the rules produced can only be applied to proteins for which the secondary structure is known. However, since the rules are insightful, they should prove to be helpful in assisting the development of taxonomic schemes. The application of ILP to fold recognition represents a novel and promising approach to this problem.
%P 53-64


%0 Conference Proceedings
%T Some limitations of feature-based recognition in case-based design
%A Hinrichs, Thomas R.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_43
%X A crucial part of Case-Based Reasoning is retrieving cases that are similar or otherwise relevant to the problem at hand. Traditionally, this has been formulated as a problem of indexing and accessing cases based on sets of predictive features. More generally, however, we can think of retrieval as a problem of recognition. In this light, several limitations of the feature-based approach become apparent. What constitutes a feature? What makes a feature predictive? And how is retrieval possible when the structure of an input is predictive, but its components are not?
%P 471-480


%0 Journal Article
%T Distributed EnergyÂ­-conserving Routing Protocols
%D 2003
%A Li, Qun
%A Aslam, Javed A.
%A Rus, Daniela
%X This paper discusses several distributed power-aware routing protocols in wireless ad-hoc networks (especially sensor networks). We seek to optimize the lifetime of the network. We have developed three distributed power-aware algorithms and analyzed their efficiency in terms of the number of message broadcasts and the overall network lifetime modelled as the time to the first message that can not be sent. These are: (1) a distributed min power algorithm (modelled on a distributed version of Dijkstra's algorithm), (2) a distributed max-min algorithm, and (3) the distributed version of the centralized online max-min zP/sub min/ algorithm presented by Qun Li et al. (2001). The first two algorithms are used to define the third, although they are very interesting and useful on their own for applications where the optimization criterion is the minimum power, respectively the maximum residual power. The distributed max-min zP/sub min/ algorithm optimizes the overall lifetime of the network by avoiding nodes of low power, while not using too much total power.

%0 Conference Proceedings
%T Qualitative knowledge to support reasoning about cases
%A Aarts, Robert J.
%A Rousu, Juho
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_518
%X Our recipe planner for bioprocesses, Sophist, uses a semi-qualitative model to reason about cases. The model represents qualitative knowledge about the possible effects of differences between cases and about the possible causes of observed problems. Hence, the model is a crucial resource of adaptation knowledge. The model representation has been developed specifically to support CBR tasks. The essential notion in this representation is that of an influence. Representation of domain knowledge in an influence graph and a mapping of case-features onto nodes of such a graph, enable a variety of interesting reasoning tasks. Examples of such task illustrate how qualitative reasoning and case-based reasoning support each other in complex planning tasks.
%P 489-498


%0 Conference Proceedings
%T Active Exploration in Instance-Based Preference Modeling
%A Karl Branting, L.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_3
%X Knowledge of the preferences of individual users is essential for intelligent systems whose performance is tailored for individual users, such as agents that interact with human users, instructional environments, and learning apprentice systems. Various memory-based, instance-based, and case-based systems have been developed for preference modeling, but these system have generally not addressed the task of selecting examples to use as queries to the user. This paper describes UGAMA, an approach to learning preference criteria through active exploration. Under this approach, Unit Gradient Approximations (UGAs) of the underlying quality function are obtained at a set of reference points through a series of queries to the user. Equivalence sets of UGAs are then merged and aligned (MA) with the apparent boundaries between linear regions. In an empirical evaluation with artificial data, use of UGAs as training data for an instance-based ranking algorithm (1ARC) led to more accurate ranking than training with random instances, and use of UGAMA led to greater ranking accuracy than UGAs alone.
%P 29-43


%0 Conference Paper
%T Applications of Approximate Word Matching in Information Retrieval James C. French Allison L. Powell
%D 1997
%A James C. French
%A Allison L. Powell
%A Eric Schulman 
%X As more online databases are integrated into digital libraries, the issue of quality control of the data becomes increasingly important, especially as it relates to the effective retrieval of information. The need to discover and reconcile variant forms of strings in bibliographic entries, i.e., authority work, will become more difficult. Spelling variants, misspellings, and transliteration differences will all increase the difficulty of retrieving information. Approximate string matching has traditionally been used to help with this problem. In this paper we introduce the notion of approximate word matching and show how it can be used to improve detection and categorization of variant forms.
%0 Conference Proceedings
%T Improving Part of Speech Disambiguation Rules by Adding Linguistic Knowledge
%A Lindberg, Nikolaj
%A Eineborg, Martin
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_18
%X This paper reports the ongoing work of producing a state of the art part of speech tagger for unedited Swedish text. Rules eliminating faulty tags have been induced using Progol. In previously reported experiments, almost no linguistically motivated background knowledge was used [5,8]. Still, the result was rather promising (recall 97.7%, with a pending average ambiguity of 1.13 tags/word). Compared to the previous study, a much richer, more linguistically motivated, background knowledge has been supplied, consisting of examples of noun phrases, verb chains, auxiliary verbs, and sets of part of speech categories. The aim has been to create the background knowledge rapidly, without laborious hand-coding of linguistic knowledge. In addition to the new background knowledge, new, more expressive rule types have been induced for two part of speech categories and compared to the corresponding rules of the previous bottom-line experiment. The new rules perform considerably better, with a recall of 99.4% for the new rules, compared to 97.6% for the old rules. Precision was slightly better for the new rules.
%P 186-197


%0 Conference Proceedings
%T On a sufficient condition for the existence of most specific hypothesis in progol
%A Furukawa, Koichi
%A Murakami, Tomoko
%A Ueno, Ken
%A Ozaki, Tomonobu
%A Shimazu, Keiko
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_44
%X In this paper, we give a sufficient condition for the existence of the most specific hypothesis (MSH) in Progol. Muggleton [2] showed that for any first order theory (background knowledge) B and a single clause (a positive example) E, there exists the most specific hypothesis Â¬bot(B, E) which satisfies B â Â¬,bot(B, E) â¨ E and for any hypothesis H satisfying B â H â¨ E, H entails bot(B, E) assuming that hypotheses are all single clauses. Yamamoto[8] gave a counter example and indicated that Muggleton's proof contains error. He also gave a sufficient condition under which the MSH exists. In this paper, we give another and more realistic sufficient condition to guarantee the existence of the MSH.
%P 157-164


%0 Conference Proceedings
%T âFish and Sinkâ an anytime-algorithm to retrieve adequate cases
%A Schaaf, JÃ¶rg Walter
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_50
%X The main idea of the presented approach is based on the observation that identical data can be interpreted and used differently in different situations and by different persons. Data is considered individually and according to the actual situation. This phenomena can be interpreted as regarding different aspects. Here, the notion of aspects is applied to cases in the area of Cased Based Reasoning. This requires special representation of cases, special structure of case bases and a new algorithm to work on the defined structure. In this paper we will focus on description and discussion of an anytime algorithm that searches for cases regarding the relevant aspects.
%P 538-547


%0 Conference Proceedings
%T A Symmetric Nearest Neighbor Learning Rule
%A Nock, Richard
%A Sebban, Marc
%A Jappy, Pascal
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_20
%X In this paper, we propose a thorough investigation of a nearest neighbor rule which we call the âSymmetric Nearest Neighbor (sNN) ruleâ. Basically, it symmetrises the classical nearest neighbor relationship from which are computed the points voting for some instance. Experiments on 29 datasets, most of which are readily available, show that the method significantly outperforms the traditional Nearest Neighbors methods. Experiments on a domain of interest related to tropical pollution normalization also show the greater potential of this method. We finally discuss the reasons for the ruleâs efficiency, provide methods for speeding-up the classification time, and derive from the sNN rule a reliable and fast algorithm to fix the parameter k in the k-NN rule, a longstanding problem in this field.
%P 222-233


%0 Conference Proceedings
%T Generalization under implication by Î»-subsumption
%A Markov, Zdravko
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027325
%X The present paper discusses a generalization operator based on the Î»-subsumption ordering between Horn clauses introduced by the author elsewhere. It has been shown that Î»-subsumption is strictly stronger than Î¸-subsumption and a local equivalent of generalized subsumption. With some language restrictions it is decidable and possesses some other useful properties. Most importantly it allows defining a non-trivial upper bound of the Î»-subsumption generalization hierarchy without the use of negative examples. Consequently this allows solving a version of the ILP task with positive-only examples.
%P 215-224


%0 Conference Proceedings
%T Integrating rules and cases for the classification task
%A Surma, Jerzy
%A Vanhoof, Koen
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_29
%X The recent progress in Case- Based Reasoning has shown that one of the most important challenges in developing future AI methods will be to combine and synergistically utilize general and case-based knowledge. In this paper a very rudimentary kind of integration for the classification task, based on simple heuristics, is sketched: âTo solve a problem, first try to use the conventional rule-based approach. If it does not work, try to remember a similar problem you have solved in the past and adapt the old solution to the new situationâ. This heuristic approach is based on the knowledge base that consists of rule base and exception case base. The method of generating this kind of knowledge base from a set of examples is described. The proposed approach is tested, and compared with alternative approaches. The experimental results show that the presented integration method can lead to an improvement in accuracy and comprehensibility.
%P 325-334


%0 Conference Paper
%T MOTION ESTIMATION BASED ON AFFINE MOMENT INVARIANTS
%D 1998
%A G. Tzanetakis
%A M. Traka
%A G. G. Tziritas
%X A method is proposed for parametric motion estimation of an image region. It is assumed that the region considered undergoes an affine transformation, which means that the motion is composed of a translation and a pure affine function of pixel coordinates. The solution of the object correspondence problem is assumed to be known. The estimation of the six motion parameters is based on the moments of the corresponding image regions. Moments up to order three are needed. For the motion computation each region is transformed to a standard position which is defined using affine invariants. The result of motion estimation is checked in the construction of a mosaic image.
%0 Conference Proceedings
%T Inducing shogi heuristics using inductive logic programming
%A Nakano, Tomofumi
%A Inuzuka, Nobuhiro
%A Seki, Hirohisa
%A Itoh, Hidenori
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027319
%X This paper reports the results of an inductive logic programming (ILP) application to solve shogi or Japanese chess mating problems, which are puzzles using shogi rules. The problems can be solved by heuristic search of AND-OR trees. We propose a method of using the ILP technique to generate heuristic functions, which are automatically tuned according to the confidence of the knowledge induced by ILP. Experiments show that the method prunes search space compared with a naive search.
%P 155-164


%0 Conference Proceedings
%T Using CBR for Automation of Software Design Patterns
%A Gomes, Paulo
%A Pereira, Francisco C.
%A Paiva, Paulo
%A Seco, Nuno
%A Carreiro, Paulo
%A Ferreira, JosÃ© L.
%A Bento, Carlos
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_39
%X Software design patterns are used in software engineering as a way to improve and maintain software systems. Patterns are abstract solutions to problem categories, and they describe why, how, and when can a pattern be applied. Their description is based on natural language, which makes the automation of design patterns a difficult task. In this paper we present an approach for automation of design pattern application. We focus on the selection of what pattern to apply, and where to apply it. We follow a Case-Based Reasoning approach, providing a complete framework for pattern application. In our approach cases describe situations for application of patterns.
%P 534-548


%0 Conference Proceedings
%T Lookahead and discretization in ILP
%A Blockeel, Hendrik
%A De Raedt, Luc
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_36
%X We present and evaluate two methods for improving the performance of ILP systems. One of them is discretization of numerical attributes, based on Fayyad and Irani's text [9], but adapted and extended in such a way that it can cope with some aspects of discretization that only occur in relational learning problems (when indeterminate literals occur). The second technique is lookahead. It is a well-known problem in ILP that a learner cannot always assess the quality of a refinement without knowing which refinements will be enabled afterwards, i.e. without looking ahead in the refinement lattice. We present a simple method for specifying when lookahead is to be used, and what kind of lookahead is interesting. Both the discretization and lookahead techniques are evaluated experimentally. The results show that both techniques improve the quality of the induced theory, while computational costs are acceptable.
%P 77-84


%0 Conference Proceedings
%T Remembering Why to Remember: Performance-Guided Case-Base Maintenance
%A Leake, David B.
%A Wilson, David C.
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_15
%X An important focus of recent CBR research is on how to develop strategies for achieving compact, competent case-bases, as a way to improve the performance of CBR systems. However, compactness and competence are not always good predictors of performance, especially when problem distributions are non-uniform. Consequently, this paper argues for developing methods that tie case-base maintenance more directly to performance concerns. The paper begins by examining the relationship between competence and performance, discussing the goals and constraints that should guide addition and deletion of cases. It next illustrates the importance of augmenting competence-based criteria with quantitative performance-based considerations, and proposes a strategy for closely re.ecting adaptation performance e.ects when compressing a case-base. It then presents empirical studies examining the performance tradeo.s of current methods and the benefits of applying fine-grained performance-based criteria to case-base compression, showing that performance-based methods may be especially important for task domains with non-uniform problem distributions.
%P 161-172


%0 Conference Proceedings
%T An engineering approach for troubleshooting case bases
%A Trott, James R.
%A Leng, Bing
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_490
%X Troubleshooting is a common application of case base technology. Often in these cases, the goal is to capture the approaches of troubleshooting experts and put these troubleshooting best practices in the hands of lesser experienced analysts. Effective knowledge capture is the primary bottleneck to creating a good troubleshooting case base. We used the KADS knowledge modeling methodology to guide the knowledge acquisition to create such a case base. KADS helped us to validate the logic of the entire case base before writing one case and to implement it more quickly than normal and with no errors. This paper illustrates our experience in the use of KADS to help build case bases effectively.
%P 178-189


%0 Conference Proceedings
%T A probabilistic model for case-based reasoning
%A Rodriguez, AndrÃ©s F.
%A Vadera, Sunil
%A Sucar, L. Enrique
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_530
%X An exemplar-based model with foundations in Bayesian networks is described. The proposed model utilises two Bayesian networks: one for indexing of categories, and another for identifying exemplars within categories. Learning is incrementally conducted each time a new case is classified. The representation structure dynamically changes each time a new case is classified and a coverage function is used as a basis for selecting suitable exemplars. Finally, a simple example is given to illustrate the concepts in the model.
%P 623-632


%0 Conference Proceedings
%T Evaluating a Multi-modal Reasoning System in Diabetes Care
%A Montani, Stefania
%A Bellazzi, Riccardo
%A Portinale, Luigi
%A Stefanelli, Mario
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_40
%X In the context of Insulin Dependent Diabetes Mellitus care, we developed a decision support system that relies on a tight integration of Case Based Reasoning and Rule Based Reasoning methodologies. In this paper, we aim at presenting the evaluation strategy we have defined to test the system accuracy, safety and reliability, and the first results obtained both on simulated and on real patients data. Reliability was positively judged by a group of expert diabetologists; an increase in the performances of the system is foreseen as new knowledge will be acquired, through its usage in clinical practice.
%P 467-478


%0 Conference Proceedings
%T A Case-Based Methodology for Planning Individualized Case Oriented Tutoring
%A Seitz, Alexander
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_23
%X The presented methods allow the modeling of student skills by a history of how well a student has performed on a series of tutoring cases. By this means, the explicit representation of a studentâs knowledge, which is especially difficult for case oriented systems, can be avoided. Moreover, case histories make it possible to model the improvement of studentâs skills and thus can be used for retrieving and adapting appropriate tutoring plans for further tutoring cases.
%P 318-328


%0 Conference Proceedings
%T Combining LAPIS and WordNet for the Learning of LR Parsers with Optimal Semantic Constraints
%A Kazakov, Dimitar
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_14
%X There is a history of research focussed on learning of shiftreduce parsers from syntactically annotated corpora by the means of machine learning techniques based on logic. The presence of lexical semantic tags in the treebank has proved useful for learning semantic constraints which limit the amount of nondeterminism in the parsers. The level of generality of the semantic tags used is of direct importance to that task. We combine the ILP system LAPIS with the lexical resource WordNet to learn parsers with semantic constraints. The generality of these constraints is automatically selected by LAPIS from a number of options provided by the corpus annotator. The performance of the parsers learned is evaluated on an original corpus also described in the article.
%P 140-151


%0 Journal Article
%T An inferential approach to Information Retrieval and its implementation using a manual thesaurus
%A Nie, Jian-Yun
%A Brisebois, Martin
%J Artificial Intelligence Review
%D 1996
%8 October 01
%V 10
%N 5
%@ 1573-7462
%F Nie1996
%X Most inferential approaches to Information Retrieval (IR) have been investigated within the probabilistic framework. Although these approaches allow one to cope with the underlying uncertainty of inference in IR, the strict formalism of probability theory often confines our use of knowledge to statistical knowledge alone (e.g. connections between terms based on their co-occurrences). Human-defined knowledge (e.g. manual thesauri) can only be incorporated with difficulty. In this paper, based on a general idea proposed by van Rijsbergen, we first develop an inferential approach within a fuzzy modal logic framework. Differing from previous approaches, the logical component is emphasized and considered as the pillar in our approach. In addition, the flexibility of a fuzzy modal logic framework offers the possibility of incorporating human-defined knowledge in the inference process. After defining the model, we describe a method to incorporate a human-defined thesaurus into inference by taking user relevance feedback into consideration. Experiments on the CACM corpus using a general thesaurus of English, Wordnet, indicate a significant improvement in the system's performance.
%9 journal article
%R 10.1007/BF00130693
%U https://doi.org/10.1007/BF00130693
%P 409-439


%0 Conference Proceedings
%T Experimental study of a similarity metric for retrieving pieces from structured plan cases: Its role in the originality of plan case solutions
%A Macedo, LuÃ­s
%A Pereira, Francisco C.
%A Grilo, Carlos
%A Cardoso, AmÃ­lcar
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_526
%X This paper describes a quantitative similarity metric and its contribution to achieve original plan solutions. This similarity metric is used by an iterative process of piece retrieval from structured plan cases. Within our approach plan cases are tree-like networks of pieces (goals and actions). These case pieces are ill-related each other by links (explanations). These links may be classified as hierarchical or temporal, antecedent or consequent, and explicit or implicit. Besides links, each case piece has also information about its properties (the attributes-value pairs), its hierarchical and temporal position in the case (the address), and about its constraints in the relationship with others (the constraints). The similarity metric computes a similarity value between two case pieces taking into account similarities between these case piece's information types. Each time a problem is proposed, different weights are given to some of those similarities, with the aim of solving it with an original solution. This similarity metric is used by the system INSPIRER (ImagiNation taking as Source Past and Imperfectly REalated Reasonings). We illustrate the role of the similarity metric in the creativity of solutions, focusing specially their originality, with the presentation of the experimental results obtained in the musical composition domain, which is considered by us as a planning domain.
%P 575-586


%0 Conference Proceedings
%T Case memory and retrieval based on the immune system
%A Hunt, John E.
%A Cooke, Denise E.
%A Holstein, Horst
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_19
%X A variety of case memory organisations and case retrieval techniques have been proposed in the literature. Each of these has different features which can affect how useful they are for different applications. However, in applications which are likely to hold very large numbers of cases, which are highly volatile, and the structure of which is poorly understood, most of the current approaches are unsuitable.
%P 205-216


%0 Conference Proceedings
%T Applying Recursive CBR for the Customization of Structured Products in an Electronic Shop
%A Stahl, Armin
%A Bergmann, Ralph
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_26
%X When applying CBR for Electronic Commerce, the adaptation capabilities of CBR can be used for product customization. Most adaptation techniques suffer from the problem that they require a large knowledge acquisition effort which leads to problems in the rapidly changing E-Commerce scenario. In this paper we present a new approach to adaptation that is particularly suited to Electronic Commerce applications. It assumes that products can be structured hierarchically into sub-components. Adaptation is achieved by incrementally replacing unsuitable sub-components through recursively applying CBR to find best-matching alternative sub-components. The presented approach avoids huge portions of the knowledge acquisition effort and is prototypically implemented as an extension of the CBR-Works tool.
%P 297-308


%0 Conference Proceedings
%T Affect-Driven CBR to generate expressive music
%A Arcos, Josep LluÃ­s
%A CaÃ±amero, Dolores
%A de MÃ¡ntaras, Ramon LÃ³pez
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_1
%X We present an extension of an existing system, called SaxEx, capable of generating expressive musical performances based on Case-Based Reasoning (CBR) techniques. The previous version of SaxEx did not take into account the possibility of using affective labels to guide the CBR task. This paper discusses the introduction of such affective knowledge to improve the retrieval capabilities of the system. Three affective dimensions are consideredâtender-aggressive, sad-joyful, and calm-restless that allow the user to declaratively instruct the system to perform according to any combination of five qualitative values along these three dimensions.
%P 1-13


%0 Conference Proceedings
%T A Unified CBR Architecture for Robot Navigation
%A Fox, Susan Eileen
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_35
%X A delivery robot navigating in the real world and contending with multiple goals and priorities benefits from combining deliberative and reactive planning. Deliberative planners anticipate and optimize actions, and manage multiple goals at once. Reactive planners respond flexibly and moment-to-moment to a changing world, based on incomplete and flawed knowledge. This project proposes using case-based reasoning to fully integrate high-level and low-level planning techniques, along with other reasoning tasks of the system. The resulting robot allows case selection to mediate between methods. In addition, the robot learns by recording new reactive behaviors, storing new plans it creates, and introspective learning of retrieval features.
%P 406-417


%0 Conference Proceedings
%T Combining Divide-and-Conquer and Separate-and-Conquer for Efficient and Effective Rule Induction
%A BostrÃ¶m, Henrik
%A Asker, Lars
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_5
%X Divide-and-Conquer (DAC) and Separate-and-Conquer (SAC) are two strategies for rule induction that have been used extensively. When searching for rules DAC is maximally conservative w.r.t. decisions made during search for previous rules. This results in a very efficient strategy, which however suffers from difficulties in effectively inducing disjunctive concepts due to the replication problem. SAC on the other hand is maximally liberal in the same respect. This allows for a larger hypothesis space to be searched, which in many cases avoids the replication problem but at the cost of lower efficiency. We present a hybrid strategy called Reconsider-and-Conquer (RAC), which handles the replication problem more effectively than DAC by reconsidering some of the earlier decisions and allows for more efficient induction than SAC by holding on to some of the decisions. We present experimental results from propositional, numerical and relational domains demonstrating that RAC significantly reduces the replication problem from which DAC suffers and is several times (up to an order of magnitude) faster than SAC.
%P 33-43


%0 Conference Proceedings
%T Sorted Downward Refinement: Building Background Knowledge into a Refinement Operator for Inductive Logic Programming
%A Frisch, Alan M.
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_11
%X Since its inception, the field of inductive logic programming has been centrally concerned with the use of background knowledge in induction. Yet, surprisingly, no serious attempts have been made to account for background knowledge in refinement operators for clauses, even though such operators are one of the most important, prominent and widely-used devices in the field. This paper shows how a sort theory, which encodes taxonomic knowledge, can be built into a downward, subsumption-based refinement operator for clauses.
%P 104-115


%0 Conference Proceedings
%T Learning rules that classify ocular fundus images for glaucoma diagnosis
%A Mizoguchi, Fumio
%A Ohwada, Hayato
%A Daidoji, Makiko
%A Shirato, Shiroteru
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_53
%X This paper provides an empirical study of an Inductive Logic Programming (ILP) method through the application to classifying ocular fundus images for glaucoma diagnosis. Key issues in this study are not only dealing with low-level measurement data such as image, but also producing diagnostic rules that are readable and comprehensive for interactions to medical experts. For this purpose, we develop a constraintdirected ILP system, GKS, that handles both symbolic and numerical data, and produce Horn clauses with numerical constraints. Furthermore, we provide GKS with a âsequentailâ learning facility where GKS repeatedly generates a single best rule which becomes background knowledge for the next learning phase. Since the learning target for this application is the abnormality of each segment in image, generated rules represent the relationships between abnormal segments. Since such relationships can be interpreted as qualitative rules and be used as diagnostic rules directly, the present method provides automatic construction of knowledge base from expert's accumulated diagnostic experience. Furthermore, the experimental result shows that induced rules have high statistical performance. The present study indicates the advantage and possibility of the ILP approach to medical diagnosis from measurement data.
%P 146-159


%0 Conference Proceedings
%T Inducing Information Extraction Systems for New Languages via CrossÂ­Language Projection
%D 2002 
%A Riloff, Ellen
%A Schafer, Charles
%A Yarowsky, David
%X Information extraction (IE) systems are costly to build because they require development texts, parsing tools, and specialized dictionaries for each application domain and each natural language that needs to be processed. We present a novel method for rapidly creating IE systems for new languages by exploiting existing IE systems via cross-language projection. Given an IE system for a source language (e.g., English), we can transfer its annotations to corresponding texts in a target language (e.g., French) and learn information extraction rules for the new language automatically. In this paper, we explore several ways of realizing both the transfer and learning processes using off-the-shelf machine translation systems, induced word alignment, attribute projection, and transformation-based learning. We present a variety of experiments that show how an English IE system for a plane crash domain can be leveraged to automatically create a French IE system for the same domain.


%0 Conference Paper
%T A unified model for metasearch and the efficient evaluation of retrieval systems via the hedge algorithm
%D 2003
%A Virgiliu Pavlu
%A Robert Savell 
%A Javed A. Aslam
%X We present a unified framework for simultaneously solving both the pooling problem (the construction of efficient document pools for the evaluation of retrieval systems) and metasearch (the fusion of ranked lists returned by retrieval systems in order to increase performance). The implementation is based on the Hedge algorithm for online learning, which has the advantage of convergence to bounded error rates approaching the performance of the best linear combination of the underlying systems. The choice of a loss function closely related to the average precision measure of system performance ensures that the judged document set performs well, both in constructing a metasearch list and as a pool for the accurate evaluation of retrieval systems. Our experimental results on TREC data demonstrate excellent performance in all measures---evaluation of systems, retrieval of relevant documents, and generation of metasearch lists.

%0 Conference Proceedings
%T A first study on case-based planning in organic synthesis
%A Napoli, Amedeo
%A Lieber, Jean
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_108
%X In this paper, we present an application of case-based reasoning to the design of synthetic plans in organic synthesis. First, we briefly introduce the principles of organic synthesis planning, e.g. building a new molecular structure or target molecule. Then, we present the knowledge representation and reasoning principles on which relies the system for organic synthesis planning that we are developing. Two main kinds of reasoning processes are employed in the system. Classificationbased reasoning is used at a tactical level for the perception of chemical characteristics and the structure modifications of the target molecule. Case-based reasoning is used at a strategic level to build a synthetic plan, according to the similarity between the target molecule and memorized synthetic plans. The representation and the handling of one-step synthetic plans are detailed and end the paper.
%P 458-469


%0 Conference Proceedings
%T A Unified Long-Term Memory Systemâ
%A Lawton, James H.
%A Turner, Roy M.
%A Turner, Elise H.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_14
%X Memory-based reasoning systems are a class of reasoners that derive solutions to new problems based on past experiences. Such reasoners use a long-term memory (LTM) to act as a knowledge base of these past experiences, which may be represented by such things as specific events (i.e. cases), plans, scripts, etc. This paper describes a Unified Long-Term Memory (ULTM) system, which is a dynamic, conceptual memory that was designed to be a general LTM capable of simultaneously supporting multiple intentional reasoning systems. Through a unique mixture of content-independent and domain-specific mechanisms, the ULTM is able to flexibly provide reasoners accurate and timely storage and recall of episodic memory structures. In addition, the ULTM provides support for recognizing opportunities to satisfy suspended goals, allowing reasoning systems to better cope with the unpredictability of dynamic real-world domains by helping them take advantage of unexpected events.
%P 188-202


%0 Conference Proceedings
%T Speech-Driven Text Retrieval: Using Target IR Collections for Statistical Language Model Adaptation in Speech Recognition
%A Fujii, Atsushi
%A Itou, Katunobu
%A Ishikawa, Tetsuya
%Y Coden, Anni R.
%Y Brown, Eric W.
%Y Srinivasan, Savitha
%S Information Retrieval Techniques for Speech Applications
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-45637-7
%F 10.1007/3-540-45637-6_9
%X Speech recognition has of late become a practical technology for real world applications. Aiming at speech-driven text retrieval, which facilitates retrieving information with spoken queries, we propose a method to integrate speech recognition and retrieval methods. Since users speak contents related to a target collection, we adapt statistical language models used for speech recognition based on the target collection, so as to improve both the recognition and retrieval accuracy. Experiments using existing test collections combined with dictated queries showed the effectiveness of our method.
%P 94-104


%0 Conference Proceedings
%T Systematic Predicate Invention in Inductive Logic Programming
%A Martin, Lionel
%A Vrain, Christel
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_48
%X We propose in this paper a new approach for learning predicate definitions from examples and from an initial theory. The particularity of this approach consists in inventing both a new predicate symbol and a specification for this predicate at most steps of learning. The specifications that are built are incomplete and imprecise, what is modelized by introducing the notion of a-interpretation. At the end of the learning task, some invented predicates are removed by unfolding techniques. The remaining predicates either enable to simplify the program, or are defined by recursive programs. In the second case, the program could not have been learned without inventing these predicates. The method has been implemented in a system, called SPILP, which has been successfully tested for inventing predicates which simplify the learned programs as well as for inventing recursively defined predicates. Let us point out that the introduction of Ï-interpretations gives us a general framework for dealing with imprecise specifications and that SPILP can work, even when the target concepts are also incompletely defined by Ï-interpretations.
%P 189-204


%0 Conference Proceedings
%T Using learned extraction patterns for text classification
%A Riloff, Ellen
%Y Wermter, Stefan
%Y Riloff, Ellen
%Y Scheler, Gabriele
%S Connectionist, Statistical and Symbolic Approaches to Learning for Natural Language Processing
%D 1996
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-49738-7
%F 10.1007/3-540-60925-3_53
%X A major knowledge-engineering bottleneck for information extraction systems is the process of constructing an appropriate dictionary of extraction patterns. AutoSlog is a dictionary construction system that has been shown to substantially reduce the time required for knowledge engineering by learning extraction patterns automatically. However, an open question was whether these extraction patterns were useful for tasks other than information extraction. We describe a series of experiments that show how the extraction patterns learned by AutoSlog can be used for text classification. Three dictionaries produced by AutoSlog for different domains performed well in our text classification experiments.
%P 275-289


%0 Conference Proceedings
%T A Note on Two Simple Transformations for Improving the Efficiency of an ILP System
%A Costa, VÃ­tor Santos
%A Srinivasan, Ashwin
%A Camacho, Rui
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_14
%X Inductive Logic Programming (ILP) systems have had note-worthy successes in extracting comprehensible and accurate models for data drawn from a number of scientific and engineering domains. These results suggest that ILP methods could enhance the model-construction capabilities of software tools being developed for the emerging discipline of âknowledge discovery from databases.â One significant concern in the use of ILP for this purpose is that of efficiency. The performance of modern ILP systems is principally affected by two issues: (1) they often have to search through very large numbers of possible rules (usually in the form of definite clauses); (2) they have to score each rule on the data (usually in the form of ground facts) to estimate âgoodnessâ. Stochastic and greedy approaches have been proposed to alleviate the complexity arising from each of these issues. While these techniques can result in order-of-magnitude improvements in the worst-case search complexity of an ILP system, they do so at the expense of exactness. As this may be unacceptable in some situations, we examine two methods that result in admissible transformations of clauses examined in a search. While the methods do not alter the size of the search space (that is, the number of clauses examined), they can alleviate the theorem-proving effort required to estimate goodness. The first transformation simply involves eliminating literals using a weak test for redundancy. The second involves partitioning the set of literals within a clause into groups that can be executed independently of each other. The efficacy of these transformations are evaluated empirically on a number of well-known ILP datasets. The results suggest that for problems that require the use of highly non-determinate predicates, the transformations can provide significant gains as the complexity of clauses sought increases.
%P 225-242


%0 Conference Proceedings
%T Virtual Function Generators: Representing and Reusing Underlying Design Concepts in Conceptual Synthesis of Mechanisms for Function Generation
%A Han, Younghyun
%A Lee, Kunwoo
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_33
%X This paper describes an approach to represent and reuse efficiently the underlying design concepts in the existing mechanisms in order to synthesize mechanisms for function-generation and motion-transmission. A notion of virtual function generator is introduced to conceptualize and represent all possible underlying design concepts in the existing mechanisms. The virtual function generators are extracted from the existing mechanisms and composed of one or more primitive mechanisms together with the involved functions. They serve as new conceptual building blocks in the conceptual synthesis of design alternatives. The whole design concept or sub-concepts of the mechanisms can be represented and reused efficiently by the notion of virtual function generator. New mechanisms are generated by extracting and combining the underlying design concepts via the virtual function generators. The capability of the proposed approach is illustrated with a design example.
%P 453-467


%0 Conference Proceedings
%T Using a neural network to learn general knowledge in a case-based system
%A Reategui, Eliseo
%A Campbell, John A.
%A Borghetti, Shirley
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_49
%X This paper presents a new approach for learning general knowledge in a diagnostic case-based system through the use of a neural network. We take advantage of the self-adapting nature of the neural network to discover the most relevant features and combination of features for each diagnosis considered. The knowledge acquired by the network is interpreted and mapped into symbolic diagnosis descriptors, which are kept and used by the case-based system to guide its reasoning process, to retrieve cases from a case library and to build explanations. The neural network used in the learning process was the Combinatorial Neural Model, a network that has been combined with other symbolic approaches previously. The paper presents the method used to interpret the knowledge learned in the neural network, as well as the guidelines followed by the reasoning process of the CBR system. An initial experiment in clinical psychology is also reported, where the case-based model introduced here was used to learn and represent the psychological profile of patients in evaluation for heart transplant.
%P 528-537


%0 Conference Proceedings
%T Towards improving case adaptability with a genetic algorithm
%A Purvis, Lisa
%A Athalye, Salil
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_510
%X Case combination is a difficult problem in Case Based Reasoning, as sub-cases often exhibit conflicts when merged together. In our previous work we formalized case combination by representing each case as a constraint satisfaction problem, and used the minimum conflicts algorithm to systematically synthesize the global solution. However, we also found instances of the problem in which the minimum conflicts algorithm does not perform case combination efficiently. In this paper we describe those situations in which initially retrieved cases are not easily adaptable, and propose a method by which to improve case adaptability with a genetic algorithm. We introduce a fitness function that maintains as much retrieved case information as possible, while also perturbing a sub-solution to allow subsequent case combination to proceed more efficiently.
%P 403-412


%0 Conference Proceedings
%T Selecting and Comparing Multiple Cases to Maximise Result Quality after Adaptation in Case-Based Adaptive Scheduling
%A Scott, Steve
%A Osborne, Hugh
%A Simpson, Ron
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_44
%X Recent Case-Based Reasoning research has begun to refocus attention on the problem of automatic adaptation of the retrieved case to give a fuller solution to the new problem. Such work has highlighted problems with the usefulness of similarity assessment of cases where adaptation is involved. As a response to this, methods of case selection are evolving that take adaptation into account. This current work looks more closely at the relationship between selection and adaptation. It considers experimental evidence considering adaptation of multiple cases for one problem. It argues that selection of the best case after adaptation will often make more efficient use of case knowledge than any attempt to pre-select a single case for adaptation.
%P 517-528


%0 Conference Proceedings
%T Evaluation Corpora for Sense Disambiguation in the Medical Domain
%D 2002
%A Raileanu, Diana
%A Buitelaar, Paul
%A Vintar, Spela
%A Bay, JÃ¶rg
%X An important aspect of word sense disambiguation is the evaluation of different methods and parameters. Unfortunately, there is a lack of test sets for evaluation, specifically for languages other than English and even more so for specific domains like medicine. Given that our work focuses on English as well as German text in the medical domain, we had to develop our own evaluation corpora in order to test our disambiguation methods. In this paper we describe the work on developing these corpora, using GermaNet and UMLS as (lexical) semantic resources, next to a description of the annotation tool KiC that we developed for support of the annotation task.


%0 Conference Proceedings
%T On Sufficient Conditions for Learnability of Logic Programs from Positive Data
%A Martin, Eric
%A Sharma, Arun
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_19
%X Shinohara, Arimura, and Krishna Rao have shown learnability in the limit of minimal models of classes of logic programs from positive only data. In most cases, these results involve logic programs in which the âsizeâ of the head yields a bound on the size of the body literals. However, when local variables are present, such a bound on body literal size cannot directly be ensured. The above authors achieve such a restriction using technical notions like mode and linear inequalities. The present paper develops a conceptually clean framework where the behavior of local variables is controlled by nonlocal ones. It is shown that for certain classes of logic programs, learnablity from positive data is equivalent to limiting identification of bounds for the number of clauses and the number of local variables. This reduces the learning problem finding two integers. This cleaner framework generalizes all the known results and establishes learnability of new classes.
%P 198-209


%0 Conference Proceedings
%T The Life Cycle of Test Cases in a CBR System
%A Minor, Mirjam
%A Hanft, Alexandre
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_39
%X In this article, a case-based approach for managing cases with a life cycle is introduced. The authors present an application for the accompaniment and support of software engineers in their work of specifying test cases. Some general aspects of corporate knowledge editing are discussed. The model of life cycles provides a solution for editing and retrieving cases with several degrees of maturity. It is realised by persistent case numbers, explicit revision states, and a multi-layered similarity function. Some experiments are performed with a prototypical system.
%P 455-466


%0 Conference Proceedings
%T A logical framework for graph theoretical decision tree learning
%A Geibel, Peter
%A Wysotzki, Fritz
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_46
%X We present a logical approach to graph theoretical learning that is based on using alphabetic substitutions for modelling graph morphisms. A classified graph is represented by a definite clause that possesses variables of the sort node for representing nodes and atoms for representing the edges. In contrast to the standard logical semantics, different node variables are assumed to denote different objects. The use of an alphabetical subsumption relation (Î±-subsumption) implies that the least generalization of clauses (Î±-generalization) has different properties than Plotkin's least generalization (gg). We present a method for constructing optimal Î±-generalizations from Plotkin's least generalization. The developed framework is used in the relational decision tree algorithm TRITOP.
%P 173-180


%0 Conference Proceedings
%T The evaluation of a hierarchical case representation using context guided retrieval
%A Watson, Ian
%A Perera, Srinath
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_497
%X This paper presents the results of the comparison of the performance of a hierarchical case representation using a context guided retrieval method against that of a simpler flat file representation using standard nearest neighbour retrieval. The estimation of the construction costs of light industrial warehouse buildings is used as the test domain. Each case comprises approximately 400 features. These are structured into a hierarchical case representation that holds more general contextual features at its top and specific building elements at its leaves. A modified nearest neighbour retrieval algorithm is used that is guided by contextual similarity. Problems are decomposed into sub-problems and solutions recomposed into a final solution. The comparative results show that the context guided retrieval method using the hierarchical case representation out performs the simple flat file representation and standard nearest neighbour retrieval.
%P 255-266


%0 Conference Proceedings
%T Case-Based Reasoning for cash flow forecasting using fuzzy retrieval
%A Lee, Rosina Weber
%A Barcia, Ricardo Miranda
%A Khator, Suresh K.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_47
%X Case-Based Reasoning (CBR) simulates the human way of solving problems as it solves a new problem using a successful past experience applied to a similar problem. In this paper we describe a CBR system that develops forecasts for cash flow accounts. Forecasting cash flows to a certain degree of accuracy is an important aspect of a Working Capital Decision Support System. Working Capital (WC) management decisions reflect a choice among different options on how to arrange the cash flow. The decision establishes an actual event in the cash flow which means that one needs to envision the consequences of such a decision. Hence, forecasting cash flows accurately can minimize losses caused by usually unpredictable events. Cash flows are usually forecasted by a combination of different techniques enhanced by human experts' feelings about the future, which are grounded in past experience. This makes the use of the CBR paradigm the proper choice. Advantages of a CBR system over other Artificial Intelligence techniques are associated to knowledge acquisition, knowledge representation, reuse, updating, and justification. An important step in developing a CBR system is the retrieval of similar cases. The proposed system makes use of fuzzy integrals to calculate the synthetic evaluations of similarities between cases instead of the usual weighted mean.
%P 510-519


%0 Conference Proceedings
%T Selecting most adaptable diagnostic solutions through Pivoting-Based Retrieval
%A Portinale, Luigi
%A Torasso, Pietro
%A Magro, Diego
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_509
%X The aim of the present paper is to investigate a retrieval strategy for case-based diagnosis called Pivoting Based Retrieval (PBR), based on a tight integration between retrieval and adaptation estimation. It exploits a heuristic estimate of the adaptability of a solution; during retrieval, lower and upper bounds for such an estimate are computed for relevant cases and a pivot case is selected, determining which cases have to be considered and which have not. Such a technique has been evaluated on three different domain models and very satisfactory results have been obtained both in terms of accuracy, space and retrieval time
%P 393-402


%0 Conference Proceedings
%T Executing Query Packs in ILP
%A Blockeel, Hendrik
%A Dehaspe, Luc
%A Demoen, Bart
%A Janssens, Gerda
%A Ramon, Jan
%A Vandecasteele, Henk
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_4
%X Inductive logic programming systems usually send large numbers of queries to a database. The lattice structure from which these queries are typically selected causes many of these queries to be highly similar. As a consequence, independent execution of all queries may involve a lot of redundant computation. We propose a mechanism for executing a hierarchically structured set of queries (a âquery packâ) through which a lot of redundancy in the computation is removed.We have incorporated our query pack execution mechanism in the ILP systems TILDE and WARMR by implementing a new Prolog engine ILPROLOG which provides support for pack execution at a lower level. Experimental results demonstrate significant efficiency gains. Our query pack execution mechanism is very general in nature and could be incorporated in most other ILP systems, with similar efficiency improvements to be expected.
%P 60-77


%0 Conference Proceedings
%T A Hybrid Case-Based Reasoner for Footwear Design
%A Main, Julie
%A Dillon, Tharam S.
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_36
%X This paper details the way case-based reasoning has been used to aid footwear designers in creating new designs while maximizing component reuse. A hybrid system was created which uses an object-oriented memory model, neural networks for retrieval and fuzzy feature vectors to augment the basic case-based reasoning model. One of the main tasks involved in the design of any case-based system is determining the features that make up a case and finding a way to index these cases in a case-base for efficient and correct retrieval. This paper looks at the components of this footwear design system and how the various elements join together to create a useful system, in particular, how the use of fuzzy feature vectors and neural networks can improve the indexing and retrieval steps in case-based systems.
%P 497-509


%0 Conference Proceedings
%T Data mining via ILP: The application of Progol to a database of enantioseparations
%A Bryant, Christopher H.
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_37
%X As far as this author is aware, this is the first paper to describe the application of Progol to enantioseparations. A scheme is proposed for data mining a relational database of published enantioseparations using Progol. The application of the scheme is described and a preliminary assessment of the usefulness of the resulting generalisations is made using their accuracy, size, ease of interpretation and chemical justification.
%P 85-92


%0 Conference Proceedings
%T A folder-based graphical interface for an information retrieval system
%D 1999
%A Low, Aidan
%X Past advances in user interface design include the move from an application-centric model to the document-centric model found in the file/folder graphical interfaces of modern operating systems. Recently, we have also seen advances in query-based information retrieval technology, such as the search engines of the World-Wide Web. This thesis proposes an interface that combines the power of these two technologies to produce a unified interface that allows users to navigate their information space more easily and more intuitively. This interface, the Haystack Browser, presents users with a file/folder graphical interface that allows users to dynamically categorize their information space by creating "folders" that correspond to queries within an information retrieval system. The interface is implemented as an extension of the Haystack Project, a personalized information retrieval system under development at the MIT Laboratory for Computer Science. Thesis Supervisor: David R. Karger Title: Associate Professor 

%0 Conference Proceedings
%T Systems, tasks and adaptation knowledge: Revealing some revealing dependencies
%A Hanney, Kathleen
%A Keane, Mark
%A Smyth, Barry
%A Cunningham, Padraig
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_42
%X This paper shows that the use of adaptation knowledge in CBR systems is heavily dependent on certain task and system constraints. Furthermore, the type of adaptation knowledge used in systems performing specific tasks is quite regular and predictable. These conclusions are reached by reviewing forty-two CBR systems and classifying them according to three taxonomies: an adaptation-relevant taxonomy of CBR systems, a taxonomy of tasks and a taxonomy of adaptation knowledge. We then show how different systems cluster with respect to interactions between these three taxonomies. The CBR system designer may find the partition of CBR systems and the division of adaptation knowledge suggested by this paper useful. Moreover, this paper may help focus the initial stages of systems development by suggesting (on the basis of existing work) what types of adaptation knowledge should be supported by a new system. In addition, the paper provides a framework for the preliminary evaluation and comparision of systems.
%P 461-470


%0 Conference Proceedings
%T Case-based reasoning in color matching
%A Cheetham, William
%A Graf, John
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_473
%X A case-based reasoning system for determining what colorants to use for producing a specific color of plastic was created. The selection of colorants needs to take many factors into consideration. A technique that involved fuzzy logic was used to compare the quality of the color match for each factor. The system has been in use for two years at a growing number of GE Plastics sites and has shown significant cost savings.
%P 1-12


%0 Conference Proceedings
%T Discovery of first-order regularities in a relational database using ofine candidate determination
%A Weber, Irene
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_57
%X In this paper, we present an algorithm for the discovery of first order clauses holding in an relational database in the framework of the nonmonotonic ILP setting [1]. The algorithm adopts the principle of offline candidate determination algorithm used for mining association rules in large transaction databases [4]. Analoguous to the measures used in mining association rules, we define a support and a confidence measure as acceptance criteria for discovered hypothesis clauses.
%P 288-295


%0 Conference Proceedings
%T Competence-Guided Case-Base Editing Techniques
%A McKenna, Elizabeth
%A Smyth, Barry
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_17
%X Case-based classification is a powerful classification method, which (in its simplest form) assigns a target case to the same class as the nearest of n previously classified cases. Many case-based classifiers use the simple nearest-neighbour technique to identify the nearest case, but this means comparing the target case to all of the stored cases at classification time, resulting in high classification costs. For this reason many techniques have been proposed to improve the performance of case-based classifiers by reducing the search they must perform. In this paper we will look at editing techniques that preserve the lazy-learning quality of case-based classification, but improve classification performance.
%P 186-197


%0 Conference Proceedings
%T Building a Case-Based Decision Support System for Land Development Control Using Land Use Function Pattern
%A Wang, Xingwen
%A Yeh, Anthony G. O.
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_47
%X Land development control is the process of controlling land development to meet the needs of the society. In this paper, we attempt to advance the use of case-based reasoning in building a case-based decision support system for land development control. Land development control is a complex domain. We first discuss how to deal with the data and knowledge involved in land development control in order to represent the knowledge and define the case in the system. We then propose to use land use function pattern, which is built on geospatial relations and land use functions of the proposed development site with its surrounding environment, to simplify case input, representation and retrieval of the system. Different land use types have different land use function patterns. Land use function pattern can be extracted from the domain knowledge derived from town planning legislation, regulations, and guidelines. Our work mainly aims to support the work of planning officers in seeking similar precedent cases in preparing recommendations to the Town Planning Board. From the preliminary results of the experimental system, we find that cases can be more easily input and represented and similar case(s) can be more efficiently and effectively retrieved using land use function pattern.
%P 642-654


%0 Conference Proceedings
%T An analogical theory of creativity in design
%A Bhatta, Sambasiva R.
%A Goel, Ashok K.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_525
%X Creative design often involves large, complex modifications to the design topology. Making these modifications typically requires transfer of design configurations from different designs to the new problem. We describe an analogical theory of creative design called model-based analogy (MBA). In this theory, case-specific structure-behavior-function (SBF) models of past designs enable abstraction of generic telelogical mechanisms (GTMs) at storage time. The goal of adapting a specific design to address a new design problem leads to the retrieval of a relevant GTM and its instantiation in the context of the case-specific SBF model at transfer time. Thus GTMs learned from past designs mediate the transfer of abstract design configurations to a new problem.
%P 565-574


%0 Conference Proceedings
%T KM-PEB: An Online Experience Base on Knowledge Management Technology
%A Althoff, Klaus-Dieter
%A MÃ¼ller, Wolfgang
%A Nick, Markus
%A Snoek, BjÃ¶rn
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_29
%X We present a framework for assessing knowledge management (KM) technology that has been validated by using more than twenty well-known tools. Based on a commercial case-based reasoning (CBR) tool, the technology descriptions have been made available in the KM-PEB experience base over the World Wide Web. KM researchers as well as KM tool developers and/or users can search for similar descriptions and/or contribute their own ones. We think that the KM and CBR communities can benefit very much from each other, and we hope that this paper - and its underlying application KM-PEB - supports the (already started) collaboration of these communities in a constructive way.
%P 335-347


%0 Conference Proceedings
%T Combining medical records with case-based reasoning in a mixed paradigm design â TROPIX architecture & implementation
%A Ochi-Okorie, A. Sunny
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_482
%X The design architecture, case representation of actual medical cases, and the implementation of TROPIX, a tropical disease diagnosis and therapy tool are presented. TROPIX is intended to be bundled with laptop computers for rural health centers and semi-urban hospitals in developing countries. Our model uses the ideal domain knowledge to build a decision matrix, DM from disease features against which new cases are measured using the MVF (Matched Vector Functions) algorithms. The result of the diagnosis stage provided by the MVF procedure and other parameters of the features are then used for CBR case retrievals, verification, and case validation. The final stage in the design yields the selection of 1 or 2 competing cases presented for reuse and perhaps for subsequent repair and adaptation.
%P 94-103


%0 Conference Proceedings
%T Representing Temporal Knowledge for Case-Based Prediction
%A JÃ¦re, Martha DÃ¸rum
%A Aamodt, Agnar
%A Skalle, PÃ¥l
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_14
%X Cases are descriptions of situations limited in time and space. The research reported here introduces a method for representation and reasoning with time-dependent situations, or temporal cases, within a knowledge-intensive CBR framework. Most current CBR methods deal with snapshot cases, descriptions of a world state at a single time stamp. In many time-dependent situations, value sets at particular time points are less important than the value changes over some interval of time. Our focus is on prediction problems for avoiding faulty situations. Based on a well-established theory of temporal intervals, we have developed a method for representing temporal cases inside the knowledge-intensive CBR system Creek. The paper presents the theoretical foundation of the method, the representation formalism and basic reasoning algorithms, and an example applied to the prediction of unwanted events in oil well drilling.
%P 174-188


%0 Conference Paper
%T CrossÂ­Lingual Medical Information Retrieval through Semantic Annotation
%D 2002
%A Vintar, Å pela
%A Buitelaar, Paul
%X We present a framework for concept-based, cross-lingual information retrieval (CLIR) in the medical domain, which is under development in the MUCHMORE project. Our approach is based on using the Unified Medical Language System (UMLS) as the primary source of semantic data, whereby documents and queries are annotated with multiple layers of linguistic information. Linguistic processing includes POS-tagging, morphological analysis, phrase recognition and the identification of medical concepts and semantic relations between them.
%0 Conference Proceedings
%T Learning prediction of time series. A theoretical and empirical comparison of CBR with some other approaches
%A Nakhaeizadeh, Gholamreza
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_77
%X Case-based Reasoning (CBR) is a rather new research area in Artificial Intelligence. The concept of K-Nearest Neighbours (KNN) that can be considered as a subarea of CBR traced back, however, to early fifties and during the last years it is deeply investigated by the statistical community. In dealing with the task âlearning prediction of time seriesâ, besides the KNN-approach, the Statistician have investigated other approaches based on regression analysis and Box-Jenkins methods. Recently, neural networks and symbolic machine learning approaches are applied to performing this task as well. Although learning prediction of time series is a very important task in different scientific disciplines, there is no comprehensive study in the literature which compares the performance of CBR with the performance of the other alternative approaches. The aim of this paper is to contribute to this debate from a theoretical and empirical point of view.
%P 65-76


%0 Conference Proceedings
%T Surviving the Information Explosion: How People Find Their Electronic Information
%A Alvarado, Christine
%A Teevan, Jaime
%A Ackerman, Mark S.
%A Karger, David R.
%D 2003
%X We report on a study of how people look for information within email, files, and the Web. When locating a document or searching for a specific answer, people relied on their contextual knowledge of their information target to help them find it, often associating the target with a specific document. They appeared to prefer to use this contextual information as a guide in navigating locally in small steps to the desired document rather than directly jumping to their target. We found this behavior was especially true for people with unstructured information organization. We discuss the implications of our findings for the design of personal information management tools.

%0 Conference Proceedings
%T Combining Rule-Based and Case-Based Learning for Iterative Part-of-Speech Tagging
%A de Andrade Lopes, Alneu
%A Jorge, AlÃ­pio
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_4
%X In this article we show how the accuracy of a rule based first order theory may be increased by combining it with a case-based approach in a classification task. Case-based learning is used when the rule language bias is exhausted. This is achieved in an iterative approach. In each iteration theories consisting of first order rules are induced and covered examples are removed. The process stops when it is no longer possible to find rules with satisfactory quality. The remaining examples are then handled as cases. The case-based approach proposed here is also, to a large extent, new. Instead of only storing the cases as provided, it has a learning phase where, for each case, it constructs and stores a set of explanations with support and confidence above given thresholds. These explanations have different levels of generality and the maximally specific one corresponds to the case itself. The same case may have different explanations representing different perspectives of the case. Therefore, to classify a new case, it looks for relevant stored explanations applicable to the new case. The different possible views of the case given by the explanations correspond to considering different sets of conditions/features to analyze the case. In other words, they lead to different ways to compute similarity between known cases/explanations and the new case to be classified (as opposed to the commonly used global metric). Experimental results have been obtained on a corpus of Portuguese texts for the task of part-of-speech tagging with significant improvement.
%P 26-36


%0 Conference Proceedings
%T Knowledge engineering requirements in derivational analogy
%A Cunningham, PÃ¡draig
%A Finn, Donal
%A Slattery, SeÃ¡n
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_90
%X A major advantage in using a case-based approach to developing knowledge-based systems is that it can be applied to problems where a strong domain theory may be difficult to determine. However the development of case-based reasoning (CBR) systems that set out to support a sophisticated case adaptation process does require a strong domain model. The Derivational Analogy (DA) approach to CBR is a case in point. In DA the case representation contains a trace of the reasoning process involved in producing the solution for that case. In the adaptation process this reasoning trace is reinstantiated in the context of the new target case; this requires a strong domain model and the encoding of problem solving knowledge. In this paper we analyse this issue using as an example a CBR system called CoBRA that assists with the modelling tasks in numerical simulation.
%P 234-245


%0 Journal Article 
%T A Corpus-based Bootstrapping Algorithm for Semi-Automated Semantic Lexicon Construction
%D 1999
%A Riloff, Ellen
%A Shepherd, Jessica
%J Natural Language Engineering 
%X Many applications need a lexicon that represents semantic information but acquiring lexical information is time consuming. We present a corpus-based bootstrapping algorithm that assists users in creating domain-specific semantic lexicons quickly. Our algorithm uses a representative text corpus for the domain and a small set of âseed wordsâ that belong to a semantic class of interest. The algorithm hypothesizes new words that are also likely to belong to the semantic class because they occur in the same contexts as the seed words. The best hypotheses are added to the seed word list dynamically, and the process iterates in a bootstrapping fashion. When the bootstrapping process halts, a ranked list of hypothesized category words is presented to a user for review. We used this algorithm to generate a semantic lexicon for eleven semantic classes associated with the MUC-4 terrorism domain.

%0 Conference Proceedings
%T Using case data to improve on rule-based function approximation
%A Indurkhya, Nitin
%A Weiss, Sholom M.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_20
%X The regression problem is to approximate a function from sample values. Decision trees and decision rules achieve this task by finding regions with constant function values. While recursive partitioning methods are strong in dynamic feature selection and in explanatory capabilities, an essential weakness of these methods is the approximation of a region by a constant value. We propose a new method that relies on searching for similar cases to boost performance. The new method preserves the strengths of the partitioning schemes while compensating for the weaknesses that are introduced with constant-value regions. Our method relies on searching for the most relevant cases using a rule-based system, and then using these cases for determining the function value. Experimental results demonstrate that the new method can often yield superior regression performance.
%P 217-228


%0 Conference Proceedings
%T A Case-Based Approach to Image Recognition
%A Micarelli, Alessandro
%A Neri, Alessandro
%A Sansonetti, Giuseppe
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_38
%X In this paper we present a case-based approach to the recognition of digital images. The architecture we propose is based on the âwavelet transformâ that has been used for the representation, in the form of old cases, of images already known to the system. The paper also presents our report on a case study in the field of âmobile robotsâ. The described system is capable of analyzing maps obtained from the sensors of a robot, and classifing them as one of the possible âobjectsâ present in the environment in which the robot navigates. The first results we have obtained are encouraging and support the choice of the case-based approach to image recognition using the wavelet transform as a tool for image representation and analysis.
%P 443-454


%0 Conference Proceedings
%T CBR in a changing environment
%A Joh, D. Y.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_478
%X Case-Based Reasoning (CBR) has been proposed for design tasks in which past experience is exploited to solve the current problem. Based on a study of experts, it is believed that a case based approach would be appropriate as the basis for computer aided decision support system for internetwork design. However, certain characteristics of the internetwork design domain require that the state of the art in CBR be extended before it could be applied to internetwork design.
%P 53-62


%0 Conference Proceedings
%T Extending K-Means Clustering to First-Order Representations
%A Kirsten, Mathias
%A Wrobel, Stefan
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_7
%X In this paper, we present an in-depth evaluation of two approaches of extending k-means clustering to work on first-order representations. The first-approach, k-medoids, selects its cluster center from the given set of instances, and is thus limited in its choice of centers. The second approach, k-prototypes, uses a heuristic prototype construction algorithm that is capable of generating new centers. The two approaches are empirically evaluated on a standard benchmark problem with respect to clustering quality and convergence. Results show that in this case indeed the k-medoids approach is a viable and fast alternative to existing agglomerative or top-down clustering approaches even for a small-scale dataset, while k-prototypes exhibited a number of deficiencies.
%P 112-129


%0 Conference Proceedings
%T Learning from positive data
%A Muggleton, Stephen
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_65
%X Gold showed in 1967 that not even regular grammars can be exactly identified from positive examples alone. Since it is known that children learn natural grammars almost exclusively from positives examples, Gold's result has been used as a theoretical support for Chomsky's theory of innate human linguistic abilities. In this paper new results are presented which show that within a Bayesian framework not only grammars, but also logic programs are learnable with arbitrarily low expected error from positive examples only. In addition, we show that the upper bound for expected error of a learner which maximises the Bayes' posterior probability when learning from positive examples is within a small additive term of one which does the same from a mixture of positive and negative examples. An Inductive Logic Programming implementation is described which avoids the pitfalls of greedy search by global optimisation of this function during the local construction of individual clauses of the hypothesis. Results of testing this implementation on artificially-generated data-sets are reported. These results are in agreement with the theoretical predictions.
%P 358-376


%0 Conference Proceedings
%T Attribute-value learning versus inductive logic programming: The missing links
%A De Raedt, Luc
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027304
%X Two contributions are sketched. A first contribution shows that a special case of relational learning can be transformed into attribute-value learning. However, it is much more tractable to stick to the relational representation than to apply the sketched transformation. This provides a sound theoretical justification for inductive logic programming. In a second contribution, we show how existing attribute-value learning techniques and systems can be upgraded towards inductive logic programming using the âLeuvenâ methodology and illustrate it using the Claudien, Tilde, ICL, Warmr, TIC, MacCent and RRL systems.
%P 1-8


%0 Conference Proceedings
%T Genetic Algorithms to Optimise CBR Retrieval
%A Jarmulak, Jacek
%A Craw, Susan
%A Rowe, Ray
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_13
%X Knowledge in a case-based reasoning (CBR) system is often more extensive than simply the cases, therefore knowledge engineering may still be very demanding. This paper offers a first step towards an automated knowledge acquisition and refinement tool for non-case CBR knowledge. A data-driven approach is presented where a Genetic Algorithm learns effective feature selection for inducing case-base index, and feature weights for similarity measure for case retrieval. The optimisation can be viewed as knowledge acquisition or maintenance depending on whether knowledge is being created or refined. Optimising CBRretrieval is achieved using cases from the case-base and only minimal expert input, and so can be easily applied to an evolving case-base or a changing environment. Experiments with a real tablet formulation problem show the gains of simultaneously optimising the index and similarity measure. Provided that the available data represents the problem domain well, the optimisation has good generalisation properties and the domain knowledge extracted is comparable to expert knowledge.
%P 136-147


%0 Conference Proceedings
%T Using machine learning for assigning indices to textual cases
%A BrÃ¼ninghaus, Stefanie
%A Ashley, Kevin D.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_501
%X This paper reports preliminary work on developing methods automatically to index cases described in text so that a case-based reasoning system can reason with them. We are employing machine learning algorithms to classify full-text legal opinions in terms of a set of predefined concepts. These factors, representing factual strengths and weaknesses in the case, are used in the case-based argumentation module of our instructional environment CATO. We first show empirical evidence for the conncetion between the factor model and the vector representation of texts developed in information retrieval. In a set of hypotheses we sketch how including knowledge about the meaning of the factors, their relations and their use in the case-based reasoning system can improve learning, and discuss in what ways background knowledge about the domain can be beneficial. The paper presents initial experiments that show the limitations of purely inductive algorithms for the task.
%P 303-314


%0 Conference Proceedings
%T Intelligent Case-Authoring Support in CaseMaker-2
%A McSherry, David
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_18
%X CaseMaker is an interactive environment for intelligent case-authoring support in CREST, a case-based reasoner for estimation tasks, in which the selection of cases for addition to a case library is guided by empirical evaluation of the coverage contributions of candidate cases. We present a new version of the environment called CaseMaker-2 which is designed to support case authoring more effectively by eliminating a previous requirement for the evaluation of candidate cases to be repeated following the addition of a new case to the library. A key role in the approach is played by eValuate, an algorithm for dynamic partitioning of the space of uncovered cases in such a way that the partition containing a given case represents the minimum additional coverage provided by its addition to the case library.
%P 198-209


%0 Conference Proceedings
%T Inferring Graphs from Walks
%A Aslam, Javed A.
%A Rivest, Ronald L.
%B COLT
%D 1990
%X We consider the problem of inferring an undirected, degree-bounded, edge-colored graph from the sequence of edge colors seen in a walk of that graph. This problem can be viewed as reconstructing the structure of a Markov chain from its output. (That is, we are not concerned with inferring the transition probabilities, but only the underlying graph structure of the Markov chain.) We present polynomial-time algorithms for the inference of underlying graphs of degree-bound 2 (linear chains and cycles), based on some surprising properties about the confluence of various sets of rewrite rules.

%0 Conference Paper
%T Empirical Development of an Exponential Probabilistic Model for Text Retrieval Using Textual Analysis to Build a Better Model
%D 2003
%A Jaime Teevan
%A David R. Karger 
%X Much work in information retrieval focuses on using a model of documents and queries to derive retrieval algorithms. Model based development is a useful alternative to heuristic development because in a model the assumptions are explicit and can be examined and refined independent of the particular retrieval algorithm. We explore the explicit assumptions underlying the naÃ¯ve framework by performing computational analysis of actual corpora and queries to devise a generative document model that closely matches text. Our thesis is that a model so developed will be more accurate than existing models, and thus more useful in retrieval, as well as other applications. We test this by learning from a corpus the best document model. We find the learned model better predicts the existence of text data and has improved performance on certain IR tasks.
%0 Conference Proceedings
%T On Quality Measures for Case Base Maintenance
%A Reinartz, Thomas
%A Iglezakis, Ioannis
%A Roth-Berghofer, Thomas
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_22
%X Case base maintenance is one of the most important issues for current research in Case-Based Reasoning (CBR). In this paper, we outline two novel steps as part of the maintenance phase of the CBR process. The review step covers assessment and monitoring of the knowledge containers whereas the restore step actually modifies the contents of the containers according to recommendations resulting from the review step. Here, we focus our attention on the review step for the case base. For this purpose, we define several quality measures based on different case and case base properties that describe specific characteristics of the case base such as correctness, consistency, uniqueness, minimality, and incoherence. These measures allow an initial implementation of the review step for the case base container. We conclude the paper with an outline of future work to extend these aspects of maintenance in CBR.
%P 247-260


%0 Conference Paper
%T Parallel Web Text Mining for Cross-Language IR
%D 2000
%A Jiang Chen
%A Jian-Yun Nie 
%X One of the approaches to cross-language information retrieval (CLIR) is based on the use of parallel texts. In this paper, we will describe a parallel text mining system called PTMiner (Parallel Text Miner) for the Web environment. We will explain the underlying mining algorithm of this system as well as its implementation using a distributed model and database technology. The resulted corpora are used as the training material for statistical translation models. Preliminary experimental results using the models for CLIR are reported.
%0 Conference Proceedings
%T Case adaptation using an incomplete causal model
%A Hastings, John D.
%A Branting, L. Karl
%A Lockwood, Jeffrey A.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_17
%X This paper describes a technique for integrating case-based reasoning with model-based reasoning to predict the behavior of biological systems characterized both by incomplete models and insufficient empirical data for accurate induction. This technique is implemented in CARMA, a system for rangeland pest management advising. CARMA's ability to predict the forage consumption judgments of 15 expert entomologists was empirically compared to that of CARMA's case-based and model-based components in isolation. This evaluation confirmed the hypothesis that integrating model-based and case-based reasoning through model-based adaptation can lead to more accurate predictions than the use of either technique individually.
%P 181-192


%0 Conference Proceedings
%T Audio Analysis using the Discrete Wavelet Transform
%D 2001
%A Tzanetakis, George
%A Essl, Georg
%A Cook, Perry R.
%X The Discrete Wavelet Transform (DWT) is a transformation that can be used to analyze the temporal and spectral properties of non-stationary signals like audio. In this paper we describe some applications of the DWT to the problem of extracting information from non-speech audio. More specifically automatic classification of various types of audio using the DWT is described and compared with other traditional feature extractors proposed in the literature. In addition, a technique for detecting the beat attributes of music is presented. Both synthetic and real world stimuli were used to evaluate the performance of the beat detection algorithm. Key-Words: audio analysis, wavelets, classification, beat extraction.


%0 Conference Proceedings
%T Static and Dynamic Information Organization with Star Clusters
%D 1998
%A Aslam, Javed A.
%A Pelekhov, Katya
%A Rus, Daniela
%X In this paper we present a system for static and dynamic information organization and show our evaluations of this system on TREC data. We introduce the off-line and on-line star clustering algorithms for information organization. Our evaluation experiments show that the offline star algorithm outperforms the single link and average link clustering algorithms. Since the star algorithm is also highly efficient and simple to implement, we advocate its use for tasks that require clustering, such as information organization, browsing, filtering, routing, topic tracking, and new topic detection. 


%0 Conference Proceedings
%T Inductive logic programming for natural language processing
%A Mooney, Raymond J.
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_45
%X This paper reviews our recent work on applying inductive logic programming to the construction of natural language processing systems. We have developed a system, Chill, that learns a parser from a training corpus of parsed sentences by inducing heuristics that control an initial overly-general shift-reduce parser. CHILL learns syntactic parsers as well as ones that translate English database queries directly into executable logical form. The ATIS corpus of airline information queries was used to test the acquisition of syntactic parsers, and CHILL performed competitively with recent statistical methods. English queries to a small database on U.S. geography were used to test the acquisition of a complete natural language interface, and the parser that Chill acquired was more accurate than an existing hand-coded system. The paper also includes a discussion of several issues this work has raised regarding the capabilities and testing of ILP systems as well as a summary of our current research directions.
%P 1-22


%0 Conference Proceedings
%T A Case Study in Using Linguistic Phrases for Text Categorization on the WWW
%D 1998
%A Ffirnkranz, Johannes
%A Mitchell, Tom Michael
%A Riloff, Ellen
%X Most learning algorithms that are applied to text categorization problems rely on a bag-of-words document representation, i.e., each word occurring in the document is considered as a separate feature. In this paper, we investigate the use of linguistic phrases as input features for text categorization problems. These features are based on information extraction patterns that are generated and used by the AUTOSLOG-TS system. We present experimental results on using such features as background knowledge for two machine learning algorithms on a classification task on the WWW. The results show that phrasal features can improve the precision of learned theories at the expense of coverage.


%0 Conference Proceedings
%T Information-Theoretic Private Information Retrieval: A Unified Construction
%A Beimel, Amos
%A Ishai, Yuval
%Y Orejas, Fernando
%Y Spirakis, Paul G.
%Y van Leeuwen, Jan
%S Automata, Languages and Programming
%D 2001
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48224-6
%F 10.1007/3-540-48224-5_74
%X A Private Information Retrieval (PIR) protocol enables a user to retrieve a data item from a database while hiding the identity of the item being retrieved. In a t-private, k-server PIR protocol the database is replicated among k servers, and the userâs privacy is protected from any collusion of up to t servers. The main cost-measure of such protocols is the communication complexity of retrieving a single bit of data.
%P 912-926


%0 Conference Proceedings
%T Noise detection and elimination applied to noise handling in a KRK chess endgame
%A Gamberger, Dragan
%A LavraÄ, Nada
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_49
%X Compression measures used in inductive learners, such as measures based on the MDL (Minimum Description Length) principle, provide a theoretically justified basis for grading candidate hypotheses. Compression-based induction is appropriate also for handling of noisy data. This paper shows that a simple compression measure can be used to detect noisy examples. A technique is proposed in which noisy examples are detected and eliminated from the training set, and a hypothesis is then built from the set of remaining examples. The separation of noise detection and hypothesis formation has the advantage that noisy examples do not influence hypothesis construction as opposed to most standard approaches to noise handling in which the learner typically tries to avoid overfitting the noisy example set. Experimental results in a KRK (king-rook-king) chess endgame domain show the potential of this novel approach to noise handling.
%P 72-88


%0 Conference Proceedings
%T An Architecture for Knowledge Intensive CBR Systems
%A DÃ­az-Agudo, BelÃ©n
%A GonzÃ¡lez-Calero, Pedro A.
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_5
%X In this paper we describe a domain independent architecture to help in the design of knowledge intensive CBR systems. It is based on the knowledge incorporation from a library of application-independent ontologies and the use of an ontology with the common CBR terminology that guides the case representation and allows the description of flexible, generic and homogeneous CBR processes based on classification.
%P 37-48


%0 
%T
%D 
%A 
%X

%0 Conference Proceedings
%T Activating Case-Based Reasoning with Active Databases
%A Li, Sheng
%A Yang, Qiang
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_2
%X Many of todayâs CBR systems are passive in nature: they require human users to activate them manually and to provide information about the incoming problem explicitly. In this paper, we present an integrated system that combines CBR system with an active database system. Active databases, with the support of active rules, can perform event detecting, condition monitoring, and event handling (action execution) in an automatic manner. The combined ActiveCBR system consists of two layers. In the lower layer, the active database is rule-driven; in the higher layer, the result of action execution of active rules is transformed into feature-value pairs required by the CBR subsystem. The layered architecture separates case-based reasoning from complicated rule-based reasoning, and improves the traditional passive CBR system with the active property. This paper shows how to construct ActiveCBR system and provides an analysis of the resulting system architecture.
%P 3-14


%0 Conference Proceedings
%T Generating numerical literals during refinement
%A Anthony, Simon
%A Frisch, Alan M.
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_35
%X Despite the rapid emergence and success of Inductive Logic Programming, problems still surround number handlingâproblems directly inherited from the choice of logic programs as the representation language. Our conjecture is that a generalisation of the representation language to Constraint Logic Programs provides an effective solution to this problem. We support this claim with the presentation of an algorithm called NUM, to which a top-down refinement operator can delegate the task of finding numerical literals. NUM can handle equations, in-equations and dis-equations in a uniform way, and, furthermore, provides more generality than competing approaches since numerical literals are not required to cover all the positive examples available.
%P 61-76


%0 Conference Proceedings
%T Data manipulation services in the Haystack IR system
%D 1998
%A Asdoorian, Mark
%X The Haystack project seeks to design and implement a distributed, intelligent, personalized, information retrieval system. Haystack archives documents with metadata, which is also indexed by the system to improve query results. To support this system, an infrastructure needed to be designed and implemented. This thesis covers the overall design of that infrastructure with a focus on the service model, event model, remote communications model, and necessary services for the addition of our core metadata for documents in the system.

%0 Conference Proceedings
%T Case-based diagnosis of multiple faults
%A Deters, Ralph
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_37
%X In order to maintain complex technical systems e.g. a telecommunication network, a rapid and precise recognition of faults and critical situations is required. But the large number of different components, the high degree of interdependencies among the components and the permanent changes in these systems make the diagnosis of faults and critical situations difficult.
%P 411-420


%0 Conference Proceedings
%T The All-or-Nothing Nature of Two-Party Secure Computation
%A Beimel, Amos
%A Malkin, Tal
%A Micali, Silvio
%Y Wiener, Michael
%S Advances in Cryptology â CRYPTOâ 99
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48405-9
%F 10.1007/3-540-48405-1_6
%X A function f is computationally securely computable if two computationally-bounded parties Alice, having a secret input x, and Bob, having a secret input y, can talk back and forth so that (even if one of them is malicious) (1) Bob learns essentially only f(x,y) while (2) Alice learns essentially nothing.
%P 80-97


%0 Journal Article
%T Reducing the Serversâ Computation in PrivateInformation Retrieval: PIR with Preprocessing
%A Beimel, Amos
%A Ishai, Yuval
%A Malkin, Tal
%J Journal of Cryptology
%D 2004
%8 March 01
%V 17
%N 2
%@ 1432-1378
%F Beimel2004
%9 journal article
%R 10.1007/s00145-004-0134-y
%U https://doi.org/10.1007/s00145-004-0134-y
%P 125-151


%0 Journal Article
%T Distributed EnergyÂ­conserving Routing Protocols
%D 2003
%A Li, Qun
%A Aslam, Javed A.
%A Rus, Daniela
%X This paper discusses several distributed power-aware routing protocols in wireless ad-hoc networks (especially sensor networks). We seek to optimize the lifetime of the network. We have developed three distributed power-aware algorithms and analyzed their efficiency in terms of the number of message broadcasts and the overall network lifetime modelled as the time to the first message that can not be sent. These are: (1) a distributed min power algorithm (modelled on a distributed version of Dijkstra's algorithm), (2) a distributed max-min algorithm, and (3) the distributed version of the centralized online max-min zP/sub min/ algorithm presented by Qun Li et al. (2001). The first two algorithms are used to define the third, although they are very interesting and useful on their own for applications where the optimization criterion is the minimum power, respectively the maximum residual power. The distributed max-min zP/sub min/ algorithm optimizes the overall lifetime of the network by avoiding nodes of low power, while not using too much total power.

%0 Conference Proceedings
%T Using ILP to Improve Planning in Hierarchical Reinforcement Learning
%A Reid, Mark
%A Ryan, Malcolm
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_11
%X Hierarchical reinforcement learning has been proposed as a solution to the problem of scaling up reinforcement learning. The RL-TOPs Hierarchical Reinforcement Learning System is an implementation of this proposal which structures an agentâs sensors and actions into various levels of representation and control. Disparity between levels of representation means actions can be misused by the planning algorithm in the system. This paper reports on how ILP was used to bridge these representation gaps and shows empirically how this improved the systemâs performance. Also discussed are some of the problems encountered when using an ILP system in what is inherently a noisy and incremental domain.
%P 174-190


%0 Article
%T An Efficient and Flexible Format for Linguistic and Semantic Annotation
%D 2002
%A Vintar, Å pela
%A Buitelaar, Paul
%A Ripplinger, BÃ¤rbel
%A Sacaleanu, Bogdan
%A Raileanu, Diana
%A Prescher, Detlef
%X The paper describes an XML annotation format and tool developed within the MUCHMORE project. The annotation scheme was designed specifically for the purposes of Cross-Lingual Information Retrieval in the medical domain so as to allow both efficient and flexible access to layers of information. We use a parallel English-German corpus of medical abstracts and annotate it with linguistic information (tokenisation, part-of-speech tagging, lemmatisation and decomposition, phrase recognition, grammatical functions) as well as semantic information from various sources. The annotation of medical terms/concepts, semantic types and semantic relations is based on the Unified Medical Language System (UMLS). Additionally, we use EuroWordNet as a general-language resource in annotating word senses and to compare domain-specific and general language use. A major aim of the project is also to complement existing ontological resources by extracting new terms and new semantic relations. We present the annotation scheme, which is conceptually related to stand-off annotation, and describe our tool for automatic semantic annotation.
%0 Conference Proceedings
%T Analyzing and learning ECG waveforms
%A KÃ³kai, Gabriella
%A Alexin, ZoltÃ¡n
%A GyimÃ³thy, Tibor
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_52
%X In this paper we present a system which integrates an ECG waveform classifier (called PECG) with an interactive learner (called IMPUT. The PECG system is based on an attribute grammar specification of ECGs that has been transformed to Prolog. The IMPUT system combines the interactive debugging technique IDT with the unfolding algorithm introduced in SPECTRE. The main result achieved in the new version of the PECG system is that an ILP method can be used to improve the effectiveness of a real size Prolog application. Applying the IMPUT method, the extended PECG system is able to suggest a correct solution to the user to replace the buggy clause recognized during the debugging process.
%P 127-145


%0 Conference Proceedings
%T Cautious induction in inductive logic programming
%A Anthony, Simon
%A Frisch, Alan M.
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_34
%X Many top-down Inductive Logic Programming systems use a greedy, covering approach to construct hypotheses. This paper presents an alternative, cautious approach, known as cautious induction. We conjecture that cautious induction can allow better hypotheses to be found, with respect to some hypothesis quality criteria. This conjecture is supported by the presentation of an algorithm called OILS, and with a complexity analysis and empirical comparison of OILS with the Progol system. The results are encouraging and demonstrate the applicability of cautious induction to problems with noisy datasets, and to problems which require large, complex hypotheses to be learnt.
%P 45-60


%0 Conference Proceedings
%T Tuning Production Processes through a Case Based Reasoning Approach
%A Bandini, Stefania
%A Manzoni, Sara
%A Simone, Carla
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_35
%X This paper illustrates how the Case Based Reasoning (CBR) paradigm has been applied to the definition of the requirements and the specifications of a Knowledge Management technology supporting the handling of tuning and anomalies in production processes. In particular, the production of truck tyres will be illustrated as the application domain of the proposed approach. This domain is a paradigmatic example where the valorization of the experiential knowledge is a company requirement, so the representation of knowledge concerning production process issues is mandatory. It requires extending CBR techniques to an emerging area of application involving knowledge about the interplay of static objects (i.e. products) with dynamic objects (i.e. processes). The content of production cases, their organization into a Case Base and a first proposal for the Case Base retrieval of similar cases will be presented.
%P 475-489


%0 Conference Proceedings
%T Carcinogenesis predictions using ILP
%A Srinivasan, A.
%A King, R. D.
%A Muggleton, S. H.
%A Sternberg, M. J. E.
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_56
%X Obtaining accurate structural alerts for the causes of chemical cancers is a problem of great scientific and humanitarian value. This paper follows up on earlier research that demonstrated the use of Inductive Logic Programming (ILP) for predictions for the related problem of mutagenic activity amongst nitroaromatic molecules. Here we are concerned with predicting carcinogenic activity in rodent bioassays using data from the U.S. National Toxicology Program conducted by the National Institute of Environmental Health Sciences. The 330 chemicals used here are significantly more diverse than the previous study, and form the basis for obtaining Structure-Activity Relationships (SARs) relating molecular structure to cancerous activity in rodents. We describe the use of the ILP system Progol to obtain SARs from this data. The rules obtained from Progol are comparable in accuracy to those from expert chemists, and more accurate than most state-of-the-art toxicity prediction methods. The rules can also be interpreted to give clues about the biological and chemical mechanisms of carcinogenesis, and make use of those learnt by Progol for mutagenesis. Finally, we present details of, and predictions for, an ongoing international blind trial aimed specifically at comparing prediction methods. This trial provides ILP algorithms an opportunity to participate at the leading-edge of scientific discovery.
%P 273-287


%0 Conference Proceedings
%T Using k-d trees to improve the retrieval step in case-based reasoning
%A Wess, Stefan
%A Althoff, Klaus-Dieter
%A Derwand, Guido
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_85
%X Retrieval of cases is one important step within the case-based reasoning paradigm. We propose an improvement of this stage in the process model for finding most similar cases with an average effort of O[log2n], n number of cases. The basic idea of the algorithm is to use the heterogeneity of the search space for a density-based structuring and to employ this precomputed structure, a k- d tree, for efficient case retrieval according to a given similarity measure. Besides illustrating the basic idea, we present empirical results of a comparison of four different k- d tree generating strategies and introduce the notion of dynamic bounds which significantly reduce the retrieval effort. The presented approach is fully implemented and used within two case-based reasoning systems for classification and diagnostic tasks, Patdex and Inreca.
%P 167-181


%0 Conference Proceedings
%T Combining Words and Compound Terms for Monolingual and CrossÂ­-Language Information Retrieval
%D 2002
%A Nie, Jing
%A Dufort, Jean-FranÃ§ois
%X
%0 Conference Paper
%T Evaluating Database Selection Techniques: A Testbed and Experiment
%D 1998
%A James C. French
%A Allison L. Powell
%A Charles L. Viles
%A Travis Emmitt
%A Kevin J. Prey 
%X We describe a testbed for database selection techniques and an experiment conducted using this testbed. The testbed is a decomposition of the TREC/TIPSTER data that allows analysis of the data along multiple dimen-sions, including collection-based and temporal-based anal-ysis. We characterize the subcollections in this testbed in terms of number of documents, queries against which the documents have been evaluated for relevance, and distribu-tion of relevant documents. We then present initial results from a study conducted using this testbed that examines the eeectiveness of the gGlOSS approach to database se-lection. The databases from our testbed were ranked us-ing the gGlOSS techniques and compared to the gGlOSS Ideal(l) baseline and a baseline derived from TREC rele-vance judgements. We have examined the degree to which several gGlOSS estimate functions approximate these base-lines. Our initial results connrm that the gGlOSS estima-tors are excellent predictors of the Ideal(l) ranks but that the Ideal(l) ranks do not estimate relevance-based ranks well.
%0 Conference Proceedings
%T Relational knowledge discovery in databases
%A Blockeel, Hendrik
%A De Raedt, Luc
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_56
%X In this paper, we indicate some possible applications of ILP or similar techniques in the knowledge discovery field, and then discuss several methods for adapting and linking ILP-systems to relational database systems. The proposed methods range from âpure ILPâ to âbased on techniques originating in ILPâ We show that it is both easy and advantageous to adapt ILP-systems in this way.
%P 199-211


%0 Journal Article
%T An automatic and guaranteed determination of the number of roots of an analytic function interior to a simple closed curve in the complex plane
%A Herlocker, Jonathan
%A Ely, Jeffrey
%J Reliable Computing
%D 1995
%8 September 01
%V 1
%N 3
%@ 1573-1340
%F Herlocker1995
%X A well known result from complex analysis allows us, under suitable circumstances, to compute the number of roots of an analytic function,f(z), that lie inside a counterclockwise, simple closed curve,C, by computing the integral.$$\frac{1}{{2\pi i}}\int_C {\frac{{f'(z)}}{{f(z)}}} dz.$$
%9 journal article
%R 10.1007/BF02385255
%U https://doi.org/10.1007/BF02385255
%P 239-249


%0 Conference Proceedings
%T Semi-automatic Acquisition of Machine Translation Knowledge from Examples
%D 1998
%A Ren, Fuji
%X A crucial problem in rule-based machine translation is the acquisition of translation knowledge. Many studies have been conducted for automatic acquisition in the past, but they require a great deal of annotated examples. In this paper, we describe a semi-automatic acquisition from translation examples in Japanese-Chinese environment. Whenever necessary, the process interacts with a user (a linguist) who will provides additional information and constraints for generalizing the translation examples. The semiautomatic approach is more efficient in the sense that less examples are required than automatic approaches. Once the acquired knowledge is integrated with an MT system, we observe an improvement in translation quality.

%0 Conference Proceedings
%T A Mirror Neuron System for Syntax Acquisition
%A Womble, Steve
%A Wermter, Stefan
%Y Dorffner, Georg
%Y Bischof, Horst
%Y Hornik, Kurt
%S Artificial Neural Networks â ICANN 2001
%D 2001
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44668-2
%F 10.1007/3-540-44668-0_172
%X We investigate the use of a connectionist model of a mirror neuron cortical network for a context free syntax acquisition task. A finite state representation of the context free grammar is learned by an implicit knowledge system (IKS) modelled by a connectionist network. A mirror neuron system (MNS) whose evolutionary pedigree suggests adaptation for goal-directed sequential processing is used to track embedded recursions in a learned finite state model of the grammar. The mirror system modifies the output of the IKS depending on the depth of embedding. Reciprocally the IKS updates the MNS as natural âgoalsâ occur within a sequence during sentence production. This solves the computationally hard problem of inferring contexts from sequential input.
%P 1233-1238


%0 Conference Proceedings
%T Using Statistical Translation Models for Bilingual IR
%A Nie, Jian-Yun
%A Simard, Michel
%Y Peters, Carol
%Y Braschler, Martin
%Y Gonzalo, Julio
%Y Kluck, Michael
%S Evaluation of Cross-Language Information Retrieval Systems
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-45691-9
%F 10.1007/3-540-45691-0_11
%X This report describes our tests on applying statistical translation models for bilingual IR tasks in CLEF-2001. These translation models have been trained on a set of parallel web pages automatically mined from the Web. Our previous studies have shown the utility of such corpora for cross-language information retrieval. The goal of the current tests is to see how we can improve the quality of the translation models and make best uses of them. Several questions are considered: Is it useful to consider the IDF factor in addition to the translation probabilities? Is it useful to further clean the training corpora before model training or the translation models themselves? How could we combine the translation models with bilingual dictionaries? Although our tests do not allow us to answer all these questions, they provide useful indication to several further research directions.
%P 137-150


%0 Conference Paper
%T An InformationÂ­theoretic Measure for Document Similarity
%D 2003
%A Javed A. Aslam
%A Meredith Frost  
%X Recent work has demonstrated that the assessment of pairwise object similarity can be approached in an axiomatic manner using information theory. We extend this concept specifically to document similarity and test the effectiveness of an information-theoretic measure for pairwise document similarity. We adapt query retrieval to rate the quality of document similarity measures and demonstrate that our proposed information-theoretic measure for document similarity yields statistically significant improvements over other popular measures of similarity.
%0 Conference Proceedings
%T Term comparisons in first-order similarity measures
%A Bohnebeck, Uta
%A HorvÃ¡th, TamÃ¡s
%A Wrobel, Stefan
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027311
%X The similarity measures used in first-order IBL so far have been limited to the function-free case. In this paper we show that a lot of predictive power can be gained by allowing lists and other terms in the input representation and designing similarity measures that work directly on these structures. We present an improved similarity measure for the first-order instance based learner Ribl that employs the concept of edit distances to efficiently compute distances between lists and terms, discuss its computational and formal properties, and show that it is empirically superior by a wide margin on a problem from the domain of biochemistry.
%P 65-79


%0 Conference Proceedings
%T Strongly typed inductive concept learning
%A Flach, P. A.
%A Giraud-Carrier, C.
%A Lloyd, J. W.
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027322
%X In this paper we argue that the use of a language with a type system, together with higher-order facilities and functions, provides a suitable basis for knowledge representation in inductive concept learning and, in particular, illu minates the relationship between attribute-value learning and inductive logic programming (ILP). Individuals are represented by closed terms: tuples of constants in the case of attribute-value learning; arbitrarily complex terms in the case of ILP. To illustrate the point, we take some learning tasks from the machine learning and ILP literature and represent them in Escher, a typed, higher-order, functional logic programming language being developed at the University of Bristol. We argue that the use of a type system provides better ways to discard meaningless hypotheses on syntactic grounds and encompasses many ad hoc approaches to declarative bias.
%P 185-194


%0 Conference Paper
%T CLIR using a Probabilistic Translation Model based on Web Documents
%D 2000
%A Nie, Jian-yun
%X In  this  report,  we  describe  the  approach  we  used  in  TREC-8  Cross-Language  IR  (CLIR)track.    The  approach  is  based  on  probabilistic  translation  models  estimated  from  twoparallel  training  corpora:  one  established  manually,  and  the  other  built  automaticallywith the documents mined from the Web. We describe the principle of model building,the mining of parallel texts, as well as some preliminary evaluations.
%0 Conference Proceedings
%T Heterogeneous Web Data Extraction using Ontology
%D 2001
%A Snoussi, Hicham
%A Nie, Jing
%X Multi-agent systems can be fully developed only when they have access to a large number of information sources. These latter are becoming more and more available on the Internet in form of web pages. This paper does not deal with the problem of information retrieval, but rather the extraction of data from HTML web pages in order to make them usable by autonomous agents. This problem is not trivial because of the heterogeneity of web pages. We describe our approach to facilitate the formalizati on, extraction and grouping of data from different sources. To do this, we developed a utility tool th at assists us in generating a uniform description for each information source, using a descriptive domain ontology. Users and agents can query the extracted data using a standard querying interface. The ultim a e goal of this tool is to provide useful information to autonomous agents. 
%0 Conference Proceedings
%T Evaluation of Strategies for Generalised Cases within a Case-Based Reasoning Antibiotics Therapy Advice System
%A Schmidt, Rainer
%A Gierl, Lothar
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_42
%X For an intensive care unit, we have developed an antibiotics therapy advice system, called ICONS. To speed-up the process of finding suitable therapy recommendations we have applied Case-based Reasoning techniques. As in a medical expert system all required information should always be up-to-date, a static case base is inappropriate. New cases should be incrementally incorporated into the case base and outdated ones should be updated or erased. For reasons of space limitations and of retrieval time an indefinite growth of the case base should be avoided. To fulfil these requirements we propose to generalise from single cases to prototypical cases and to erase redundant cases. In this paper, we mainly focus on results of extended experiments with generation strategies of generalised cases (prototypes). Additionally, we compare measured retrieval times for two indexing retrieval algorithms: For simple indexing and Tree-Hash retrieval.
%P 491-503


%0 Conference Proceedings
%T An Efficient Approach to Similarity-Based Retrieval on Top of Relational Databases
%A Schumacher, JÃ¼rgen
%A Bergmann, Ralph
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_24
%X This paper presents an approach to realize a case retrieval engine on top of a relational database. In a nutshell the core idea is to approximate a similarity-based retrieval with SQL-queries. The approach avoids duplicating the case data or compiling index structures and is therefore ideal for huge case bases which are often subject to changes. The presented approach is fully implemented as part of the commercial CBR toolbox orenge and the experimental evaluation demonstrates impressive retrieval behaviour.
%P 273-285


%0 Conference Proceedings
%T A large case-based reasoner for legal cases
%A Weber-Lee, Rosina
%A Barcia, Ricardo Miranda
%A da Costa, Marcio C.
%A Filho, Ilson W. Rodrigues
%A Hoeschl, Hugo C.
%A Bueno, Tania C. D'Agostini
%A Martins, Alejandro
%A Pacheco, Roberto C.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_491
%X In this paper we propose a large case-based reasoner for the legal domain. Analyzing legal texts for indexing purposes makes the implementation of large case bases a complex task. We present a methodology to automatically convert legal texts into legal cases guided by domain expert knowledge in a rule-based system with Natural Language Processing (NLP) techniques. This methodology can be generalized to be applied in different domains making Case-Based Reasoning (CBR) paradigm a powerful technology to solve real world problems with large knowledge sources.
%P 190-199


%0 Journal Article
%T PRIME: A System for MultiÂ­lingual Patent Retrieval
%A Higuchi, Shigeto
%A Fukui, Masatoshi
%A Fujii, Atsushi
%A Ishikawa, Tetsuya
%J ArXiv
%D 2002
%X Given the growing number of patents filed in multiple countries, users are interested in retrieving patents across languages. We propose a multi-lingual patent retrieval system, which translates a user query into the target language, searches a multilingual database for patents relevant to the query, and improves the browsing efficiency by way of machine translation and clustering. Our system also extracts new translations from patent families consisting of comparable patents, to enhance the translation dictionary.
%0 Book Section
%T Knowledge Discovery in Databases: An Overview
%A Fayyad, Usama
%E DÅ¾eroski, SaÅ¡o
%E LavraÄ, Nada
%B Relational Data Mining
%D 2001
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-662-04599-2
%F Fayyad2001
%X Data Mining and Knowledge Discovery in Databases (KDD) promise to play an important role in the way people interact with databases, especially decision support databases where analysis and exploration operations are essential. Inductive logic programming can potentially play some key roles in KDD. We define the basic notions in data mining and KDD, define the goals, present motivation, and give a high-level definition of the KDD Process and how it relates to Data Mining. We then focus on data mining methods. Basic coverage of a sampling of methods will be provided to illustrate the methods and how they are used. We cover two case studies of successful applications in science data analysis, one of which is the classification of cataloging of a major astronomy sky survey covering 2 billion objects in the northern sky. The system can outperform human as well as classical computational analysis tools in astronomy on the task of recognizing faint stars and galaxies. We conclude with a listing of research challenges and we outline the areas where ILP could play some important roles in KDD.
%R 10.1007/978-3-662-04599-2_2
%U https://doi.org/10.1007/978-3-662-04599-2_2
%P 28-47


%0 Conference Proceedings
%T Theory Recovery
%A Parson, Rupert
%A Khan, Khalid
%A Muggleton, Stephen
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_24
%X In this paper we examine the problem of repairing incomplete background knowledge using Theory Recovery. Repeat Learning under ILP considers the problem of updating background knowledge in order to progressively increase the performance of an ILP algorithm as it tackles a sequence of related learning problems. Theory recovery is suggested as a suitable mechanism. A bound is derived for the performance of theory recovery in terms of the information content of the missing predicate definitions. Experiments are described that use the logical back-propagation ability of Progol 5.0 to perform theory recovery. The experimental results are consistent with the derived bound.
%P 257-267


%0 Conference Proceedings
%T Using case-based reasoning for argumentation with multiple viewpoints
%A Karacapilidis, Nikos
%A Trousse, Brigitte
%A Papadias, Dimitris
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_523
%X The integration of classical case-based reasoning with other problem solving methods attracts increasing research interest in the broader area of information and decision support systems. This paper presents a framework where CBR and Argumentation Based Reasoning jointly aid agents to address various discourse instances in group decision making processes. The ability to comprehend and engage in arguments is essential for these environments, while use of precedent cases is well-suited. Cases in our model are not merely considered as representations of past data, but as flexible entities associated with the underlying viewpoint of an agent and the evolution of the corresponding discussion. The paper provides an object-oriented description of the elements involved, and illustrates their dependencies through a comprehensive example.
%P 541-552


%0 Conference Proceedings
%T Stratified case-based reasoning in non-refinable abstraction hierarchies
%A Branting, L. Karl
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_521
%X Stratified case-based reasoning (Scbr.) is a technique in which case abstractions are used to assist case retrieval, matching, and adaptation. Previous work showed that Scbr can significantly decrease the computational expense required for retrieval, matching, and adaptation in a route-finding domain characterized by abstraction hierarchies with the downward refinement property. This work explores the effectiveness of Scbr in hierarchies without the downward refinement property. In an experimental evaluation using such hierarchies (1) Scbr significantly decreased search cost in hierarchies without the downward refinement property, although the speedup over ground-level A* was not as great as in refinable hierarchies, (2) little difference was observed in Scbr search costs between case libraries created top-down in the process of Refinement and those created bottom-up from a valid ground solution, and (3) the most important factor in determining speedup appeared to be a priori likelihood that a previous solution can be usefully applied to a new problem.
%P 519-530


%0 Conference Proceedings
%T A Logical Database Mining Query Language
%A De Raedt, Luc
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_5
%X A novel query language for database mining, called RDM, is presented. RDM provides primitives for discovering frequent patterns and association rules, for manipulating example sets, for performing predictive and descriptive induction and for reasoning about the generality of hypotheses. RDM is designed for querying deductive databases and employs principles from inductive logic programming. Therefore RDM allows to query patterns that involve multiple relations as well as background knowledge. The embedding of RDM within a programming language such as PROLOG puts database mining on similar grounds as constraint programming. An operational semantics for RDM is outlined and an efficient algorithm for solving RDM queries is presented. This solver integrates Mitchellâs versionspace approach with the well-known APRIORI algorithm by Agrawal et al.
%P 78-92


%0 Conference Proceedings
%T The adaptation knowledge bottleneck: How to ease it by learning from cases
%A Hanney, Kathleen
%A Keane, Mark T.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_506
%X Assuming that adaptation knowledge will continue to be an important part of CBR systems, a major challenge for the area is to overcome the knowledge-engineering problems that arise in its acquisition. This paper describes an approach to automating the acquisition of adaptation knowledge overcoming many of the associated knowledge-engineering costs. This approach makes use of inductive techniques, which learn adaptation knowledge from case comparison. We also show how this adaptation knowledge can be usefully applied and report on how available domain knowledge might be exploited in such an adaptation-rule learning-system.
%P 359-370


%0 Conference Proceedings
%T Creative design: Reasoning and understanding
%A Simina, Marin
%A Kolodner, Janet
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_527
%X This paper investigates memory issues that influence longterm creative problem solving and design activity, taking a case-based reasoning perspective. Our exploration is based on a well-documented example: the invention of the telephone by Alexander Graham Bell. We abstract Bell's reasoning and understanding mechanisms that appear time and again in long-term creative design. We identify that the understanding mechanism is responsible for analogical anticipation of design constraints and analogical evaluation, beside case-based design. But an already understood design can satisfy opportunistically suspended design problems, still active in background. The new mechanisms are integrated in a computational model, ALEC1, that accounts for some creative behavior in case-based design.
%P 587-598


%0 Conference Proceedings
%T Flexible Control of Case-Based Prediction in the Framework of Possibility Theory
%A Dubois, Didier
%A HÃ¼llermeier, Eyke
%A Prade, Henri
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_7
%X The âsimilar problem-similar solutionâ hypothesis underlying case-based reasoning is modelled in the framework of possibility theory and fuzzy sets. Thus, case-based prediction can be realized in the form of fuzzy set-based approximate reasoning. The inference process makes use of fuzzy rules. It is controlled by means of modifier functions acting on such rules and related similarity measures. Our approach also allows for the incorporation of domain-specific (expert) knowledge concerning the typicality (or exceptionality) of the cases at hand. It thus favors a view of case-based reasoning according to which the user interacts closely with the system in order to control the generalization beyond observed data. Our method is compared to instance-based learning and kernel-based density estimation. Loosely speaking, it adopts basic principles of these approaches and supplements them with the capability of combining knowledge and data in a flexible way.
%P 61-73


%0 Article
%T Lexical Semantics in the Age of the Semantic Web
%D 2001
%A Buitelaar, Paul
%X Lexical semantics is the study of word meaning. The semantic web is a vision of what the web could be if it would foremost consist of knowledge (structured data) rather than text or other unstructured data as it is today. This talk is about the future of word meaning if the semantic web becomes a reality. First, I will therefore briefly clarify what the semantic web vision consists of, followed by a sketch of lexical semantics. Finally, I will speculate on how the inherent semantic standardization process of the semantic web could have a dramatic influence on the study and use of word meaning.
%0 Conference Proceedings
%T Weighting features
%A Wettschereck, Dietrich
%A Aha, David W.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_31
%X Many case-based reasoning algorithms retrieve cases using a derivative of the k-nearest neighbor (k-NN) classifier, whose similarity function is sensitive to irrelevant, interacting, and noisy features. Many proposed methods for reducing this sensitivity parameterize k-NN's similarity function with feature weights. We focus on methods that automatically assign weight settings using little or no domain-specific knowledge. Our goal is to predict the relative capabilities of these methods for specific dataset characteristics. We introduce a five-dimensional framework that categorizes automated weight-setting methods, empirically compare methods along one of these dimensions, summarize our results with four hypotheses, and describe additional evidence that supports them. Our investigation revealed that most methods correctly assign low weights to completely irrelevant features, and methods that use performance feedback demonstrate three advantages over other methods (i.e., they require less pre-processing, better tolerate interacting features, and increase learning rate).
%P 347-358


%0 Conference Proceedings
%T Using prior probabilities and density estimation for relational classification
%A Cussens, James
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027314
%X A Bayesian method for incorporating probabilistic background knowledge into ILP is presented. Positive only learning is extended to allow density estimation. Estimated densities and defined prior are combined in Bayes theorem to perform relational classification. An initial application of the technique is made to part-of-speech (POS) tagging. A novel use of Gibbs sampling for POS tagging is given.
%P 106-115


%0 Conference Proceedings
%T Using software process modeling for building a case-based reasoning methodology: Basic approach and case study
%A Bergmann, Ralph
%A Wilke, Wolfgang
%A Schumacher, JÃ¼rgen
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_520
%X Building a methodology for developing and maintaining CBR applications is an important goal currently addressed by CBR researchers and practitioners. Since CBR application development is a special kind of software development, building a CBR methodology can certainly be viewed as a software engineering research and development activity. This paper presents a perspective of how software process modeling, which is a recent approach in software engineering, can be used for building a case-based reasoning methodology. Further we describe a case study to show the applicability of the proposed concepts.
%P 509-518


%0 Conference Proceedings
%T Towards using a single uniform metric in instance-based learning
%A Ting, Kai Ming
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_52
%X In instance-based learning, two different metrics are usually used for continuous-valued attributes and nominal attributes. The problem of using different metrics in domains which have both types of attribute has been mitigated by methods such as attribute and instance weightings in instance-based learning.
%P 559-568


%0 Article
%T Bootstrapping for Text Learning Tasks
%D 1999
%A Jones, Rosie
%A Mccallum, Andrew
%A Nigam, Kamal
%A Riloff, Ellen
%X When applying text learning algorithms to complex tasks, it is tedious and expensive to hand-label the large amounts of training data necessary for good performance. This paper presents bootstrapping as an alternative approach to learning from large sets of labeled data. Instead of a large quantity of labeled data, this paper advocates using a small amount of seed information and a large collection of easily-obtained unlabeled data. Bootstrapping initializes a learner with the seed information; it then iterates, applying the learner to calculate labels for the unlabeled data, and incorporating some of these labels into the training input for the learner. Two case studies of this approach are presented. Bootstrapping for information extraction provides 76% precision for a 250-word dictionary for extracting locations from web pages, when starting with just a few seed locations. Bootstrapping a text classifier from a few keywords per class and a class hierarchy provides accuracy of 66%, a level close to human agreement, when placing computer science research papers into a topic hierarchy. The success of these two examples argues for the strength of the general bootstrapping approach for text learning tasks.

%0 Conference Proceedings
%T Integrity constraints in ILP using a Monte Carlo approach
%A Jorge, AlÃ­pio
%A Brazdil, Pavel B.
%Y Muggleton, Stephen
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69583-7
%F 10.1007/3-540-63494-0_58
%X Many state-of-the-art ILP systems require large numbers of negative examples to avoid overgeneralization. This is a considerable disadvantage for many ILP applications, namely inductive program synthesis where relativelly small and sparse example sets are a more realistic scenario. Integrity constraints are first order clauses that can play the role of negative examples in an inductive process. One integrity constraint can replace a long list of ground negative examples. However, checking the consistency of a program with a set of integrity constraints usually involves heavy theorem-proving. We propose an efficient constraint satisfaction algorithm that applies to a wide variety of useful integrity constraints and uses a Monte Carlo strategy. It looks for inconsistencies by random generation of queries to the program. This method allows the use of integrity constraints instead of (or together with) negative examples. As a consequence programs to induce can be specified more rapidly by the user and the ILP system tends to obtain more accurate definitions. Average running times are not greatly affected by the use of integrity constraints compared to ground negative examples.
%P 229-244


%0 Conference Proceedings
%T Improved Bicriteria Existence Theorems for Scheduling
%D 1999
%A Aslam, Javed A.
%A Lehman, April Rasala
%A Stein, Clifford
%A Young, Neal E.
%X Two common objectives for evaluating a schedule are the makespan, or schedule length, and the average completion time. This short note gives improved bounds on the existence of schedules that simultaneously optimize both criteria. In particular, for any rho> 0, there exists a schedule of makespan at most 1+rho times the minimum, with average completion time at most (1-e)^rho times the minimum. The proof uses an infininite-dimensional linear program to generalize and strengthen a previous analysis by Cliff Stein and Joel Wein (1997).


%0 Conference Proceedings
%T The Life Cycle of Test Cases in a CBR System
%A Minor, Mirjam
%A Hanft, Alexandre
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_39
%X In this article, a case-based approach for managing cases with a life cycle is introduced. The authors present an application for the accompaniment and support of software engineers in their work of specifying test cases. Some general aspects of corporate knowledge editing are discussed. The model of life cycles provides a solution for editing and retrieving cases with several degrees of maturity. It is realised by persistent case numbers, explicit revision states, and a multi-layered similarity function. Some experiments are performed with a prototypical system.
%P 455-466


%0 Conference Proceedings
%T Theory Completion Using Inverse Entailment
%A Muggleton, Stephen H.
%A Bryant, Christopher H.
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_8
%X The main real-world applications of Inductive Logic Programming (ILP) to date involve the âObservation Predicate Learningâ (OPL) assumption, in which both the examples and hypotheses define the same predicate. However, in both scientific discovery and language learning potential applications exist in which OPL does not hold. OPL is ingrained within the theory and performance testing of Machine Learning. A general ILP technique called âTheory Completion using Inverse Entailmentâ (TCIE) is introduced which is applicable to non-OPL applications. TCIE is based on inverse entailment and is closely allied to abductive inference. The implementation of TCIE within Progol5.0 is described. The implementation uses contra-positives in a similar way to Stickelâs Prolog Technology Theorem Prover. Progol5.0 is tested on two different data-sets. The first dataset involves a grammar which translates numbers to their representation in English. The second dataset involves hypothesising the function of unknown genes within a network of metabolic pathways. On both datasets near complete recovery of performance is achieved after relearning when randomly chosen portions of background knowledge are removed. Progol5.0âs running times for experiments in this paper were typically under 6 seconds on a standard laptop PC.
%P 130-146


%0 Conference Proceedings
%T Improved Noise-Tolerant Learning and Generalized Statistical Queries
%D 1994
%A Aslam, Javed A.
%A Decatur, Scott E.
%X The statistical query learning model can be viewed as a tool for creating (or demonstrating the existence of) noise-tolerant learning algorithms in the PAC model. The complexity of a statistical query algorithm, in conjunction with the complexity of simulating SQ algorithms in the PAC model with noise, determine the complexity of the noise-tolerant PAC algorithms produced. Although roughly optimal upper bounds have been shown for the complexity of statistical query learning, the corresponding noisetolerant PAC algorithms are not optimal due to ine cient simulations. In this paper we provide both improved simulations and a new variant of the statistical query model in order to overcome these ine ciencies. We improve the time complexity of the classi cation noise simulation of statistical query algorithms. Our new simulation has a roughly optimal dependence on the noise rate. We also derive a simpler proof that statistical queries can be simulated in the presence of classi cation noise. This proof makes fewer assumptions on the queries themselves and therefore allows one to simulate more general types of queries. We also de ne a new variant of the statistical query model based on relative error, and we show that this variant is more natural and strictly more powerful than the standard additive error model. We demonstrate e cient PAC simulations for algorithms in this new model and give general upper bounds on both learning with relative error statistical queries and PAC simulation. We show that any statistical query algorithm can be simulated in the PAC model with malicious errors in such a way that the resultant PAC algorithm has a roughly optimal tolerable malicious error rate and sample complexity. Finally, we generalize the types of queries allowed in the statistical query model. We discuss the advantages of allowing these generalized queries and show that our results on improved simulations also hold for these queries. 
%0 Conference Proceedings
%T Is CBR Applicable to the Coordination of Search and Rescue Operations? A Feasibility Study
%A Abi-Zeid, IrÃ¨ne
%A Lamontagne, Luc
%A Yang, Qiang
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_26
%X In response to the occurrence of an air incident, controllers at one of the three Canadian Rescue Coordination Centers (RCC) must make a series of critical decisions on the appropriate procedures to follow. These procedures (called incident prosecution) include hypotheses formulation and information gathering, development of a plan for the search and rescue (SAR) missions and in the end, the generation of reports. We present in this paper the results of a project aimed at evaluating the applicability of CBR to help support incident prosecution in the RCC. We have identified three possible applications of CBR: Online help, real time support for situation assessment, and report generation. We present a brief description of the situation assessment agent system that we are implementing as a result of this study.
%P 358-370


%0 Conference Proceedings
%T Case based reasoning, fuzzy systems modeling and solution composition
%A Yager, Ronald R.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_531
%X Fuzzy systems modeling technique and the case based reasoning methodology are briefly described. It is then shown that these two approaches can be viewed as essentially involving the same process, a matching step and a solution composition step. It is noted that in the typical case based reasoning application the solution composition step is more difficult. Two techniques are suggested to help in the solution composition task in case based reasoning. The first, the weighted median, is useful in domains in which the action space consists of an ordered collection of alternatives. The second, a variation of reinforcement learning, is useful in domains in which the resulting actions involve a sequence of steps.
%P 633-642


%0 Conference Proceedings
%T Maintenance of a Case-Base for the Retrieval of Rotationally Symmetric Shapes for the Design of Metal Castings
%A Mileman, Tony
%A Knight, Brian
%A Petridis, Miltos
%A Preddy, Keith
%A Mejasson, Patrick
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_36
%X In this paper, we discuss the problem of maintenance of a CBR system for retrieval of rotationally symmetric shapes. The special feature of this system is that similarity is derived primarily from graph matching algorithms. The special problem of such a system is that it does not operate on search indices that may be derived from single cases and then used for visualisation and principle component analyses. Rather, the system is built on a similarity metric defined directly over pairs of cases. The problems of efficiency, consistency, redundancy, completeness and correctness are discussed for such a system. Performance measures for the CBR system are given, and the results for trials of the system are presented. The competence of the current case-base is discussed, with reference to a representation of cases as points in an n-dimensional feature space, and a Gramian visualisation. A refinement of the case base is performed as a result of the competence analysis and the performance of the case-base before and after refinement is compared.
%P 418-430


%0 Conference Proceedings
%T Probability Based Metrics for Nearest Neighbor Classification and Case-Based Reasoning
%A Blanzieri, Enrico
%A Ricciâ, Francesco
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_2
%X This paper is focused on a class of metrics for the Nearest Neighbor classifier, whose definition is based on statistics computed on the case base. We show that these metrics basically rely on a probability estimation phase. In particular, we reconsider a metric proposed in the 80âs by Short and Fukunaga, we extend its definition to an input space that includes categorical features and we evaluate empirically its performance. Moreover, we present an original probability based metric, called Minimum Risk Metric (MRM), i.e. a metric for classification tasks that exploits estimates of the posterior probabilities. MRM is optimal, in the sense that it optimizes the finite misclassification risk, whereas the Short and Fukunaga Metric minimize the difference between finite risk and asymptotic risk. An experimental comparison of MRM with the Short and Fukunaga Metric, the Value Difference Metric, and Euclidean-Hamming metrics on benchmark datasets shows that MRM outperforms the other metrics. MRM performs comparably to the Bayes Classifier based on the same probability estimates. The results suggest that MRM can be useful in case-based applications where the retrieval of a nearest neighbor is required.
%P 14-28


%0 Conference Proceedings
%T Concurrent Execution of Optimal Hypothesis Search for Inverse Entailment
%A Ohwada, Hayato
%A Nishiyama, Hiroyuki
%A Mizoguchi, Fumio
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_10
%X Inductive Logic Programming (ILP) allows first-order learning and provides greater expressiveness than propositional learning. However, due to its tradeoff, the learning speed may not be reasonable for datamining settings. To overcome this problem, this paper describes a distributed implementation of an ILP engine, allowing speeding up optimal hypothesis search in inverse entailment according to the number of processors. In this implementation, load balancing is achieved by contract net communication between the processors, resulting in a dynamic allocation of the hypothesis search task. This paper describes our concurrent search algorithm, distributed implementation and experimental results for speeding up inverse entailment. An initial experiment was conducted to demonstrate the well-balanced task allocation.
%P 165-173


%0 Conference Proceedings
%T How case-based reasoning and cooperative query answering techniques support RICAD
%A Daengdej, Jirapun
%A Lukose, Dickson
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_502
%X Many Case-Based Reasoning (CBR) systems are built using the conventional database systems as their case memory. Even though these Database Management Systems (DBMSs) provide a large number of advantages, CBR systems developers face one major draw back. That is, partial-match retrieval is not supported by most of the conventional DBMSs. To overcome this limitation, we investigated contemporary research in CBR and Cooperative Query Answering (CQA). Our finding indicates that there are a number of issues in CQA that can be solved by applying some of the innovative techniques developed by the CBR community, on the other hand, the CQA provide a number of new features which enable easy development of CBR systems. The main contribution of this paper is in explicating how CBR can benefit from the CQA research, and how CQA techniques can enhance the CBR systems. Further, it describes the CQA features in RICAD (Risk Cost Advisor, our experimental CBR system), and how these features enhance its performance.
%P 315-324


%0 Conference Proceedings
%T A Case Retention Policy based on Detrimental Retrieval
%A MuÃ±oz-Avila, HÃ©ctor
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_20
%X This paper presents a policy to retain new cases based on retrieval benefits for case-based planning (CBP). After each case-based problem solving episode, an analysis of the adaptation effort is made to evaluate the guidance provided by the retrieved cases. If the guidance is determined to be detrimental, the obtained solution is retain as a new case in the case base. Otherwise, if the retrieval is beneficial, the case base remains unchanged. We will observe that the notion of adaptable cases is not adequate to address the competence of a case base in the context of CBP. Instead, we claim that the notion of detrimental retrieval is more adequate. We compare our retain policy against two policies in the CBP literature and claim that our policy to retain cases based on the benefits is more effective. Our claim is supported by empirical validation.
%P 276-287


%0 Conference Proceedings
%T Efficient Searching in Distributed Digital Libraries
%D 1998 
%A French, James C.
%A Powell, Allison L.
%A Creighton, Walter R.
%X When a digital library is decomposed into many geographically distributed repositories, search efficiencybecomesan issue. Increasing network congestion makes this a compelling issue. We discuss an effective method for reducing the number of servers needed to respond to a query and give examples of search space reduction in the NCSTRL distributed digital library. 

%0 Conference Proceedings
%T A Cross-Modal Electronic Travel Aid Device
%A Fontana, F.
%A Fusiello, A.
%A Gobbi, M.
%A Murino, V.
%A Rocchesso, D.
%A Sartor, L.
%A Panuccio, A.
%Y PaternÃ², Fabio
%S Human Computer Interaction with Mobile Devices
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-45756-5
%F 10.1007/3-540-45756-9_46
%X This paper describes the design of an Electronic Travel Aid device, that will enable blind individuals to âsee the world with their ears.â A wearable prototype will be assembled using low-cost hardware: earphones, sunglasses fitted with two CMOS micro cameras, and a palmtop computer. Currently, the system is able to detect the light spot produced by a laser pointer, compute its angular position and depth, and generate a correspondent sound providing the auditory cues for the perception of the position and distance of the pointed surface. In this way the blind person can use a common pointer as a replacement of the cane.
%P 393-397


%0 Conference Proceedings
%T The case for graph-structured representations
%A Sanders, Kathryn E.
%A Kettler, Brian P.
%A Hendler, James A.
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_496
%X Case-based reasoning involves reasoning from cases: specific pieces of experience, the reasoner's or another's, that can be used to solve problems. We use the term âgraph-structuredâ for representations that (1) are capable of expressing the relations between any two objects in a case, (2) allow the set of relations used to vary from case to case, and (3) allow the set of possible relations to be expanded as necessary to describe new cases. Such representations can be implemented as, for example, semantic networks or lists of concrete propositions in some logic.
%P 245-254


%0 Conference Proceedings
%T Using Global Statistics to Rank Retrieval Systems without Relevance Judgments
%A Shi, Zhiwei
%A Wang, Bin
%A Li, Peng
%A Shi, Zhongzhi
%Y Shi, Zhongzhi
%Y Vadera, Sunil
%Y Aamodt, Agnar
%Y Leake, David
%S Intelligent Information Processing V
%D 2010
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-642-16327-2
%F 10.1007/978-3-642-16327-2_24
%X How to reduce the amount of relevance judgments is an important issue in retrieval evaluation. In this paper, we propose a novel method using global statistics to rank retrieval systems without relevance judgments. In our method, a series of global statistics of a system, which indicate the percentage of its documents found by k out of all the N systems (k = 1, 2, ..., N), are selected, then a linear combination of the series of global statistics is utilized to fit the mean average precision (MAP) of the retrieval system. Optimal coefficients are obtained by linear regression. No human relevance judgments are required in the entire process. Compared with existing evaluation methods without relevance judgments, our method has two advantages. Firstly, it outperforms all early attempts. Secondly, it is adjustable for different effectiveness measurements, e.g. MAP, precision at n, and so forth.
%P 183-192


%0 Conference Proceedings
%T Towards Learning in CARIN-ALN
%A Rouveirol, CÃ©line
%A Ventos, VÃ©ronique
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_12
%X In this paper we investigate a new language for learning, which combines two well-known representation formalisms, Description Logics and Horn Clause Logics. Our goal is to study the feasability of learning in such a hybrid description - horn clause language, namely CARIN-ALN [LR98b], in the presence of hybrid background knowledge, including a Horn clause and a terminological component. After setting our learning framework, we present algorithms for testing example coverage and subsumption between two hypotheses, based on the existential entailment algorithm studied in[LR98b]. While the hybrid language is more expressive than horn clause logics alone, the complexity of these two steps for CARIN-ALN remains bounded by their respective complexity in horn clause logics.
%P 191-208


%0 Conference Proceedings
%T Distances and limits on Herbrand interpretations
%A Nienhuys-Cheng, Shan-Hwei
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027329
%X A notion of distances between Herbrand interpretations enables us to measure how good a certain program, learned from examples, approximates some target program. The distance introduced in [10] has the disadvantage that it does not fit the notion of âidentification in the limitâ. We use a distance defined by a level mapping [5] to overcome this problem, and study in particular the mapping TII induced by a definite program 11 on the metric space. Continuity of TII holds under certain conditions, and we give a concrete level mapping that satisfies these conditions, based on [10]. This allows us to prove the existence of fixed points without using the Banach Fixed Point Theorem.
%P 250-260


%0 Conference Proceedings
%T Collaborative Maintenance - A Distributed, Interactive Case-Base Maintenance Strategy
%A Ferrario, Maria Angela
%A Smyth, Barry
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_34
%X Case-base maintenance is an important emerging issue for case-base reasoners as they scale-up to handle real-world problems in unstable environments. Overtime the contents of a case-base may become out-of-date or inconsistent with the current target problem space, and maintenance strategies must be devised to help recognise and repair these problems, by deleting, adding, or modifying cases, for example. In this paper we describe a maintenance framework called collaborative maintenance (CM), which has been designed to facilitate, monitor, and control the incremental up-date of live, dynamic case-bases. Our approach is novel in that it automatically supports a distributed, interactive maintenance process - users are permitted to recommend case updates and the collaborative maintenance process ensures that these recommendations are properly reviewed and actioned.
%P 393-405


%0 Conference Proceedings
%T Online PowerÂ­aware Routing in Wireless AdÂ­hoc Networks
%D 2001
%A Li, Qun
%A Aslam, Javed A.
%A Rus, Daniela
%X This paper discusses online power-aware routing in large wireless ad-hoc networks for applications where the message sequence is not known. We seek to optimize the lifetime of the network. We show that online power-aware routing does not have a constant competitive ratio to the off-line optimal algorithm. We develop an approximation algorithm called max-min zPmin that has a good empirical competitive ratio. To ensure scalability, we introduce a second online algorithm for power-aware routing. This hierarchical algorithm is called zone-based routing. Our experiments show that its performance is quite good.

%0 Conference Proceedings
%T On the admissibility of concrete domains for CBR based on description logics
%A Kamp, Gerd
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_494
%X In order to use descriptions logics for case-based reasoning it must be possible to use primitive datatypes such as numbers and strings within the representation and inference mechanisms of the logic. The best way to do so is via so called admissible concrete domains. In this paper we address the general problem of the admissibility of concrete domains, using the application area of the retrieval of bibliographic data as an example. We investigate the theoretical limitations on admissible concrete domains over numbers and strings imposed by decidability results known from mathematical logic and automata theory, as well as the prospects of potential implementations in our description logic CTL.
%P 223-234


%0 Conference Proceedings
%T Constructive Adaptation
%A Plaza, Enric
%A Arcos, Josep-LluÃ­s
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_23
%X Constructive adaptation is a search-based technique for generative reuse in CBR systems for configuration tasks. We discuss the relation of constructive adaptation (CA) with other reuse approaches and we define CA as a search process in the space of solutions where cases are used in two main phases: hypotheses generation and hypotheses ordering. Later, three different CBR systems using CA for reuse are analyzed: configuring gas treatment plants, generating expressive musical phrases, and configuring component-based software applications. After the three analyses, constructive adaptation is discussed in detail and some conclusions are drawn to close the paper.
%P 306-320


%0 Conference Proceedings
%T A hybrid approach to word segmentation
%A Kazakov, Dimitar
%A Manandhar, Suresh
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027316
%X This article presents a combination of unsupervised and supervised learning techniques for generation of word segmentation rules from a list of words. First, a bias for word segmentation is introduced and a simple genetic algorithm is used for the search of segmentation that corresponds to the best bias value. In the second phase, the segmentation obtained from the genetic algorithm is used as an input for two inductive logic programming algorithms, namely FoIDL and CLOG. The result is a logic program that can be used for segmentation of unseen words. The learnt program contains affixes which are characteristic for the given language and can be used in other morphology tasks.
%P 125-134


%0 Conference Proceedings
%T Normal forms for inductive logic programming
%A Flach, Peter A.
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_43
%X In this paper we study induction of unrestricted clausal theories from interpretations. First, we show that in the propositional case induction from complete evidence can be seen as an equivalence-preserving transformation from DNF to CNF. From this we conclude that induction is essentially a process of determining what is false in the domain of discourse. We then proceed by investigating dual normal forms for evidence and hypotheses in predicate logic. We define evidence nonnal form (ENF), which is Skolemised existential DNF under a Consistent Naming Assumption. Because ENF is incomplete, in the sense that it does not have the expressive power of clausal logic, ENF evidence requires the identification of Skolem terms. The approach is partly implemented in the Primus system.
%P 149-156


%0 Conference Proceedings
%T An Evolutionary Approach to Case Adaptation
%A de GÃ³mez Silva Garza, AndrÃ©s
%A Maher, Mary Lou
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_12
%X We present a case adaptation method that employs ideas from the field of genetic algorithms. Two types of adaptations, case combination and case mutation, are used to evolve variations on the contents of retrieved cases until a satisfactory solution is found for a new specified problem. A solution is satisfactory if it matches the specified requirements and does not violate any constraints imposed by the domain of applicability. We have implemented our ideas in a computational system called GENCAD, applied to the layout design of residences such that they conform to the principles of feng shui, the Chinese art of placement. This implementation allows us to evaluate the use of GAâs for case adaptation in CBR. Experimental results show the role of representation and constraints.
%P 162-173


%0 Conference Proceedings
%T Inverse Entailment in Nonmonotonic Logic Programs
%A Sakama, Chiaki
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_13
%X Inverse entailment (IE) is known as a technique for finding inductive hypotheses in Horn theories. When a background theory is nonmonotonic, however, IE is not applicable in its present form. The purpose of this paper is extending the IE technique to nonmonotonic inductive logic programming (ILP). To this end, we first establish a new entailment theorem in normal logic programs, then introduce the notion of contrapositive programs. Finally, a theory of IE in nonmonotonic ILP is constructed.
%P 209-224


%0 Article
%T HUMAN PERCEPTION AND COMPUTER EXTRACTION OF MUSICAL BEAT STRENGTH
%D 2000
%A Tzanetakis, George
%A Essl, Georg
%A Cook, Perry 
%X Musical signals exhibit periodic temporal structure that create the sensation of rhythm. In order to model, analyze, and retrieve musical signals it is important to automatically extract rhythmic information. To somewhat simplify the problem, automatic algo-rithms typically only extract information about the main beat of the signal which can be loosely defined as the regular periodic se-quence of pulses corresponding to where a human would tap his foot while listening to the music. In these algorithms, the beat is characterized by its frequency (tempo), phase (accent locations) and a confidence measure about its detection. The main focus of this paper is the concept of Beat Strength, which will be loosely defined as one rhythmic characteristic that could allow to discriminate between two pieces of music having the same tempo. Using this definition, we might say that a piece of Hard Rock has a higher beat strength than a piece of Classical Music at the same tempo. Characteristics related to Beat Strength have been implicitely used in automatic beat detection algorithms and shown to be as important as tempo information for music clas-sification and retrieval. In the work presented in this paper, a user study exploring the perception of Beat Strength was conducted and the results were used to calibrate and explore automatic Beat Strength measures based on the calculation of Beat Histograms.

%0 Conference Proceedings
%T Similarity measures for structured representations
%A Bunke, H.
%A Messmer, B. T.
%Y Wess, Stefan
%Y Althoff, Klaus-Dieter
%Y Richter, Michael M.
%S Topics in Case-Based Reasoning
%D 1994
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48655-8
%F 10.1007/3-540-58330-0_80
%X A key concept in case-based reasoning is similarity. In this paper, we first propose a similarity measure for structured representations that is based on graph edit operations. Then we show how this similarity measure can be computed by means of state space search. Subsequently, subgraph isomorphism is considered as a special case of graph similarity and a new efficient algorithm for its detection is proposed. The new algorithm is particularly suitable if there is a large number of library cases being tested against an input graph. Finally, we present experimental results showing the computational efficiency of the proposed approach.
%P 106-118


%0 Journal Article
%T A framework for audio analysis based on classification and temporal segmentation
%D 1999 
%A Tzanetakis, George
%A Cook, Perry R.
%X Existing audio tools handle the increasing amount of computer audio data inadequately. The typical tape-recorder paradigm for audio interfaces is inflexible and time consuming, especially for large data sets. On the other hand, completely automatic audio analysis and annotation is impossible using current techniques. Alternative solutions are semi-automatic user interfaces that let users interact with sound in flexible ways based on content. This approach offers significant advantages over manual browsing, annotation and retrieval. Furthermore, it can be implemented using existing techniques for audio content analysis in restricted domains. This paper describes a framework for experimenting evaluating and integrating such techniques. As a test for the architecture, some recently proposed techniques have been implemented and tested. In addition, a new method for temporal segmentation based on audio texture is described. This method is combined with audio analysis techniques and used for hierarchical browsing classification and annotation of audio files.

%0 Conference Paper
%T Learning Subjective Nouns using Extraction Pattern Bootstrapping
%D 2003
%A Ellen Riloff
%A Janyce Wiebe
%A Theresa Wilson
%X We explore the idea of creating a subjectivity classifier that uses lists of subjective nouns learned by bootstrapping algorithms. The goal of our research is to develop a system that can distinguish subjective sentences from objective sentences. First, we use two bootstrapping algorithms that exploit extraction patterns to learn sets of subjective nouns. Then we train a Naive Bayes classifier using the subjective nouns, discourse features, and subjectivity clues identified in prior research. The bootstrapping algorithms learned over 1000 subjective nouns, and the subjectivity classifier performed well, achieving 77% recall with 81% precision.We explore the idea of creating a subjectivity classifier that uses lists of subjective nouns learned by bootstrapping algorithms. The goal of our research is to develop a system that can distinguish subjective sentences from objective sentences. First, we use two bootstrapping algorithms that exploit extraction patterns to learn sets of subjective nouns. Then we train a Naive Bayes classifier using the subjective nouns, discourse features, and subjectivity clues identified in prior research. The bootstrapping algorithms learned over 1000 subjective nouns, and the subjectivity classifier performed well, achieving 77% recall with 81% precision.

%0 Conference Proceedings
%T Reexamining the Cluster Hypothesis: Scatter/Gather on Retrieval Results
%D 1996
%A Hearst, Marti A.
%A Pedersen, Jan O.
%X We present Scatter/Gather, a cluster-based document browsing method, as an alternative to ranked titles for the organization and viewing of retrieval results. We systematically evaluate Scatter/Gather in this context and find significant improvements over similarity search ranking alone. This result provides evidence validating the cluster hypothesis which states that relevant documents tend to be more similar to each other than to non-relevant documents. We describe a system employing Scatter/Gather and demonstrate that users are able to use this system close to its full potential.

%0 Conference Proceedings
%T Relations between Customer Requirements, Performance Measures, and General Case Properties for Case Base Maintenance
%A Iglezakis, Ioannis
%A Reinartz, Thomas
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_13
%X The ultimate goal of CBR applications is to satisfy customers using this technology in their daily business. As one of the crucial issues in CBR for practical applications, maintenance is important to cope with demands changing over time. Review and restore are the two steps in CBR that deal with tasks of maintenance. In order to perform these tasks, we suggested case and case base properties, quality criteria, and restore operators in earlier publications. In this paper, we specify concrete performance measures that correspond to general customer requirements, and analyze the relations between these performance criteria, case properties, and restore operators. We present initial results on theoretical analyzes on these relations, and report on examples of experimental studies that indicate that the suggested case properties and the respective restore operators help to identify maintenance strategies in order to optimize performance of CBR systems over time.
%P 159-173


%0 Conference Proceedings
%T A New Algorithm for Learning Range Restricted Horn Expressions
%A Arias, Marta
%A Khardon, Roni
%Y Cussens, James
%Y Frisch, Alan
%S Inductive Logic Programming
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44960-7
%F 10.1007/3-540-44960-4_2
%X A learning algorithm for the class of range restricted Horn expressions is presented and proved correct. The algorithm works within the framework of learning from entailment, where the goal is to exactly identify some pre-fixed and unknown expression by making questions to membership and equivalence oracles. This class has been shown to be learnable in previous work. The main contribution of this paper is in presenting a more direct algorithm for the problem which yields an improvement in terms of the number of queries made to the oracles. The algorithm is also adapted to the class of Horn expressions with inequalities on all syntactically distinct terms where a significant improvement in the number of queries is obtained.
%P 21-39


%0 Conference Proceedings
%T Experiments on Case-Based Retrieval of Software Designs
%A Gomes, Paulo
%A Pereira, Francisco C.
%A Paiva, Paulo
%A Seco, Nuno
%A Carreiro, Paulo
%A Ferreira, JosÃ© L.
%A Bento, Carlos
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_10
%X Software systems are becoming increasingly complex, demanding for more computational resources and better software development methodologies. The software engineer and the CASE tool must work like a team. For this to happen, the CASE tool must be able to understand the user, and to provide new functionalities, such as flexible retrieval of old designs. We think that Case-Based Reasoning can provide a reasoning framework capable of meeting these demands. One important task that a CASE tool based on Case-Based Reasoning can perform adequately, is the retrieval of relevant designs. These designs can be stored in a case library, central to the software development company, thus enabling knowledge sharing through out the company. In this paper we present an approach to case-based retrieval of software designs, and experimental results achieved with this approach.
%P 118-132


%0 Conference Proceedings
%T Activating CBR Systems through Autonomous Information Gathering
%A Carrick, Christina
%A Yang, Qiang
%A Abi-Zeid, Irene
%A Lamontagne, Luc
%Y Althoff, Klaus-Dieter
%Y Bergmann, Ralph
%Y Branting, L.Karl
%S Case-Based Reasoning Research and Development
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48508-7
%F 10.1007/3-540-48508-2_6
%X Most traditional CBR systems are passive in nature, adopting an advisor role in which a user manually consults the system. In this paper, we propose a system architecture and algorithm for transforming a passive interactive CBR system into an active, autonomous CBR system. Our approach is based on the idea that cases in a CBR system can be used to model hypotheses in a situation assessment application, where case attributes can be considered as questions or information tasks to be performed on multiple information sources. Under this model, we can use the CBR system to continually generate tasks that are planned for and executed based on information sources such as databases, the Internet or the user herself. The advantage of the system is that the majority of trivial or repeated questions to information sources can be done autonomously through information gathering techniques, and human users are only asked a small number of necessary questions by the system. We demonstrate the application of our approach to an equipment diagnosis domain. We show that the system integrates CBR retrieval with hierarchical query planning, optimization and execution.
%P 74-88


%0 Conference Proceedings
%T ADAPtER: An integrated diagnostic system combining case-based and abductive reasoning
%A Portinale, Luigi
%A Torasso, Pietro
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_25
%X The aim of this paper is to describe the ADAPtER system, a diagnostic architecture combining case-based reasoning with abductive reasoning and exploiting the adaptation of the solution of old episodes, in order to focus the reasoning process. Domain knowledge is represented via a logical model and basic mechanisms, based on abductive reasoning with consistency constraints, have been defined for solving complex diagnostic problems involving multiple faults. The model-based component has been supplemented with a case memory and adaptation mechanisms have been developed, in order to make the diagnostic system able to exploit past experience in solving new cases. A heuristic function is proposed, able to rank the solutions associated to retrieved cases with respect to the adaptation effort needed to transform such solutions into possible solutions for the current case. We will discuss some preliminary experiments showing the validity of the above heuristic and the convenience of solving a new case by adapting a retrieved solution rather than solving the new problem from scratch.
%P 277-288


%0 Conference Proceedings
%T Manipulation, analysis and retrieval systems for audio signals
%D 2002
%A Cook, Perry R.
%A Tzanetakis, George
%X Digital audio and especially music collections are becoming a major part of the average computer user experience. Large digital audio collections of sound effects are also used by the movie and animation industry. Research areas that utilize large audio collections include: Auditory Display, Bioacoustics, Computer Music, Forensics, and Music Cognition. In order to develop more sophisticated tools for interacting with large digital audio collections, research in Computer Audition algorithms and user interfaces is required. In this work a series of systems for manipulating, retrieving from, and analysing large collections of audio signals will be described. The foundation of these systems is the design of new and the application of existing algorithms for automatic audio content analysis. The results of the analysis are used to build novel 2D and 3D graphical user interfaces for browsing and interacting with audio signals and collections. The proposed systems are based on techniques from the fields of Signal Processing, Pattern Recognition, Information Retrieval, Visualization and Human Computer Interaction. All the proposed algorithms and interfaces are integrated under MARSYAS, a free software framework designed for rapid prototyping of computer audition research. In most cases the proposed algorithms have been evaluated and informed by conducting user studies. Contributions of this work to the area of Computer Audition include: a general multi-feature audio texture segmentation methodology, feature extraction from mp3 compressed data, automatic beat detection and analysis based on the Discrete Wavelet Transform and musical genre classification combining timbral, rhythmic and harmonic features. Novel graphical user interfaces developed in this work are various tools for browsing and visualizing large audio collections such as the Timbregram, TimbreSpace, GenreGram, and Enhanced Sound Editor.


%0 Conference Proceedings
%T Prolog, refinements and RLGG's
%A Sammut, Claude
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027326
%X Cohen's [1] refinement rules provide a flexible mechanism for introducing intentional background knowledge in an ILP system. Whereas Cohen used a limited second order theorem prover to imple- ment the rule interpreter, we extend the method to use a full Prolog interpreter. This makes the introduction of more complex background knowledge possible. Although refinement rules have been used to gener- ate literals for a general-to-specific search, we show how they can also be used as filters to reduce the number of literals in an RLGG algorithm. Each literal constructed by the LGG is tested against the refinement rules and only admitted if a refinement rule has been satisfied.
%P 225-234


%0 Conference Proceedings
%T Perspectives: A declarative bias mechanism for case retrieval
%A Arcos, Josep LluÃ­s
%A de MÃ¡ntaras, Ramon LÃ³pez
%Y Leake, David B.
%Y Plaza, Enric
%S Case-Based Reasoning Research and Development
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69238-6
%F 10.1007/3-540-63233-6_499
%X The aim of this paper is to present a mechanism, called perspectives, to describe declarative biases for case retrieval in structured representations of cases. Our approach is based on the observation that, in complex tasks, the identification of the relevant aspects for retrieval in a given situation may involve the use of knowledge intensive methods. This identification process requires dynamical decisions about the relevant aspects of a problem and usually forces to consider non predefined retrieval indexes in the memory of cases. Declarative biases provide a flexible way of constructing dynamical perspectives for retrieval in the memory of cases. We have implemented the notion of perspectives in a reflective object-centered representation language, called Noos, based on feature terms. Finally, we have used perspectives as declarative biases for retrieval in the Saxex application, a complex real-world case-based reasoning system for generating expressive performances of melodies based on examples of human performances that are represented as structured.
%P 279-290


%0 Conference Proceedings
%T Analogical Prediction
%A Muggleton, Stephen
%A Bain, Michael
%Y DÅ¾eroski, SaÅ¡o
%Y Flach, Peter
%S Inductive Logic Programming
%D 1999
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48751-7
%F 10.1007/3-540-48751-4_22
%X Inductive Logic Programming (ILP) involves constructing an hypothesis H on the basis of background knowledge B and training examples E. An independent test set is used to evaluate the accuracy of H. This paper concerns an alternative approach called Analogical Prediction (AP). AP takes B, E and then for each test example ???x, y??? forms an hypothesis Hx from B, E, x. Evaluation of AP is based on estimating the probability that Hx(x) = y for a randomly chosen ???x, y???. AP has been implemented within CProgol4.4. Experiments in the paper show that on English past tense data AP has significantly higher predictive accuracy on this data than both previously reported results and CProgol in inductive mode. However, on KRK illegal AP does not outperform CProgol in inductive mode. We conjecture that AP has advantages for domains in which a large proportion of the examples must be treated as exceptions with respect to the hypothesis vocabulary. The relationship of AP to analogy and instance-based learning is discussed. Limitations of the given implementation of AP are discussed and improvements suggested.
%P 234-244


%0 Conference Proceedings
%T Using ILP-systems for verification and validation of multi-agent systems
%A Jacobs, Nico
%A Driessens, Kurt
%A De Raedt, Luc
%Y Page, David
%S Inductive Logic Programming
%D 1998
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69059-7
%F 10.1007/BFb0027318
%X Most applications of inductive logic programming focus on prediction or the discovery of new knowledge. We describe a less common application of ILP namely verification and validation of knowledge based systems and multi-agent systems. Using inductive logic programming, partial declarative specifications of the software can be induced from the behaviour of the software. These rules can be readily interpreted by the designers or users of the software, and can in turn result in changes to the software. The approach outlined was tested in the domain of multi-agent systems, more in particular the RoboCup domain.
%P 145-154


%0 Conference Proceedings
%T Using abstraction schemata in inductive logic programming
%A Sadohar, Ken
%A Haraguchi, Makoto
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_54
%X We consider inductive logic programming guided by a language bias called abstraction schemata which enables us to specify a partial structure for a target program. Specifically, to improve the efficiency of such learning, we discuss a class of programs for which it is possible to devise a learning algorithm capable of identifying and pruning unpromising uses of the schemata. This identification process includes the bias shift problem: how to decide whether a hypothesis space contains no correct program with respect to a given example specification. For solving this problem, a required property of hypothesis spaces is discovered. This result yields a class of programs that are beyond the representational capabilities of previous approaches â most notably, non-trivial programs with local variables.
%P 256-263


%0 Conference Proceedings
%T On the use of CBR in optimisation problems such as the TSP
%A Cunningham, PÃ¡draig
%A Smyth, Barry
%A Hurley, Neil
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_36
%X The particular strength of CBR is normally considered to be its use in weak theory domains where solution quality is compiled into cases and is reusable. In this paper we explore an alternative use of CBR in optimisation problems where cases represent highly optimised structures in a huge highly constrained solution space. Our analysis focuses on the Travelling Salesman Problem where difficulty arises from the computational complexity of the problem rather than any difficulty associated with the domain theory. We find that CBR is good for producing medium quality solutions in very quick time. We have difficulty getting CBR to produce high quality solutions because solution quality seems to be lost in the adaptation process. We also argue that experiments with CBR on transparent problems such as the TSP tell us a lot about aspects of CBR such as; the quality of CBR solutions, the coverage that cases in the case-base offer and the utility of extending a case-base.
%P 401-410


%0 Conference Proceedings
%T Active Delivery for Lessons Learned Systems
%A Weber, Rosina
%A Aha, David W.
%A MuÃ±oz-Ãvila, Hector
%A Breslow, Leonard A.
%Y Blanzieri, Enrico
%Y Portinale, Luigi
%S Advances in Case-Based Reasoning
%D 2000
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-44527-2
%F 10.1007/3-540-44527-7_28
%X Lessons learned processes, and software systems that support them, have been developed by many organizations (e.g., all USA military branches, NASA, several Department of Energy organizations, the Construction Industry Institute). Their purpose is to promote the dissemination of knowledge gained from the experiences of an organizationâs employees. Unfortunately, lessons learned systems are usually ineffective because they invariably introduce new processes when, instead, they should be embedded into the processes that they are meant to improve. We developed an embedded case-based approach for lesson dissemination and reuse that brings lessons to the attention of users rather than requiring them to fetch lessons from a standalone software tool. We demonstrate this active lessons delivery architecture in the context of HICAP, a decision support tool for plan authoring. We also show the potential of active lessons delivery to increase plan quality for a new travel domain.
%P 322-334


%0 Conference Paper
%T The impact of database selection on distributed searching
%D 2000
%A Allison L. Powell
%A James C. French
%A Jamie Callan
%A Margaret Connell
%A Charles L. Viles 
%X The proliferation of online information resources increases the importance of effective and efficient distributed searching. Distributed searching is cast in three parts â database selection, query processing, and results merging. In this paper we examine the effect of database selection on retrieval performance. We look at retrieval performance in three different distributed retrieval testbeds and distill some general results. First we find that good database selection can result in better retrieval effectiveness than can be achieved in a centralized database. Second we find that good performance can be achieved when only a few sites are selected and that the performance generally increases as more sites are selected. Finally we find that when database selection is employed, it is not necessary to maintain collection wide information (CWI), e.g. global idf. Local information can be used to achieve superior performance. This means that distributed systems can be engineered with more autonomy and less cooperation. This work suggests that improvements in database selection can lead to broader improvements in retrieval performance, even in centralized (i.e. single database) systems. Given a centralized database and a good selection mechanism, retrieval performance can be improved by decomposing that database conceptually and employing a selection step.
%0 Conference Proceedings
%T Case-based reasoning for expertise relocation in support of rural health workers in developing countries
%A Opiyo, Elisha T. O.
%Y Veloso, Manuela
%Y Aamodt, Agnar
%S Case-Based Reasoning Research and Development
%D 1995
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-48446-2
%F 10.1007/3-540-60598-3_8
%X Developing countries still suffer lack of adequate skilled medical health personnel and poor infrastructure. Expert systems have been identified as potential tools in addressing some aspects of these problems. In particular, most of the earlier researchers investigated the possibility of incorporating diagnostic-support applications in the medical work place. They did so by using expert systems that were built around representations such as production rules, frames, scripts and semantic networks. In this paper, a report on a different approach is given. A MEdical Reference SYstem(MERSY) is proposed. The basis of the design of MERSY is the case-based reasoning paradigm with some underlying domain model. This system therefore gets around the limitations of traditional expert systems that are related to knowledge representation and acquisition. The work also a emphasizes a high level of physical portability, hence the relocation of expertise. It is an on-going research.
%P 77-87


%0 Conference Proceedings
%T Learning Horn definitions with equivalence and membership queries
%A Reddy, Chandra
%A Tadepalli, Prasad
%Y LavraÄ, Nada
%Y DÅ¾eroski, SaÅ¡o
%S Inductive Logic Programming
%D 1997
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-69587-5
%F 10.1007/3540635149_53
%X A Horn definition is a set of Horn clauses with the same head literal. In this paper, we consider learning non-recursive, function-free first-order Horn definitions. We show that this class is exactly learnable from equivalence and membership queries. It follows then that this class is PAC learnable using examples and membership queries. Our results have been shown to be applicable to learning efficient goal-decomposition rules in planning domains.
%P 243-255


%0 Conference Proceedings
%T ITR: A Case-Based Travel Advisory System
%A Ricci, Francesco
%A Arslan, Bora
%A Mirzadeh, Nader
%A Venturini, Adriano
%Y Craw, Susan
%Y Preece, Alun
%S Advances in Case-Based Reasoning
%D 2002
%I Springer Berlin Heidelberg
%C Berlin, Heidelberg
%@ 978-3-540-46119-7
%F 10.1007/3-540-46119-1_45
%X This paper presents a web based recommender system aimed at supporting a user in information filtering and product bundling. The system enables the selection of travel locations, activities and attractions, and supports the bundling of a personalized travel plan. A travel plan is composed in a mixed initiative way: the user poses queries and the recommender exploits an innovative technology that helps the user, when needed, to reformulate the query. Travel plans are stored in a memory of cases, which is exploited for ranking travel items extracted from catalogues. A new âcollaborativeâ approach is introduced, where user past behavior similarity is replaced with session (travel plan) similarity.
%P 613-627


