FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Aslam, JA
   Decatur, SE
AF Aslam, JA
   Decatur, SE
TI On the sample complexity of noise-tolerant learning
SO INFORMATION PROCESSING LETTERS
LA English
DT Article
DE machine learning; computational learning theory; computational
   complexity; fault tolerance; theory of computation
AB In this paper, we further characterize the complexity of noise-tolerant learning in the PAC model, Specifically, we show a general lower bound of Omega(log(1/delta)/epsilon(1 - 2 eta)(2)) on the number of examples required for PAC learning in the presence of classification noise, Combined with a result of Simon, we effectively show that the sample complexity of PAC learning in the presence of classification noise is Omega(VC(F)/epsilon(1-2 eta)(2) + log(1/delta)/epsilon(1 - 2 eta)(2)). Furthermore, we demonstrate the optimality of the general lower bound by providing a noise-tolerant learning algorithm for the class of symmetric Boolean functions which uses a sample size within a constant factor of this bound. Finally, we note that our general lower bound compares favorably with various general upper bounds for PAC learning in the presence of classification noise.
C1 HARVARD UNIV,CAMBRIDGE,MA 02138.
   DARTMOUTH COLL,DEPT COMP SCI,HANOVER,NH 03755.
   MIT,COMP SCI LAB,CAMBRIDGE,MA 02139.
NR 11
TC 17
Z9 17
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0020-0190
J9 INFORM PROCESS LETT
JI Inf. Process. Lett.
PD FEB 26
PY 1996
VL 57
IS 4
BP 189
EP 195
DI 10.1016/0020-0190(96)00006-3
PG 7
WC Computer Science, Information Systems
SC Computer Science
GA UA651
UT WOS:A1996UA65100003
DA 2019-08-26
ER

EF